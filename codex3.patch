diff --git a/app/main.py b/app/main.py
index fef004bfe2cc02b25b484109821fa1fafdba66b4..3c09fafd422d3694491c84f7d313b6fbe4072d6e 100644
--- a/app/main.py
+++ b/app/main.py
@@ -1,64 +1,66 @@
 import sys
 import os
 import json
 from pathlib import Path
 from typing import List, Dict, Any
 from fastapi import FastAPI, HTTPException, Depends, WebSocket, WebSocketDisconnect
 from fastapi.middleware.cors import CORSMiddleware
 from fastapi.openapi.utils import get_openapi
 from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
 from router import router
+from routers.router_completions import router_completions
 from routers.healthcheck import router_health_check
 from fastapi.responses import Response
 import yaml
 import functools
 import logging
 from services.service_db import DBService
 
 # Add the parent directory to sys.path to make 'tools' module discoverable
 sys.path.append(str(Path(__file__).parent.parent))
 
 # Set up logging
 logging.basicConfig(level=logging.INFO)
 logger = logging.getLogger(__name__)
 
 # Initialize the FastAPI application
 app = FastAPI(title="OpenAPI Assistants V2.0", version="0.1.0")
 
 # Add CORS middleware
 app.add_middleware(
     CORSMiddleware,
     allow_origins=["*"],  # Adjust as needed for production
     allow_credentials=True,
     allow_methods=["*"],
     allow_headers=["*"],
 )
 
 # Include routers
 app.include_router(router_health_check)
 app.include_router(router)
+app.include_router(router_completions)
 
 # WebSocket connection manager
 class ConnectionManager:
     def __init__(self):
         self.active_connections: List[WebSocket] = []
         
     async def connect(self, websocket: WebSocket):
         await websocket.accept()
         self.active_connections.append(websocket)
         logger.info(f"New WebSocket connection. Total connections: {len(self.active_connections)}")
         
     def disconnect(self, websocket: WebSocket):
         if websocket in self.active_connections:
             self.active_connections.remove(websocket)
             logger.info(f"WebSocket disconnected. Remaining connections: {len(self.active_connections)}")
         
     async def send_personal_message(self, message: str, websocket: WebSocket):
         await websocket.send_text(message)
         
     async def broadcast(self, message: str):
         for connection in self.active_connections:
             await connection.send_text(message)
     
     async def send_json(self, data: Dict[str, Any], websocket: WebSocket):
         await websocket.send_json(data)
diff --git a/app/routers/router_completions.py b/app/routers/router_completions.py
new file mode 100644
index 0000000000000000000000000000000000000000..3cf376797f208144ed1b649ce813a6c2c05408c4
--- /dev/null
+++ b/app/routers/router_completions.py
@@ -0,0 +1,75 @@
+import os
+from typing import List, Optional, Dict, Any
+
+from fastapi import APIRouter, HTTPException
+from pydantic import BaseModel, Field
+from openai import AsyncOpenAI
+
+# Simple in-memory session store
+_SESSION_STORE: Dict[str, List[Dict[str, Any]]] = {}
+
+router_completions = APIRouter(prefix="/api/v3/agent", tags=["Agent V3"])
+
+
+class CompletionRequest(BaseModel):
+    session_id: Optional[str] = Field(None, description="Used to track conversation memory")
+    prompt: str = Field(..., description="The user's message")
+    model: str = Field("gpt-4o", description="Model to use")
+    system_message: Optional[str] = Field(None, description="Assistant persona")
+    messages: Optional[List[Dict[str, Any]]] = Field(None, description="Previous messages")
+    tools: Optional[List[Dict[str, Any]]] = Field(None, description="Tool/function schemas")
+    tool_choice: Optional[str] = Field(None, description="Tool selection strategy")
+
+
+class CompletionResponse(BaseModel):
+    reply: str
+    tool_calls: Optional[List[Dict[str, Any]]]
+    messages: List[Dict[str, Any]]
+
+
+openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
+
+
+@router_completions.post("/request", response_model=CompletionResponse)
+async def agent_request(req: CompletionRequest) -> CompletionResponse:
+    try:
+        # Load prior messages
+        messages: List[Dict[str, Any]] = []
+        if req.session_id and req.session_id in _SESSION_STORE:
+            messages = list(_SESSION_STORE[req.session_id])
+        elif req.messages:
+            messages = list(req.messages)
+
+        # Prepend system message if provided
+        if req.system_message:
+            messages.insert(0, {"role": "system", "content": req.system_message})
+
+        # Append current user prompt
+        messages.append({"role": "user", "content": req.prompt})
+
+        # Generate response using OpenAI chat completions
+        resp = await openai_client.chat.completions.create(
+            model=req.model,
+            messages=messages,
+            tools=req.tools,
+            tool_choice=req.tool_choice,
+        )
+        assistant_message = resp.choices[0].message
+        reply_content = assistant_message.content or ""
+        tool_calls = getattr(assistant_message, "tool_calls", None)
+
+        # Append assistant response
+        if hasattr(assistant_message, "model_dump"):
+            messages.append(assistant_message.model_dump())
+        elif hasattr(assistant_message, "dict"):
+            messages.append(assistant_message.dict())
+        else:
+            messages.append({"role": "assistant", "content": reply_content, "tool_calls": tool_calls})
+
+        # Save updated messages back to session
+        if req.session_id:
+            _SESSION_STORE[req.session_id] = messages
+
+        return CompletionResponse(reply=reply_content, tool_calls=tool_calls, messages=messages)
+    except Exception as e:
+        raise HTTPException(status_code=500, detail=str(e))
