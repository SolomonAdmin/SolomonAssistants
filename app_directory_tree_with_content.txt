"""
Here is the application tree for the "app" directory:

├── app
│   ├── .cache.sqlite
│   ├── rds_db_connection.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/rds_db_connection.py

# test_db_connection.py
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import SQLAlchemyError
import urllib
import os
from dotenv import load_dotenv
from typing import Any, Dict, List, Optional
import logging

class DatabaseConnector:
    def __init__(self):
        self.engine = None
        self.Session = None
        self._load_env_variables()
        self._create_connection_string()
        self._create_engine()

    def _load_env_variables(self):
        current_dir = os.path.dirname(os.path.abspath(__file__))
        dotenv_path = os.path.join(os.path.dirname(current_dir), '.env')
        load_dotenv(dotenv_path)

        self.db_host = os.getenv('DB_HOST')
        self.db_port = os.getenv('DB_PORT')
        self.db_name = os.getenv('DB_NAME')
        self.db_user = os.getenv('DB_USER')
        self.db_password = os.getenv('DB_PASSWORD')
        self.db_type = os.getenv('DB_TYPE', 'mssql+pyodbc')

    def _create_connection_string(self):
        params = urllib.parse.quote_plus(
            f'DRIVER={{ODBC Driver 17 for SQL Server}};'
            f'SERVER={self.db_host},{self.db_port};'
            f'DATABASE={self.db_name};'
            f'UID={self.db_user};'
            f'PWD={self.db_password}'
        )
        self.connection_string = f'{self.db_type}:///?odbc_connect={params}'

    def _create_engine(self):
        self.engine = create_engine(
            self.connection_string,
            echo=False,  # Set to True for debugging
            pool_pre_ping=True,
            pool_recycle=3600,
            pool_size=10,
            max_overflow=20
        )
        self.Session = sessionmaker(bind=self.engine)

    def test_connection(self) -> bool:
        try:
            with self.engine.connect() as connection:
                result = connection.execute(text("SELECT 1"))
                return result.scalar() == 1
        except SQLAlchemyError as e:
            logging.error(f"Database connection test failed: {e}")
            return False

    def execute_query(self, query, params=None):
        with self.Session() as session:
            try:
                result = session.execute(text(query), params or {})
                return result.fetchall()
            except SQLAlchemyError as e:
                logging.error(f"Database error in execute_query: {e}")
                session.rollback()
                raise

    def get_threads(self, solomon_consumer_key: str) -> List[Dict[str, Any]]:
        query = text("SELECT thread_id, thread_name FROM dbo.solConnectThreads WHERE solomon_consumer_key = :key")
        with self.Session() as session:
            try:
                result = session.execute(query, {"key": solomon_consumer_key})
                return [row._asdict() for row in result.fetchall()]
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving threads: {e}")
                return []
    
    def get_consumer_key_by_email(self, email: str) -> Optional[str]:
        query = text("SELECT TOP 1 solomon_consumer_key FROM dbo.solConnectConsumers WHERE customer_email = :email")
        with self.Session() as session:
            try:
                result = session.execute(query, {"email": email})
                row = result.fetchone()
                return row[0] if row else None
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving consumer key by email: {e}")
                return None
            
    def update_solomon_consumer_key(self, email: str, new_key: str) -> bool:
        query = text("UPDATE dbo.solConnectConsumers SET solomon_consumer_key = :new_key WHERE customer_email = :email")
        with self.Session() as session:
            try:
                result = session.execute(query, {"email": email, "new_key": new_key})
                session.commit()
                if result.rowcount == 0:
                    logging.warning(f"No record found for email: {email}")
                    return False
                return True
            except SQLAlchemyError as e:
                logging.error(f"Error updating Solomon consumer key: {e}")
                session.rollback()
                return False
    
    def get_workspaces_by_email(self, email: str) -> list[str]:
        query = text("""
            SELECT workspace_name
            FROM dbo.solConnectUsers 
            WHERE customer_email = :email
        """)
        
        with self.Session() as session:
            try:
                result = session.execute(query, {"email": email})
                # Extract just the workspace_name values from the result
                return [row[0] for row in result]
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving workspaces by email: {e}")
                return []
    
    def get_consumer_key_by_email_and_workspace(self, email: str, workspace_name: str) -> Optional[str]:
        query = text("""
            SELECT solomon_consumer_key
            FROM dbo.solConnectUsers 
            WHERE customer_email = :email 
            AND workspace_name = :workspace_name
        """)
        
        with self.Session() as session:
            try:
                result = session.execute(query, {
                    "email": email,
                    "workspace_name": workspace_name
                })
                row = result.fetchone()
                return row[0] if row else None
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving consumer key: {e}")
                return None

    def get_assistant_builder_threads(self, solomon_consumer_key: str) -> List[Dict[str, Any]]:
        query = text("""
            SELECT thread_id, thread_name 
            FROM dbo.solConnect_AssistantBuilderThreads 
            WHERE solomon_consumer_key = :key
        """)
        with self.Session() as session:
            try:
                result = session.execute(query, {"key": solomon_consumer_key})
                return [row._asdict() for row in result.fetchall()]
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving assistant builder threads: {e}")
                return []

    def create_assistant_builder_thread(self, solomon_consumer_key: str, thread_id: str, thread_name: str) -> bool:
        query = text("""
            INSERT INTO dbo.solConnect_AssistantBuilderThreads 
            (solomon_consumer_key, thread_id, thread_name)
            VALUES (:solomon_consumer_key, :thread_id, :thread_name)
        """)
        with self.Session() as session:
            try:
                session.execute(query, {
                    "solomon_consumer_key": solomon_consumer_key,
                    "thread_id": thread_id,
                    "thread_name": thread_name
                })
                session.commit()
                return True
            except SQLAlchemyError as e:
                logging.error(f"Error creating assistant builder thread: {e}")
                session.rollback()
                return False

    def delete_assistant_builder_thread(self, thread_id: str) -> bool:
        query = text("""
            DELETE FROM dbo.solConnect_AssistantBuilderThreads
            WHERE thread_id = :thread_id
        """)
        with self.Session() as session:
            try:
                result = session.execute(query, {"thread_id": thread_id})
                session.commit()
                return result.rowcount > 0
            except SQLAlchemyError as e:
                logging.error(f"Error deleting assistant builder thread: {e}")
                session.rollback()
                return False
    
    def get_assistant_id_by_thread(self, thread_id: str, solomon_consumer_key: str) -> Optional[str]:
        """
        Retrieves the assistant_id associated with a thread_id and validates the solomon_consumer_key.
        
        Args:
            thread_id (str): The ID of the thread
            solomon_consumer_key (str): The Solomon consumer key for authentication
            
        Returns:
            Optional[str]: The assistant_id if found, None otherwise
        """
        query = text("""
            SELECT assistant_id 
            FROM dbo.solConnect_AssistantBuilderThreads 
            WHERE thread_id = :thread_id 
            AND solomon_consumer_key = :solomon_consumer_key
        """)
        
        with self.Session() as session:
            try:
                result = session.execute(query, {
                    "thread_id": thread_id,
                    "solomon_consumer_key": solomon_consumer_key
                })
                row = result.fetchone()
                return row[0] if row else None
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving assistant ID: {e}")
                return None

    def get_assistant_builder_id(self, solomon_consumer_key: str, workspace_name: str) -> Optional[str]:
        """
        Retrieves the assistant_builder_id for a given solomon_consumer_key and workspace_name.
        
        Args:
            solomon_consumer_key (str): The Solomon consumer key
            workspace_name (str): The workspace name
            
        Returns:
            Optional[str]: The assistant_builder_id if found, None otherwise
        """
        query = text("""
            SELECT assistant_builder_id 
            FROM dbo.solConnectConsumers 
            WHERE solomon_consumer_key = :solomon_consumer_key 
            AND workspace_name = :workspace_name
        """)
        
        with self.Session() as session:
            try:
                result = session.execute(query, {
                    "solomon_consumer_key": solomon_consumer_key,
                    "workspace_name": workspace_name
                })
                row = result.fetchone()
                return row[0] if row else None
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving assistant builder ID: {e}")
                return None
    
    def add_team_member(self, solomon_consumer_key: str, origin_assistant_id: str, 
                     callable_assistant_id: str, callable_assistant_reason: Optional[str] = None) -> tuple[bool, str]:
        """
        Adds a new team member entry in the solConnectTeams table.
        Returns a tuple of (success: bool, message: str)
        """
        # First check if the team member already exists
        check_query = text("""
            SELECT COUNT(1) 
            FROM dbo.solConnectTeams 
            WHERE solomon_consumer_key = :solomon_consumer_key
            AND origin_assistant_id = :origin_assistant_id
            AND callable_assistant_id = :callable_assistant_id
        """)
        
        with self.Session() as session:
            try:
                # Check for existing record
                result = session.execute(check_query, {
                    "solomon_consumer_key": solomon_consumer_key,
                    "origin_assistant_id": origin_assistant_id,
                    "callable_assistant_id": callable_assistant_id
                })
                
                if result.scalar() > 0:
                    return False, "Team member already exists"

                # If no existing record, proceed with insert
                insert_query = text("""
                    INSERT INTO dbo.solConnectTeams 
                    (solomon_consumer_key, origin_assistant_id, callable_assistant_id, callable_assistant_reason)
                    VALUES (:solomon_consumer_key, :origin_assistant_id, :callable_assistant_id, :callable_assistant_reason)
                """)
                
                session.execute(insert_query, {
                    "solomon_consumer_key": solomon_consumer_key,
                    "origin_assistant_id": origin_assistant_id,
                    "callable_assistant_id": callable_assistant_id,
                    "callable_assistant_reason": callable_assistant_reason
                })
                session.commit()
                return True, "Team member added successfully"
                
            except SQLAlchemyError as e:
                logging.error(f"Error adding team member: {e}")
                session.rollback()
                return False, f"Database error: {str(e)}"

    def get_team_callable_assistants(self, solomon_consumer_key: str, origin_assistant_id: str) -> List[Dict[str, Any]]:
        """
        Retrieves all callable assistants for a given origin assistant.
        """
        query = text("""
            SELECT callable_assistant_id, callable_assistant_reason
            FROM dbo.solConnectTeams
            WHERE solomon_consumer_key = :solomon_consumer_key 
            AND origin_assistant_id = :origin_assistant_id
        """)
        
        with self.Session() as session:
            try:
                result = session.execute(query, {
                    "solomon_consumer_key": solomon_consumer_key,
                    "origin_assistant_id": origin_assistant_id
                })
                return [row._asdict() for row in result.fetchall()]
            except SQLAlchemyError as e:
                logging.error(f"Error retrieving team callable assistants: {e}")
                return []

    def delete_team_callable_assistant(self, solomon_consumer_key: str, origin_assistant_id: str, 
                                    callable_assistant_id: str) -> bool:
        """
        Deletes a specific team callable assistant entry.
        """
        query = text("""
            DELETE FROM dbo.solConnectTeams
            WHERE solomon_consumer_key = :solomon_consumer_key
            AND origin_assistant_id = :origin_assistant_id
            AND callable_assistant_id = :callable_assistant_id
        """)
        
        with self.Session() as session:
            try:
                result = session.execute(query, {
                    "solomon_consumer_key": solomon_consumer_key,
                    "origin_assistant_id": origin_assistant_id,
                    "callable_assistant_id": callable_assistant_id
                })
                session.commit()
                return result.rowcount > 0
            except SQLAlchemyError as e:
                logging.error(f"Error deleting team callable assistant: {e}")
                session.rollback()
                return False

def test_db_connection():
    db = DatabaseConnector()
    if db.test_connection():
        print("Database connection successful")
        
        # # Test get_threads method
        # threads = db.get_threads("C69E685B-A783-4950-A040-414B69F61FCC")
        # print(f"Retrieved threads: {threads}")
        
        # Test get_consumer_key_by_email method
        test_email = "jsturgis@solomonconsult.com"
        consumer_key = db.get_consumer_key_by_email(test_email)
        if consumer_key:
            print(f"Consumer key for {test_email}: {consumer_key}")
        else:
            print(f"No consumer key found for {test_email}")
    else:
        print("Database connection failed")

if __name__ == "__main__":
    test_db_connection()

# def main():
#     db_connector = DatabaseConnector()
    
#     try:
#         # Example query
#         query = "SELECT TOP 10 * FROM dbo.solConnectConsumers WHERE solomon_consumer_key = :key"
#         params = {"key": "C69E685B-A783-4950-A040-414B69F61FCC"}
        
#         results = db_connector.execute_query(query, params)
        
#         if results:
#             for row in results:
#                 print(row)
#         else:
#             print("No results found.")
#     except Exception as e:
#         logging.error(f"Error in main: {e}")
#         print("An error occurred while executing the query.")

# if __name__ == '__main__':
#     main()

FILE NAME /Users/rossdickinson/SolomonAssistants/app/rds_db_connection.py

│   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/__init__.py



FILE NAME /Users/rossdickinson/SolomonAssistants/app/__init__.py

│   ├── utils.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/utils.py

# utils.py
import os
from dotenv import load_dotenv

# Get the directory of the current file (utils.py)
current_dir = os.path.dirname(os.path.abspath(__file__))

# Construct the path to the .env file (assuming it's in the parent directory)
dotenv_path = os.path.join(os.path.dirname(current_dir), '.env')

# Load the .env file
load_dotenv(dotenv_path)

# Get environment variables
OPENAI_API_KEY_env = os.getenv('OPENAI_API_KEY')

def get_headers(openai_api_key: str = None) -> dict:
    """
    Returns the headers required for OpenAI API requests.
    If openai_api_key is provided, it will use that, otherwise it will use the environment variable.
    """
    api_key = openai_api_key or OPENAI_API_KEY_env
    print(api_key)
    if not api_key:
        raise ValueError("OpenAI API key must be provided either as an argument or set as an environment variable.")

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
            "OpenAI-Beta": "assistants=v2"
    }
    return headers


FILE NAME /Users/rossdickinson/SolomonAssistants/app/utils.py

│   ├── safe_router.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/safe_router.py

# app/safe_router.py

from fastapi import APIRouter
from typing import Callable
import logging

logger = logging.getLogger(__name__)

class SafeAPIRouter(APIRouter):
    def add_api_route(self, path: str, endpoint: Callable, **kwargs):
        operation_id = kwargs.get('operation_id')
        if operation_id and len(operation_id) > 64:
            logger.warning(f"Operation ID '{operation_id}' exceeds 64 characters. It will be truncated.")
            kwargs['operation_id'] = operation_id[:64]
        super().add_api_route(path, endpoint, **kwargs)

    def get(self, path: str, *args, **kwargs):
        return self.add_api_route(path, methods=["GET"], *args, **kwargs)

    def post(self, path: str, *args, **kwargs):
        return self.add_api_route(path, methods=["POST"], *args, **kwargs)

    def put(self, path: str, *args, **kwargs):
        return self.add_api_route(path, methods=["PUT"], *args, **kwargs)

    def delete(self, path: str, *args, **kwargs):
        return self.add_api_route(path, methods=["DELETE"], *args, **kwargs)

    # Add other HTTP methods as needed...

FILE NAME /Users/rossdickinson/SolomonAssistants/app/safe_router.py

│   ├── router.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/router.py

from fastapi import APIRouter
from safe_router import SafeAPIRouter
from routers.router_assistant import router_assistant
from routers.router_runs import router_runs
from routers.router_messages import router_messages
from routers.router_vector_stores import router_vector_stores
from routers.router_vector_store_files import router_vector_store_files
from routers.router_files import router_files
from routers.router_o1 import router_o1
from routers.router_threads import router_threads
from routers.router_auth import router_auth
from routers.router_tools import tool_available_router 
from routers.router_assistant_builder_threads import router_assistant_builder_threads
from routers.router_workato import router_workato
from routers.router_teams import router_teams

router = SafeAPIRouter(prefix="/api/v2")

router.include_router(router_assistant)
router.include_router(tool_available_router)
router.include_router(router_runs)
router.include_router(router_messages)
router.include_router(router_vector_stores)
router.include_router(router_vector_store_files)
router.include_router(router_files)
router.include_router(router_o1)
router.include_router(router_threads)
router.include_router(router_auth)
router.include_router(router_assistant_builder_threads)
router.include_router(router_workato)
router.include_router(router_teams)

FILE NAME /Users/rossdickinson/SolomonAssistants/app/router.py

│   ├── main.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/main.py

import sys
import os
from pathlib import Path
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.openapi.utils import get_openapi
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from router import router
from routers.healthcheck import router_health_check
from fastapi.responses import Response
import yaml
import functools

# Add the parent directory to sys.path to make 'tools' module discoverable
sys.path.append(str(Path(__file__).parent.parent))

# Initialize the FastAPI application
app = FastAPI(title="OpenAPI Assistants V2.0", version="0.1.0")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Adjust as needed for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(router_health_check)
app.include_router(router)

# Customize OpenAPI schema
def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    openapi_schema = get_openapi(
        title="OpenAPI Assistants V2.0",
        version="0.1.0",
        description="Your API description",
        routes=app.routes,
    )
    openapi_schema["components"]["securitySchemes"] = {
        "BearerAuth": {
            "type": "http",
            "scheme": "bearer",
            "bearerFormat": "JWT",
        }
    }
    openapi_schema["security"] = [{"BearerAuth": []}]
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi

@app.get("/openapi.yaml")
@functools.lru_cache()
def get_openapi_yaml() -> Response:
    openapi_json = app.openapi()  # Get the OpenAPI JSON spec
    yaml_output = yaml.dump(openapi_json)  # Convert JSON to YAML
    return Response(content=yaml_output, media_type="text/x-yaml")

# Debug middleware to log requests
@app.middleware("http")
async def log_requests(request, call_next):
    print(f"Received request: {request.method} {request.url}")
    print("Headers:")
    for name, value in request.headers.items():
        print(f"{name}: {value}")
    response = await call_next(request)
    return response

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

FILE NAME /Users/rossdickinson/SolomonAssistants/app/main.py

│   ├── run_server.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/run_server.py

import uvicorn
import argparse
import os
import sys

def main():
    parser = argparse.ArgumentParser(description="Start the WebSocket server for OpenAI Agents")
    parser.add_argument("--host", default="0.0.0.0", help="Host to bind the server to")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind the server to")
    parser.add_argument("--reload", action="store_true", help="Enable auto-reload for development")
    
    args = parser.parse_args()
    
    print(f"Starting WebSocket server on {args.host}:{args.port}")
    
    # Determine the correct path to the websocket server
    if os.path.exists(os.path.join(os.path.dirname(__file__), "api", "websocket", "websocket_server.py")):
        server_path = "app.api.websocket.websocket_server:app"
    else:
        server_path = "app.api.websocket_server:app"
    
    print(f"Using server path: {server_path}")
    
    uvicorn.run(
        server_path, 
        host=args.host, 
        port=args.port,
        reload=args.reload
    )

if __name__ == "__main__":
    main() 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/run_server.py

│   ├── routers
│   │   ├── router_messages.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_messages.py

from fastapi import APIRouter, HTTPException, Query, Header
from models.models_messages import ListMessagesResponse, CreateMessageRequest, CreateMessageResponse
from services.service_messages import list_thread_messages, create_message
from services.service_db import DBService
import logging
from typing import Optional

router_messages = APIRouter(prefix="/messages", tags=["Messages"])

logger = logging.getLogger(__name__)

@router_messages.get("/list_messages/threads/{thread_id}/messages", response_model=ListMessagesResponse, operation_id="list_thread_messages")
async def list_messages_endpoint(
    thread_id: str,
    limit: int = Query(20, description="A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20."),
    order: str = Query("desc", description="Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order."),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        logger.info(f"Retrieved OpenAI API key: {openai_api_key[:4]}...{openai_api_key[-4:]}")  # Log partial key

        response = await list_thread_messages(thread_id, limit, order, openai_api_key)
        return response
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.exception(f"Error in list_messages_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

@router_messages.post("/create_message/threads/{thread_id}/messages", response_model=CreateMessageResponse, operation_id="create_thread_message")
async def create_message_endpoint(
    thread_id: str,
    create_message_request: CreateMessageRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        logger.info(f"Retrieved OpenAI API key: {openai_api_key[:4]}...{openai_api_key[-4:]}")  # Log partial key

        response = await create_message(thread_id, create_message_request, openai_api_key=openai_api_key)
        return response
    except ValueError as ve:
        logger.error(f"Value Error: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.exception(f"Error in create_message_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_messages.py

│   │   ├── router_auth.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_auth.py

# routers/router_auth.py
from fastapi import APIRouter, Depends, HTTPException, Header, Query
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.security import OAuth2PasswordBearer
from models.models_auth import UserSignUp, UserSignIn, TokenResponse, UserResponse, VerificationRequest, SolomonConsumerKeyUpdate, WorkspacesResponse
from services.service_auth import CognitoService
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
from botocore.exceptions import ClientError
from rds_db_connection import DatabaseConnector 
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

security = HTTPBearer()

router_auth = APIRouter(tags=["Auth"])
cognito_service = CognitoService()
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")
security = HTTPBearer()
db_connector = DatabaseConnector()  

# Dependency to get the token
async def get_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    return credentials.credentials

@router_auth.post("/signup", response_model=UserResponse)
async def sign_up(user: UserSignUp):
    try:
        return await cognito_service.sign_up(user)
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router_auth.post("/signin", response_model=TokenResponse)
async def sign_in(user: UserSignIn):
    try:
        return await cognito_service.sign_in(user)
    except Exception as e:
        if "Incorrect username or password" in str(e):
            raise HTTPException(status_code=401, detail="Incorrect username or password")
        elif "User does not exist" in str(e):
            raise HTTPException(status_code=404, detail="User not found")
        else:
            raise HTTPException(status_code=500, detail=f"An error occurred: {str(e)}")

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        token = credentials.credentials
        return await cognito_service.get_user(token)
    except Exception as e:
        raise HTTPException(status_code=401, detail=str(e))

async def get_token(authorization: str = Header(None)):
    if not authorization:
        raise HTTPException(status_code=401, detail="Authorization header missing")
    scheme, _, token = authorization.partition(" ")
    if scheme.lower() != "bearer":
        raise HTTPException(status_code=401, detail="Invalid authentication scheme")
    if not token:
        raise HTTPException(status_code=401, detail="Token missing")
    return token

@router_auth.get("/me", response_model=UserResponse)
async def get_user_info(authorization: str = Header(...)):
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid authorization header")
    
    token = authorization.split(" ")[1]
    
    try:
        # Step 1: Retrieve user data from Cognito
        cognito_user = await cognito_service.get_user(token)
        
        # Step 2: Fetch Solomon consumer key from the database
        solomon_consumer_key = db_connector.get_consumer_key_by_email(cognito_user.email)
        
        # Step 3: Combine the data and create the final response
        user_response = UserResponse(
            id=cognito_user.id,
            email=cognito_user.email,
            name=cognito_user.name,
            solomon_consumer_key=solomon_consumer_key
        )
        
        return user_response
    except Exception as e:
        raise HTTPException(status_code=401, detail=str(e))

@router_auth.post("/verify")
async def verify_signup(verification: VerificationRequest):
    try:
        result = await cognito_service.confirm_sign_up(verification)
        if result:
            return {"message": "User verified successfully"}
    except Exception as e:
        if "Invalid verification code" in str(e):
            raise HTTPException(status_code=400, detail="Invalid verification code")
        elif "Verification code has expired" in str(e):
            raise HTTPException(status_code=400, detail="Verification code has expired")
        else:
            raise HTTPException(status_code=500, detail=f"An error occurred: {str(e)}")
        
@router_auth.post("/refresh-token", response_model=TokenResponse)
async def refresh_token(refresh_token: str = Query(...), email: str = Query(...)):
    try:
        token_response = await cognito_service.refresh_token(refresh_token, email)
        return token_response
    except Exception as e:
        raise HTTPException(status_code=401, detail=str(e))
    
@router_auth.post("/logout")
async def logout(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        token = credentials.credentials
        cognito_service.client.global_sign_out(AccessToken=token)
        return {"message": "Logged out successfully"}
    except ClientError as e:
        raise HTTPException(status_code=500, detail=f"Error logging out: {str(e)}")
    
@router_auth.get("/consumer-key", response_model=dict)
async def get_consumer_key(
    authorization: str = Header(...),
):
    """
    Get the solomon consumer key for the authenticated user.
    Requires Bearer token authentication.
    """
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid authorization header")
    
    token = authorization.split(" ")[1]
    
    try:
        # Step 1: Validate token and get user from Cognito
        cognito_user = await cognito_service.get_user(token)
        
        # Step 2: Get consumer key from RDS
        consumer_key = db_connector.get_consumer_key_by_email(cognito_user.email)
        
        if consumer_key is None:
            logger.warning(f"No consumer key found for user: {cognito_user.email}")
            raise HTTPException(status_code=404, detail="Consumer key not found")
            
        return {"solomon_consumer_key": consumer_key}
        
    except Exception as e:
        logger.error(f"Error retrieving consumer key: {str(e)}")
        if "Invalid or expired token" in str(e):
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@router_auth.put("/consumer-key")
async def update_consumer_key(
    update: SolomonConsumerKeyUpdate,
    authorization: str = Header(...),
):
    """
    Update the solomon consumer key for the authenticated user in RDS database.
    Requires Bearer token authentication.
    """
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid authorization header")
    
    token = authorization.split(" ")[1]
    
    try:
        # Step 1: Validate token and get user from Cognito
        cognito_user = await cognito_service.get_user(token)
        logger.info(f"Updating consumer key for user: {cognito_user.email}")
        
        # Step 2: Update consumer key in RDS
        success = db_connector.update_solomon_consumer_key(
            cognito_user.email, 
            update.solomon_consumer_key
        )
        
        if not success:
            logger.warning(f"Failed to update consumer key for user: {cognito_user.email}")
            raise HTTPException(
                status_code=404,
                detail="User not found in database or update failed"
            )
            
        logger.info(f"Successfully updated consumer key for user: {cognito_user.email}")
        return {
            "message": "Solomon consumer key updated successfully",
            "email": cognito_user.email
        }
        
    except Exception as e:
        logger.error(f"Error updating consumer key: {str(e)}")
        if "Invalid or expired token" in str(e):
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@router_auth.get("/workspaces", response_model=WorkspacesResponse)
async def get_user_workspaces(authorization: str = Header(...)):
    """
    Get all workspace names available to the authenticated user.
    Uses the user's Cognito email to query the solConnectUsers table.
    """
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid authorization header")
    
    token = authorization.split(" ")[1]
    
    try:
        # Step 1: Get user email from Cognito
        cognito_user = await cognito_service.get_user(token)
        
        # Step 2: Get workspace names from database using email
        workspace_names = db_connector.get_workspaces_by_email(cognito_user.email)
        
        return WorkspacesResponse(workspace_names=workspace_names)
        
    except Exception as e:
        logger.error(f"Error retrieving workspaces: {str(e)}")
        if "Invalid or expired token" in str(e):
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@router_auth.get("/workspace-key/{workspace_name}", response_model=dict)
async def get_workspace_consumer_key(
    workspace_name: str,
    authorization: str = Header(...)
):
    """
    Get the solomon consumer key for a specific workspace.
    Requires Bearer token authentication.
    """
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid authorization header")
    
    token = authorization.split(" ")[1]
    
    try:
        # Step 1: Get user from Cognito
        cognito_user = await cognito_service.get_user(token)
        
        # Step 2: Get consumer key for workspace
        consumer_key = db_connector.get_consumer_key_by_email_and_workspace(
            cognito_user.email,
            workspace_name
        )
        
        if not consumer_key:
            raise HTTPException(
                status_code=404, 
                detail="Consumer key not found for this workspace"
            )
            
        return {"solomon_consumer_key": consumer_key}
        
    except Exception as e:
        logger.error(f"Error retrieving workspace consumer key: {str(e)}")
        if "Invalid or expired token" in str(e):
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        raise HTTPException(
            status_code=500, 
            detail=f"Internal server error: {str(e)}"
        )

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_auth.py

│   │   ├── thread.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/thread.py

from fastapi import APIRouter, HTTPException, UploadFile, File
from services.services import create_thread_with_file_service

router = APIRouter()

@router.post("/create_thread_with_file")
async def create_thread_with_file(file: UploadFile = File(...), user_message: str = "Default user message"):
    try:
        thread = await create_thread_with_file_service(file, user_message)
        return {"message": "Thread created successfully", "thread": thread}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/thread.py

│   │   ├── router_threads.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_threads.py

from fastapi import APIRouter, Depends, HTTPException, Header
from typing import Optional
from models.models_threads import ThreadsResponse, CreateThreadRequest, ThreadResponse
from services.service_threads import ThreadService
from services.service_db import DBService
import logging

router_threads = APIRouter(prefix="/thread", tags=["RDS"])

@router_threads.get("/threads/{solomon_consumer_key}", response_model=ThreadsResponse)
async def get_threads(solomon_consumer_key: str, thread_service: ThreadService = Depends(ThreadService)):
    threads = thread_service.get_threads(solomon_consumer_key)
    if not threads:
        raise HTTPException(status_code=404, detail="No threads found for the given consumer key")
    return ThreadsResponse(threads=threads)

@router_threads.post("/create", response_model=ThreadResponse, operation_id="create_thread")
async def create_thread(
    thread_data: Optional[CreateThreadRequest] = None,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        # Create thread with optional data
        thread_service = ThreadService()
        thread_dict = thread_data.dict() if thread_data else {}
        response = thread_service.create_thread_service(thread_dict, openai_api_key)
        return ThreadResponse(**response)
    except Exception as e:
        logging.error(f"Error in create_thread: {e}")
        raise HTTPException(status_code=500, detail=f"Error creating thread: {str(e)}")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_threads.py

│   │   ├── router_files.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_files.py

from fastapi import APIRouter, UploadFile, File, HTTPException, Form, Query, Header
from models.models_files import UploadFileResponse, ListFilesResponse, FileContentUploadRequest, FileContentUploadResponse, FileResponse
from services.service_files import upload_file, list_files, upload_file_content, get_file
import logging
import os
import tempfile
from typing import Optional
from services.service_db import DBService
import logging

logger = logging.getLogger(__name__)

router_files = APIRouter(prefix="/files", tags=["Files V2"])

@router_files.post("/upload", response_model=UploadFileResponse, operation_id="upload_file")
async def upload_file_endpoint(
    file: UploadFile = File(...),  # The uploaded file
    purpose: str = Form("assistants"),  # The purpose of the file, defaulting to "assistants"
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        # Save the uploaded file temporarily
        file_location = f"/tmp/{file.filename}"
        with open(file_location, "wb") as buffer:
            buffer.write(file.file.read())

        # Upload the file to OpenAI using the API key
        response = upload_file(file_path=file_location, purpose=purpose, openai_api_key=openai_api_key)

        # Remove the temporary file
        os.remove(file_location)

        return response
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.exception(f"Error in upload_file_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

@router_files.get("/list", response_model=ListFilesResponse, operation_id="list_files")
async def list_files_endpoint(
    purpose: Optional[str] = Query(None, description="Filter by file purpose"),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = list_files(purpose=purpose, openai_api_key=openai_api_key)
        return response
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.exception(f"Error in list_files_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

@router_files.post("/upload_file_workato", response_model=FileContentUploadResponse, operation_id="upload_file_content")
async def upload_file_content_endpoint(
    request: FileContentUploadRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        with tempfile.NamedTemporaryFile(mode='w+', suffix=f'.{request.file_type}', delete=False) as temp_file:
            temp_file.write(request.content)
            temp_file.flush()
            
            response = upload_file_content(
                file_path=temp_file.name,
                file_name=request.file_name,
                purpose=request.purpose,
                openai_api_key=openai_api_key
            )
            
        os.remove(temp_file.name)
        return response
        
    except Exception as e:
        logger.exception(f"Error in upload_file_content_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

@router_files.get("/{file_id}", response_model=FileResponse, operation_id="get_file")
async def get_file_endpoint(
    file_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")
        
        response = get_file(file_id=file_id, openai_api_key=openai_api_key)
        return response
    except HTTPException as he:
        raise he
    except Exception as e:
        logger.exception(f"Error in get_file_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_files.py

│   │   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/__init__.py



FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/__init__.py

│   │   ├── router_tools.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_tools.py

from fastapi import APIRouter
from tools import tool_registry

tool_available_router = APIRouter(tags=["Tools Available - function calls"])

@tool_available_router.get("/tools", response_model=dict)
async def get_available_tools():
    tools = {}
    for tool_name, tool_class in tool_registry.items():
        tool_instance = tool_class()
        tools[tool_name] = tool_instance.get_definition()["function"]
    return tools


FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_tools.py

│   │   ├── router_teams.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_teams.py

from fastapi import APIRouter, HTTPException, Header, Depends, Path
from models.models_teams import TeamMemberCreate, TeamCallableAssistantsResponse
from services.service_teams import TeamService

router_teams = APIRouter(prefix="/teams", tags=["Teams"])

@router_teams.post("/member/{origin_assistant_id}")
async def add_team_member(
    team_member_data: TeamMemberCreate,
    origin_assistant_id: str = Path(..., description="ID of the origin assistant"),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
    team_service: TeamService = Depends(TeamService)
):
    success, message = team_service.add_team_member(
        solomon_consumer_key=solomon_consumer_key,
        origin_assistant_id=origin_assistant_id,
        callable_assistant_id=team_member_data.callable_assistant_id,
        callable_assistant_reason=team_member_data.callable_assistant_reason
    )
    
    if not success:
        if "already exists" in message:
            raise HTTPException(status_code=409, detail=message)  # 409 Conflict
        raise HTTPException(status_code=400, detail=message)
    
    return {"message": message}

@router_teams.get("/callable-assistants/{origin_assistant_id}", response_model=TeamCallableAssistantsResponse)
async def get_team_callable_assistants(
    origin_assistant_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
    team_service: TeamService = Depends(TeamService)
):
    callable_assistants = team_service.get_team_callable_assistants(
        solomon_consumer_key=solomon_consumer_key,
        origin_assistant_id=origin_assistant_id
    )
    return TeamCallableAssistantsResponse(callable_assistants=callable_assistants)

@router_teams.delete("/callable-assistant/{origin_assistant_id}/{callable_assistant_id}")
async def delete_team_callable_assistant(
    origin_assistant_id: str,
    callable_assistant_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
    team_service: TeamService = Depends(TeamService)
):
    success = team_service.delete_team_callable_assistant(
        solomon_consumer_key=solomon_consumer_key,
        origin_assistant_id=origin_assistant_id,
        callable_assistant_id=callable_assistant_id
    )
    
    if not success:
        raise HTTPException(status_code=404, detail="Team callable assistant not found")
    
    return {"message": "Team callable assistant deleted successfully"}

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_teams.py

│   │   ├── healthcheck.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/healthcheck.py

# routers/healthcheck.py

from fastapi import APIRouter, status
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from services.service_healthcheck import HealthcheckService

router_health_check = APIRouter(tags=["HealthCheck"])

class HealthResponse(BaseModel):
    status: str

class DatabaseHealthResponse(BaseModel):
    status: str
    message: str

@router_health_check.get(
    "/", 
    status_code=status.HTTP_200_OK, 
    operation_id="health_check",
    response_model=HealthResponse
)
async def health_check():
    return {"status": "available"}

@router_health_check.get(
    "/db",
    status_code=status.HTTP_200_OK,
    operation_id="db_health_check",
    response_model=DatabaseHealthResponse
)
async def db_health_check():
    is_healthy, message = await HealthcheckService.check_database_connection()
    if is_healthy:
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content={"status": "available", "message": message}
        )
    else:
        return JSONResponse(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            content={"status": "unavailable", "message": message}
        )

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/healthcheck.py

│   │   ├── router_o1.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_o1.py

# routers/router_o1.py
from fastapi import APIRouter, Depends, HTTPException
from models.models_o1 import O1Request, O1Response
from services.service_o1 import get_o1_completion

router_o1 = APIRouter(
    prefix="/o1",
    tags=["o1-preview"],
)

@router_o1.post("/completion", response_model=O1Response)
async def o1_completion(request: O1Request):
    try:
        response = await get_o1_completion(request)
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_o1.py

│   │   ├── router_assistant_builder_threads.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_assistant_builder_threads.py

from fastapi import APIRouter, Depends, HTTPException, Header
from models.models_assistant_builder_threads import (
    AssistantBuilderThreadsResponse, 
    AssistantBuilderThreadCreate,
    AssistantIdResponse,
    AssistantBuilderIdResponse
)
from services.service_assistant_builder_threads import AssistantBuilderThreadService
import logging
router_assistant_builder_threads = APIRouter(prefix="/assistant-builder-thread", tags=["Assistant Builder Threads"])
logger = logging.getLogger(__name__)

@router_assistant_builder_threads.post("/thread")
async def create_thread(
    thread_data: AssistantBuilderThreadCreate, 
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
    thread_service: AssistantBuilderThreadService = Depends(AssistantBuilderThreadService)
):
    try:
        logger.info(f"Creating assistant builder thread with ID: {thread_data.thread_id}")
        thread_data.solomon_consumer_key = solomon_consumer_key
        success = thread_service.create_thread(thread_data)
        
        if not success:
            raise HTTPException(status_code=400, detail="Failed to create thread")
            
        return {"message": "Thread created successfully", "thread_id": thread_data.thread_id}
        
    except Exception as e:
        logger.exception(f"Error creating assistant builder thread: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router_assistant_builder_threads.get("/threads/{solomon_consumer_key}", response_model=AssistantBuilderThreadsResponse)
async def get_threads(
    solomon_consumer_key: str,
    thread_service: AssistantBuilderThreadService = Depends(AssistantBuilderThreadService)
):
    threads = thread_service.get_threads(solomon_consumer_key)
    return AssistantBuilderThreadsResponse(threads=threads)

@router_assistant_builder_threads.delete("/thread/{thread_id}")
async def delete_thread(
    thread_id: str, 
    thread_service: AssistantBuilderThreadService = Depends(AssistantBuilderThreadService)
):
    success = thread_service.delete_thread(thread_id)
    if not success:
        raise HTTPException(status_code=404, detail="Thread not found")
    return {"message": "Thread deleted successfully"}

@router_assistant_builder_threads.get(
    "/thread/{thread_id}/assistant",
    response_model=AssistantIdResponse,
    summary="Get Assistant ID for Thread"
)
async def get_assistant_id_for_thread(
    thread_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
    thread_service: AssistantBuilderThreadService = Depends(AssistantBuilderThreadService)
):
    """
    Retrieves the Assistant ID associated with a Thread ID.
    
    Parameters:
        thread_id: The ID of the thread
        solomon_consumer_key: The Solomon consumer key for authentication
        
    Returns:
        AssistantIdResponse containing the assistant_id
    """
    try:
        assistant_id = thread_service.get_assistant_id(thread_id, solomon_consumer_key)
        
        if not assistant_id:
            raise HTTPException(
                status_code=404,
                detail="Assistant ID not found for the given thread ID or unauthorized access"
            )
            
        return AssistantIdResponse(assistant_id=assistant_id)
        
    except Exception as e:
        logger.exception(f"Error retrieving assistant ID for thread {thread_id}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )

@router_assistant_builder_threads.get(
    "/assistant-builder/{workspace_name}",
    response_model=AssistantBuilderIdResponse,
    summary="Get Assistant Builder ID for Workspace"
)
async def get_assistant_builder_id_for_workspace(
    workspace_name: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
    thread_service: AssistantBuilderThreadService = Depends(AssistantBuilderThreadService)
):
    """
    Retrieves the Assistant Builder ID for a given workspace name.
    
    Parameters:
        workspace_name: The name of the workspace
        solomon_consumer_key: The Solomon consumer key for authentication
        
    Returns:
        AssistantBuilderIdResponse containing the assistant_builder_id
    """
    try:
        assistant_builder_id = thread_service.get_assistant_builder_id(
            solomon_consumer_key=solomon_consumer_key,
            workspace_name=workspace_name
        )
        
        if not assistant_builder_id:
            raise HTTPException(
                status_code=404,
                detail="Assistant Builder ID not found for the given workspace or unauthorized access"
            )
            
        return AssistantBuilderIdResponse(assistant_builder_id=assistant_builder_id)
        
    except Exception as e:
        logger.exception(f"Error retrieving assistant builder ID for workspace {workspace_name}: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_assistant_builder_threads.py

│   │   ├── router_vector_store_files.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_vector_store_files.py

from fastapi import APIRouter, HTTPException, Query, Header
from models.models_vector_store_files import CreateVectorStoreFileRequest, VectorStoreFileResponse, ListVectorStoreFilesResponse, DeleteVectorStoreFileResponse, CreateVectorStoreFileWorkatoRequest
from services.service_vector_store_files import create_vector_store_file, list_vector_store_files, delete_vector_store_file, retrieve_vector_store_file, create_vector_store_file_workato
from services.service_db import DBService
from typing import Optional
import logging

router_vector_store_files = APIRouter(prefix="/vector_stores", tags=["Vector Store Files V2"])

logger = logging.getLogger(__name__)

@router_vector_store_files.post("/create_vector_store_file/{vector_store_id}/files", response_model=VectorStoreFileResponse, operation_id="create_vector_store_file")
async def create_vector_store_file_endpoint(
    vector_store_id: str, 
    create_vector_store_file_request: CreateVectorStoreFileRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        return create_vector_store_file(vector_store_id, create_vector_store_file_request, openai_api_key)
    except requests.exceptions.HTTPError as errh:
        logger.error(f"HTTP Error: {errh}")
        raise HTTPException(status_code=errh.response.status_code, detail=errh.response.text)
    except Exception as e:
        logger.error(f"Error in create_vector_store_file_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

@router_vector_store_files.get("/list_vector_store_files/{vector_store_id}/files", response_model=ListVectorStoreFilesResponse, operation_id="list_vector_store_files")
async def list_vector_store_files_endpoint(
    vector_store_id: str,
    limit: int = Query(20),
    order: str = Query("desc"),
    after: Optional[str] = Query(None),
    before: Optional[str] = Query(None),
    filter: Optional[str] = Query(None),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        return list_vector_store_files(
            vector_store_id, limit, order, after, before, filter,
            openai_api_key=openai_api_key
        )
    except Exception as e:
        logger.error(f"Error in list_vector_store_files_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

@router_vector_store_files.delete("/delete_vector_store_file/{vector_store_id}/files/{file_id}", response_model=DeleteVectorStoreFileResponse, operation_id="delete_vector_store_file")
async def delete_vector_store_file_endpoint(
    vector_store_id: str, 
    file_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        return delete_vector_store_file(vector_store_id, file_id, openai_api_key)
    except Exception as e:
        logger.error(f"Error in delete_vector_store_file_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

@router_vector_store_files.get("/retrieve_vector_store_file/{vector_store_id}/files/{file_id}", response_model=VectorStoreFileResponse, operation_id="retrieve_vector_store_file")
async def retrieve_vector_store_file_endpoint(
    vector_store_id: str, 
    file_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        return retrieve_vector_store_file(vector_store_id, file_id, openai_api_key)
    except requests.exceptions.HTTPError as errh:
        logger.error(f"HTTP Error: {errh}")
        raise HTTPException(status_code=errh.response.status_code, detail=errh.response.text)
    except Exception as e:
        logger.error(f"Error in retrieve_vector_store_file_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")
    
@router_vector_store_files.post("/create_vector_store_file_workato/{vector_store_id}/files", response_model=VectorStoreFileResponse, operation_id="create_vector_store_file_workato")
async def create_vector_store_file_workato_endpoint(
    vector_store_id: str,
    request: CreateVectorStoreFileWorkatoRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")
            
        return create_vector_store_file_workato(vector_store_id, request, openai_api_key)
    except requests.exceptions.HTTPError as errh:
        logger.error(f"HTTP Error: {errh}")
        raise HTTPException(status_code=errh.response.status_code, detail=errh.response.text)
    except Exception as e:
        logger.error(f"Error in create_vector_store_file_workato_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_vector_store_files.py

│   │   ├── router_runs.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_runs.py

from fastapi import APIRouter, HTTPException, Query, Header
from models.models_runs import CreateThreadRunRequest, RunThreadRequest
from models.models_messages import ListMessagesResponse
from services.service_runs import create_run_and_list_messages, run_thread_and_list_messages
from services.service_db import DBService
import logging
from typing import Optional, List, Dict, Any, Union
from tools import tool_registry
from typing import List, Dict, Any, Union

router_runs = APIRouter(prefix="/runs", tags=["Runs V2"])

logger = logging.getLogger(__name__)

@router_runs.post("/create_thread_and_run", response_model=List[Dict[str, Any]], operation_id="create_thread_and_run")
async def create_thread_and_run_endpoint(
    create_thread_run_request: CreateThreadRunRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        logger.info(f"Received request for assistant_id: {create_thread_run_request.assistant_id}")
        logger.debug(f"Request body: {create_thread_run_request.json()}")
        logger.debug(f"Solomon Consumer Key: {solomon_consumer_key[:4]}...{solomon_consumer_key[-4:]}")  # Log partial key

        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        logger.info(f"Retrieved OpenAI API key: {openai_api_key}")  # Log partial key

        if not create_thread_run_request.tools:
            create_thread_run_request.tools = [
                tool_class().get_definition() for tool_class in tool_registry.values()
            ]
            logger.info(f"Added {len(create_thread_run_request.tools)} tools to the request")

        request_dict = create_thread_run_request.dict()
        logger.debug(f"Converted request to dict: {request_dict}")

        messages_response = create_run_and_list_messages(request_dict, openai_api_key=openai_api_key)
        logger.info("Successfully created run and listed messages")
        
        if isinstance(messages_response, list):
            return messages_response
        elif isinstance(messages_response, dict) and 'data' in messages_response:
            return messages_response['data']
        else:
            raise ValueError("Unexpected response format from create_run_and_list_messages")

    except HTTPException as he:
        logger.error(f"HTTP Exception in create_thread_and_run_endpoint: {str(he)}")
        raise he
    except Exception as e:
        logger.exception(f"Error in create_thread_and_run_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

@router_runs.post("/run_thread_and_list_messages", response_model=Union[List[Dict[str, Any]], Dict[str, Any]], operation_id="run_thread_and_list_messages")
async def run_thread_and_list_messages_endpoint(
    run_thread_request: RunThreadRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        logger.info(f"Received request to run thread {run_thread_request.thread_id} with assistant {run_thread_request.assistant_id}")
        
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        logger.info(f"Retrieved OpenAI API key: {openai_api_key}")  # Log partial key

        messages_response = run_thread_and_list_messages(
            thread_id=run_thread_request.thread_id,
            assistant_id=run_thread_request.assistant_id,
            tools=run_thread_request.tools,
            openai_api_key=openai_api_key
        )
        return messages_response
    except HTTPException as he:
        logger.error(f"HTTP Exception in run_thread_and_list_messages_endpoint: {str(he)}")
        raise he
    except Exception as e:
        logger.exception(f"Error in run_thread_and_list_messages_endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_runs.py

│   │   ├── router_workato.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_workato.py

from fastapi import APIRouter, Header, HTTPException
import requests
import logging
from models.models_workato import WorkatoAssistantBuilderRequest, WorkatoAssistantBuilderResponse

router_workato = APIRouter(prefix="/workato", tags=["Workato Integration"])

logger = logging.getLogger(__name__)

# Hardcoded API token - in production, consider moving this to environment variables or secure secrets management
WORKATO_API_TOKEN = "340a90abdecd4f0584569b180dc4c4326ebda649ca88e731dcaa44d04d30cbeb"
WORKATO_ENDPOINT = "https://apim.workato.com/solconsult/assistant-functions-v1/assistant-builder-functions"

@router_workato.post("/assistant-builder", response_model=WorkatoAssistantBuilderResponse)
async def forward_to_workato(
    request: WorkatoAssistantBuilderRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
    thread_id: str = Header(..., description="Thread ID for the request")
):
    try:
        # Prepare headers for Workato request
        headers = {
            "API-TOKEN": WORKATO_API_TOKEN,
            "Solomon_consumer_key": solomon_consumer_key,
            "Thread_id": thread_id,
            "Content-Type": "application/json"
        }

        # Prepare request body
        payload = {
            "name": request.name,
            "description": request.description,
            "instructions": request.instructions
        }

        # Forward request to Workato
        response = requests.post(
            WORKATO_ENDPOINT,
            headers=headers,
            json=payload
        )

        # Handle response
        if response.status_code == 200:
            return WorkatoAssistantBuilderResponse(
                success=True,
                message="Successfully forwarded request to Workato"
            )
        else:
            logger.error(f"Workato request failed: {response.text}")
            return WorkatoAssistantBuilderResponse(
                success=False,
                message=f"Workato request failed with status code: {response.status_code}"
            )

    except Exception as e:
        logger.error(f"Error forwarding request to Workato: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_workato.py

│   │   ├── router_assistant.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_assistant.py

from fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Query, Path, Header
from fastapi.params import Body
from fastapi.responses import JSONResponse
from models.models_assistants import CreateAssistantRequest, AssistantResponse, ListAssistantsRequest, ListAssistantsResponse, Assistant, ModifyAssistantRequest, DeleteAssistantResponse, CreateAssistantWithToolsRequest
from models.models_assistants import (
    CreateAssistantRequest, 
    ListAssistantsRequest, 
    ListAssistantsResponse, 
    ModifyAssistantRequest, 
    DeleteAssistantResponse,
    CreateAssistantWithToolsRequest,
    AssistantResponse,
)
from services.service_db import DBService
from services.service_assistants import create_assistant_service, list_openai_assistants, modify_openai_assistant, delete_openai_assistant, create_assistant_with_tools, get_openai_assistant
import logging
from typing import Optional
from tools import tool_registry

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router_assistant = APIRouter(prefix="/assistant", tags=["Assistants V2"])

@router_assistant.post("/create_with_tools", response_model=Assistant, operation_id="create_assistant_with_tools")
async def create_assistant_with_tools_endpoint(
    assistant_data: CreateAssistantWithToolsRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        if not assistant_data.tools:
            assistant_data.tools = [
                tool_class().get_definition() for tool_class in tool_registry.values()
            ]
        
        assistant = create_assistant_with_tools(assistant_data, openai_api_key)
        return assistant
    except Exception as e:
        logging.error(f"Error in create_assistant_with_tools_endpoint: {e}")
        raise HTTPException(status_code=500, detail=f"Error creating assistant: {str(e)}")
    
@router_assistant.post("/create_assistant", operation_id="create_assistant", response_model=AssistantResponse)
async def create_assistant(
    assistant: CreateAssistantRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = create_assistant_service(assistant, openai_api_key)
        return AssistantResponse(**response)  
    except Exception as e:
        logging.error(f"Error in create_assistant: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

@router_assistant.get("/list_assistants", response_model=ListAssistantsResponse, operation_id="list_assistants")
async def get_openai_assistants_endpoint(
    limit: Optional[int] = Query(20, description="A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20."),
    order: Optional[str] = Query("desc", description="Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order."),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication"),
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = list_openai_assistants(
            limit=limit,
            order=order,
            openai_api_key=openai_api_key
        )
        
        return ListAssistantsResponse(**response)
    except Exception as e:
        logging.error(f"Error in get_openai_assistants endpoint: {e}")
        return JSONResponse(status_code=500, content={"detail": "Internal Server Error"})
    
@router_assistant.post("/modify_assistant/{assistant_id}", response_model=AssistantResponse)  # Keep as POST
async def modify_assistant(
    assistant_id: str = Path(..., description="The ID of the assistant to modify"),
    request: ModifyAssistantRequest = Body(..., description="The modifications to apply to the assistant"),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
) -> AssistantResponse:
    """
    Modify an existing assistant.
    """
    try:
        # Get OpenAI API key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        # Convert request to dict, maintaining the exact structure OpenAI expects
        modifications = request.dict(exclude_unset=True, exclude_none=True)
        
        logger.info(f"Modifying assistant {assistant_id}")
        logger.debug(f"Modification request: {modifications}")
        
        # Modify the assistant
        response = modify_openai_assistant(
            assistant_id=assistant_id,
            data=modifications,
            openai_api_key=openai_api_key
        )

        return AssistantResponse(**response)

    except HTTPException as he:
        raise he
    except Exception as e:
        logger.error(f"Error in modify_assistant: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    
@router_assistant.delete("/delete_assistant/{assistant_id}", response_model=DeleteAssistantResponse, operation_id="delete_assistant")
async def delete_assistant(
    assistant_id: str = Path(..., description="The ID of the assistant to delete"),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = delete_openai_assistant(assistant_id, openai_api_key=openai_api_key)
        return DeleteAssistantResponse(**response)
    except Exception as e:
        logging.error(f"Error in delete_assistant endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

@router_assistant.get("/{assistant_id}", response_model=AssistantResponse, operation_id="get_assistant")
async def get_assistant(
    assistant_id: str = Path(..., description="The ID of the assistant to retrieve"),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = get_openai_assistant(assistant_id, openai_api_key=openai_api_key)
        return AssistantResponse(**response)
    except Exception as e:
        logging.error(f"Error in get_assistant endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_assistant.py

│   │   ├── router_vector_stores.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_vector_stores.py

from fastapi import APIRouter, HTTPException, Query, Header
from models.models_vector_stores import CreateVectorStoreRequest, VectorStoreResponse, ListVectorStoresResponse, DeleteVectorStoreResponse
from services.service_vector_stores import create_vector_store, list_vector_stores, retrieve_vector_store, delete_vector_store
from services.service_db import DBService
import logging
from typing import Optional

router_vector_stores = APIRouter(prefix="/vector_stores", tags=["Vector Stores"])

logger = logging.getLogger(__name__)

@router_vector_stores.post("/create_vector_store", response_model=VectorStoreResponse, operation_id="create_vector_store")
async def create_vector_store_endpoint(
    create_vector_store_request: CreateVectorStoreRequest,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        # Retrieve the OpenAI API key using the solomon_consumer_key
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = create_vector_store(create_vector_store_request, openai_api_key)
        return response
    except Exception as e:
        logger.error(f"Error in create_vector_store_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

@router_vector_stores.get("/list_vector_stores", response_model=ListVectorStoresResponse, operation_id="list_vector_stores")
async def list_vector_stores_endpoint(
    limit: int = Query(20),
    order: str = Query("desc"),
    after: Optional[str] = Query(None),
    before: Optional[str] = Query(None),
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = list_vector_stores(limit=limit, order=order, after=after, before=before, openai_api_key=openai_api_key)
        return response
    except Exception as e:
        logger.error(f"Error in list_vector_stores_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

@router_vector_stores.get("/retrieve_vector_store/{vector_store_id}", response_model=VectorStoreResponse, operation_id="retrieve_vector_store")
async def retrieve_vector_store_endpoint(
    vector_store_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = retrieve_vector_store(vector_store_id, openai_api_key)
        return response
    except Exception as e:
        logger.error(f"Error in retrieve_vector_store_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")
    
@router_vector_stores.delete("/delete_vector_store/{vector_store_id}", response_model=DeleteVectorStoreResponse, operation_id="delete_vector_store")
async def delete_vector_store_endpoint(
    vector_store_id: str,
    solomon_consumer_key: str = Header(..., description="Solomon Consumer Key for authentication")
):
    try:
        openai_api_key = await DBService.get_openai_api_key(solomon_consumer_key)
        
        if not openai_api_key:
            raise HTTPException(status_code=401, detail="Invalid Solomon Consumer Key")

        response = delete_vector_store(vector_store_id, openai_api_key)
        return response
    except Exception as e:
        logger.error(f"Error in delete_vector_store_endpoint: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/routers/router_vector_stores.py

│   ├── tools
│   │   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/__init__.py

from typing import Dict, Type
from .base import BaseTool
from .weather.current_temperature import CurrentTemperatureTool
from .workato.workato_tool import WorkatoAssistantFunctionTool
from .assistants.create_assistant_tool import CreateAssistantTool
from .assistants.list_assistants_tool import ListAssistantsTool
from .assistants.modify_assistant_tool import ModifyAssistantTool
from .assistants.delete_assistant_tool import DeleteAssistantTool
from .assistants.call_agent_tool import CallAgentTool
from .workato_action_tool.workato_action_tool import WorkatoActionTool

tool_registry: Dict[str, Type[BaseTool]] = {
    "get_current_temperature": CurrentTemperatureTool,
    "send_workato_assistant_request": WorkatoAssistantFunctionTool,
    "create_assistant": CreateAssistantTool,
    "list_assistants": ListAssistantsTool,
    "modify_assistant": ModifyAssistantTool,
    "delete_assistant": DeleteAssistantTool,
    "call_agent": CallAgentTool,
    "execute_workato_action": WorkatoActionTool,
}

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/__init__.py

│   │   ├── base.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/base.py

from abc import ABC, abstractmethod
from typing import Dict, Any

class BaseTool(ABC):
    @abstractmethod
    def execute(self, **kwargs) -> Any:
        pass

    @abstractmethod
    def get_definition(self) -> Dict[str, Any]:
        pass

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/base.py

│   │   ├── assistants
│   │   │   ├── create_assistant_tool.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/create_assistant_tool.py

from typing import Dict, Any
import requests
from .base_assistant import BaseTool

class CreateAssistantTool(BaseTool):
    # Hardcoded API token
    API_TOKEN = '3cb323833ca87933cf00c6cf1b12a25e14acc1309d8ad544b850f17deaac24b5'

    def execute(self, name: str, instructions: str, description: str, solomon_consumer_key: str, thread_id: str) -> Dict[str, Any]:
        """
        Creates a new assistant using the Workato endpoint.

        :param name: The name of the assistant
        :param instructions: The instructions for the assistant
        :param description: The description of the assistant
        :param solomon_consumer_key: User's unique consumer key
        :param thread_id: Thread ID for the request
        :return: The response from the API
        """
        url = 'https://apim.workato.com/solconsult/assistant-functions-v1/assistant-builder-functions'
        
        headers = {
            'solomon-consumer-key': solomon_consumer_key,
            'api-token': self.API_TOKEN,
            'thread_id': thread_id,
            'Content-Type': 'application/json'
        }
        
        data = {
            'name': name,
            'description': description,
            'instructions': instructions
        }
        
        response = requests.post(url, headers=headers, json=data)
        return response.json()

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "create_assistant",
                "description": "Creates a new assistant using the Workato endpoint.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "name": {
                            "type": "string",
                            "description": "The name of the assistant."
                        },
                        "instructions": {
                            "type": "string",
                            "description": "The instructions that define the assistant's behavior."
                        },
                        "description": {
                            "type": "string",
                            "description": "The description of the assistant."
                        },
                        "solomon_consumer_key": {
                            "type": "string",
                            "description": "User's unique consumer key for authentication."
                        },
                        "thread_id": {
                            "type": "string",
                            "description": "Thread ID for the request."
                        }
                    },
                    "required": ["name", "instructions", "description", "solomon_consumer_key", "thread_id"]
                }
            }
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/create_assistant_tool.py

│   │   │   ├── list_assistants_tool.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/list_assistants_tool.py

from typing import Dict, Any
import requests
from .base_assistant import BaseTool

class ListAssistantsTool(BaseTool):
    def execute(self, limit: int = 20, order: str = "desc", solomon_consumer_key: str = None) -> Dict[str, Any]:
        """
        Sends a GET request to list all assistants.

        :param limit: A limit on the number of objects to be returned (between 1 and 100)
        :param order: Sort order by created_at timestamp ('asc' or 'desc')
        :param solomon_consumer_key: User's unique API key for authentication
        :return: The response from the API as a dictionary
        """
        url = f'{self.base_url}/assistant/list_assistants'
        headers = self.get_headers(solomon_consumer_key)
        params = {
            'limit': limit,
            'order': order
        }
        response = requests.get(url, params=params, headers=headers)
        return response.json()

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "list_assistants",
                "description": "Retrieves a list of assistants with pagination support.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "limit": {
                            "type": "integer",
                            "description": "A limit on the number of objects to be returned. Limit can range between 1 and 100.",
                            "default": 20,
                            "minimum": 1,
                            "maximum": 100
                        },
                        "order": {
                            "type": "string",
                            "description": "Sort order by the created_at timestamp of the objects.",
                            "enum": ["asc", "desc"],
                            "default": "desc"
                        },
                        "solomon_consumer_key": {
                            "type": "string",
                            "description": "User's unique API key for authentication."
                        }
                    },
                    "required": ["solomon_consumer_key"]
                }
            }
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/list_assistants_tool.py

│   │   │   ├── modify_assistant_tool.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/modify_assistant_tool.py

from typing import Dict, Any, Optional, List
import requests

class ModifyAssistantTool:
    def execute(self, assistant_id: str, name: Optional[str] = None, 
                description: Optional[str] = None, instructions: Optional[str] = None, 
                model: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None,
                file_ids: Optional[List[str]] = None, tools: Optional[List[Dict[str, Any]]] = None,
                temperature: Optional[float] = None, top_p: Optional[float] = None,
                response_format: Optional[Dict[str, Any]] = None,
                tool_resources: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Sends a POST request to modify an existing assistant.

        :param assistant_id: The ID of the assistant to modify
        :param name: Optional new name for the assistant
        :param description: Optional description of the assistant
        :param instructions: Optional new instructions for the assistant
        :param model: Optional new model for the assistant
        :param metadata: Optional metadata dictionary
        :param file_ids: Optional list of file IDs
        :param tools: Optional list of tools configurations
        :param temperature: Optional sampling temperature
        :param top_p: Optional top_p sampling parameter
        :param response_format: Optional response format configuration
        :param tool_resources: Optional tool resources configuration
        :return: The response from the API as a dictionary
        """
        url = f'https://55gdlc2st8.execute-api.us-east-1.amazonaws.com/assistant/modify_assistant/{assistant_id}'
        headers = {
            'Content-Type': 'application/json'
        }
        
        # Build payload with only non-None values
        payload = {}
        basic_fields = {
            'name': name,
            'description': description,
            'instructions': instructions,
            'model': model,
            'metadata': metadata,
            'file_ids': file_ids,
            'temperature': temperature,
            'top_p': top_p,
            'response_format': response_format
        }
        
        for field, value in basic_fields.items():
            if value is not None:
                payload[field] = value

        # Handle tools separately
        if tools is not None:
            payload['tools'] = tools

        # Handle tool_resources separately
        if tool_resources is not None:
            processed_tool_resources = {}
            
            if 'code_interpreter' in tool_resources:
                processed_tool_resources['code_interpreter'] = {
                    'file_ids': tool_resources['code_interpreter']['file_ids']
                }
                
            if 'file_search' in tool_resources:
                processed_tool_resources['file_search'] = {
                    'vector_store_ids': tool_resources['file_search']['vector_store_ids']
                }
                
            if processed_tool_resources:
                payload['tool_resources'] = processed_tool_resources

        response = requests.post(url, json=payload, headers=headers)
        return response.json()

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "modify_assistant",
                "description": "Modifies an existing assistant's properties.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "assistant_id": {
                            "type": "string",
                            "description": "The ID of the assistant to modify."
                        },
                        "name": {
                            "type": "string",
                            "description": "The new name for the assistant.",
                            "optional": True
                        },
                        "description": {
                            "type": "string",
                            "description": "A description of the assistant.",
                            "optional": True
                        },
                        "instructions": {
                            "type": "string",
                            "description": "The new instructions that define the assistant's behavior.",
                            "optional": True
                        },
                        "model": {
                            "type": "string",
                            "description": "The new model to use for the assistant (e.g., 'gpt-4').",
                            "optional": True
                        },
                        "metadata": {
                            "type": "object",
                            "description": "Metadata in key-value pairs.",
                            "additionalProperties": True,
                            "optional": True
                        },
                        "file_ids": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "List of file IDs attached to the assistant.",
                            "optional": True
                        },
                        "tools": {
                            "type": "array",
                            "items": {"type": "object"},
                            "description": "List of tool configurations.",
                            "optional": True
                        },
                        "temperature": {
                            "type": "number",
                            "description": "Sampling temperature between 0 and 2.",
                            "minimum": 0,
                            "maximum": 2,
                            "optional": True
                        },
                        "top_p": {
                            "type": "number",
                            "description": "Nucleus sampling parameter.",
                            "minimum": 0,
                            "maximum": 1,
                            "optional": True
                        },
                        "response_format": {
                            "type": "object",
                            "description": "Format of the assistant's response.",
                            "optional": True
                        },
                        "tool_resources": {
                            "type": "object",
                            "description": "Configuration for tool resources including code_interpreter and file_search.",
                            "properties": {
                                "code_interpreter": {
                                    "type": "object",
                                    "properties": {
                                        "file_ids": {
                                            "type": "array",
                                            "items": {"type": "string"}
                                        }
                                    }
                                },
                                "file_search": {
                                    "type": "object",
                                    "properties": {
                                        "vector_store_ids": {
                                            "type": "array",
                                            "items": {"type": "string"}
                                        }
                                    }
                                }
                            },
                            "optional": True
                        }
                    },
                    "required": ["assistant_id"]
                }
            }
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/modify_assistant_tool.py

│   │   │   ├── call_agent_tool.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/call_agent_tool.py

from typing import Dict, Any
import requests
from .base_assistant import BaseTool

class CallAgentTool(BaseTool):
    def execute(self, solomon_consumer_key: str, assistant_id: str, content: str) -> Dict[str, Any]:
        """
        Creates a thread and runs it with the specified assistant.

        Args:
            solomon_consumer_key (str): User's unique consumer key for authentication
            assistant_id (str): The ID of the assistant to run
            content (str): The content/message to be processed by the assistant

        Returns:
            Dict[str, Any]: The response from the API containing the thread messages
        """
        url = 'https://55gdlc2st8.execute-api.us-east-1.amazonaws.com/api/v2/runs/create_thread_and_run'
        
        headers = {
            'solomon-consumer-key': solomon_consumer_key,
            'Content-Type': 'application/json'
        }
        
        payload = {
            "assistant_id": assistant_id,
            "thread": {
                "messages": [
                    {
                        "role": "user",
                        "content": content
                    }
                ]
            }
        }
        
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "create_thread_run",
                "description": "Delegates a task to another assistant by creating a new conversation thread. Use this when you need specialized knowledge or capabilities from another assistant. The other assistant will process the provided content and return their response.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "solomon_consumer_key": {
                            "type": "string",
                            "description": "User's unique consumer key for authentication"
                        },
                        "assistant_id": {
                            "type": "string",
                            "description": "The ID of the specialized assistant to consult. Choose this based on the assistant's expertise and capabilities in their description."
                        },
                        "content": {
                            "type": "string",
                            "description": "The specific question, task, or information to be analyzed by the specialized assistant. Include any relevant context or requirements they need to provide an effective response."
                        }
                    },
                    "required": ["solomon_consumer_key", "assistant_id", "content"]
                }
            }
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/call_agent_tool.py

│   │   │   ├── delete_assistant_tool.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/delete_assistant_tool.py

from typing import Dict, Any
import requests

class DeleteAssistantTool:
    def execute(self, assistant_id: str) -> Dict[str, Any]:
        """
        Sends a DELETE request to remove an existing assistant.

        :param assistant_id: The ID of the assistant to delete
        :return: The response from the API as a dictionary
        """
        url = f'https://55gdlc2st8.execute-api.us-east-1.amazonaws.com/assistant/delete_assistant/{assistant_id}'
        headers = {
            'Content-Type': 'application/json'
        }
        
        response = requests.delete(url, headers=headers)
        return response.json()

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "delete_assistant",
                "description": "Deletes an existing assistant by ID.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "assistant_id": {
                            "type": "string",
                            "description": "The ID of the assistant to delete."
                        }
                    },
                    "required": ["assistant_id"]
                }
            }
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/delete_assistant_tool.py

│   │   │   ├── base_assistant.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/base_assistant.py

class BaseTool:
    def __init__(self):
        self.base_url = 'https://55gdlc2st8.execute-api.us-east-1.amazonaws.com/api/v2'

    def get_headers(self, solomon_consumer_key: str) -> dict:
        return {
            'accept': 'application/json',
            'solomon-consumer-key': solomon_consumer_key,
            'Content-Type': 'application/json'
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/assistants/base_assistant.py

│   │   ├── workato
│   │   │   ├── workato_tool.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato/workato_tool.py

from typing import Dict, Any
import requests
import json

class WorkatoAssistantFunctionTool:
    def execute(self, data_type: str, info: str) -> str:
        """
        Sends a POST request to the Workato assistant function endpoint with specified data.

        :param data_type: The value to be sent in the request body under the key 'data_type'.
        :param info: Additional information to be sent with the request.
        :return: The response text as a string.
        """
        url = 'https://apim.workato.com/jayc0/workato_assistant_function'
        headers = {
            'API-TOKEN': 'af1d16385d51a386e715e3867b747a928c048bd3b9c7f03f5bc61aa606368e03',
            'Content-Type': 'application/json'
        }
        data = {'data_type': data_type, 'info': info}
        response = requests.post(url, json=data, headers=headers)
        return response.text

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "send_workato_assistant_request",
                "description": "Sends a POST request to the Workato assistant function endpoint with specified data type and information.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "data_type": {
                            "type": "string",
                            "description": "The type of data being sent (e.g., 'contact', 'failed', etc.)."
                        },
                        "info": {
                            "type": "string",
                            "description": "Additional information to be sent with the request."
                        }
                    },
                    "required": ["data_type", "info"]
                }
            }
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato/workato_tool.py

│   │   │   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato/__init__.py



FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato/__init__.py

│   │   ├── weather
│   │   │   ├── .cache.sqlite
│   │   │   ├── open_meteo_api.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/weather/open_meteo_api.py

# https://open-meteo.com/

import openmeteo_requests

import requests_cache
import pandas as pd
from retry_requests import retry


def get_weather_data(params):
    # Setup the Open-Meteo API client with cache and retry on error
    cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)
    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)
    openmeteo = openmeteo_requests.Client(session = retry_session)

    # Make sure all required weather variables are listed here
    # The order of variables in hourly or daily is important to assign them correctly below
    url = "https://api.open-meteo.com/v1/forecast"
    # params = {
    #   "latitude": 51.4108,
    #   "longitude": -0.6748,
    #   "current": "temperature_2m",
    #   "hourly": "temperature_2m"
    # }
    responses = openmeteo.weather_api(url, params=params)

    # Process first location. Add a for-loop for multiple locations or weather models
    response = responses[0]
    print(f"Coordinates {response.Latitude()}°N {response.Longitude()}°E")
    print(f"Elevation {response.Elevation()} m asl")
    print(f"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}")
    print(f"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s")

    # Current values. The order of variables needs to be the same as requested.
    current = response.Current()
    current_temperature_2m = current.Variables(0).Value()

    print(f"Current time {current.Time()}")
    print(f"Current temperature_2m {current_temperature_2m}")

    # Process hourly data. The order of variables needs to be the same as requested.
    # hourly = response.Hourly()
    # hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()

    # hourly_data = {"date": pd.date_range(
    #   start = pd.to_datetime(hourly.Time(), unit = "s", utc = True),
    #   end = pd.to_datetime(hourly.TimeEnd(), unit = "s", utc = True),
    #   freq = pd.Timedelta(seconds = hourly.Interval()),
    #   inclusive = "left"
    # )}
    # hourly_data["temperature_2m"] = hourly_temperature_2m

    # hourly_dataframe = pd.DataFrame(data = hourly_data)
    # print(hourly_dataframe)

    return current_temperature_2m

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/weather/open_meteo_api.py

│   │   │   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/weather/__init__.py



FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/weather/__init__.py

│   │   │   ├── current_temperature.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/weather/current_temperature.py

from typing import Dict, Any
from .open_meteo_api import get_weather_data

class CurrentTemperatureTool:  # Remove the inheritance from BaseTool for now
    def execute(self, latitude: str, longitude: str, unit: str) -> float:
        params = {
            "latitude": float(latitude),
            "longitude": float(longitude),
            "current": "temperature_2m"
        }
        temperature = get_weather_data(params)
        
        # The API returns temperature in Celsius by default
        if unit.lower() == "fahrenheit":
            temperature = (temperature * 9/5) + 32
        
        return round(temperature, 2)

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "get_current_temperature",
                "description": "Get the current temperature for a specific location",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "latitude": {
                            "type": "string",
                            "description": "The latitude of the location."
                        },
                        "longitude": {
                            "type": "string",
                            "description": "The longitude of the location."
                        },
                        "unit": {
                            "type": "string",
                            "enum": ["Celsius", "Fahrenheit"],
                            "description": "The temperature unit to use."
                        }
                    },
                    "required": ["latitude", "longitude", "unit"]
                }
            }
        }

# # Add this at the end of the file for testing
# if __name__ == "__main__":
#     tool = CurrentTemperatureTool()
    
#     # Test for New York City
#     latitude = "40.7128"
#     longitude = "-74.0060"
    
#     # Test in Celsius
#     result_celsius = tool.execute(latitude, longitude, "Celsius")
#     print(f"Current temperature in New York City (Celsius): {result_celsius}°C")
    
#     # Test in Fahrenheit
#     result_fahrenheit = tool.execute(latitude, longitude, "Fahrenheit")
#     print(f"Current temperature in New York City (Fahrenheit): {result_fahrenheit}°F")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/weather/current_temperature.py

│   │   ├── workato_action_tool
│   │   │   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato_action_tool/__init__.py



FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato_action_tool/__init__.py

│   │   │   ├── workato_action_tool.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato_action_tool/workato_action_tool.py

from typing import Dict, Any, Optional
import requests
import json

class WorkatoActionTool:
    def execute(self, action_type: str, schema: Optional[Dict[str, Any]] = None, parameters: Optional[Dict[str, Any]] = None) -> str:
        """
        Sends a POST request to the Workato action endpoint with specified action type, parameters, and schema.

        :param action_type: The specific task to execute (e.g., 'query_db', 'send_email', etc.).
        :param schema: Optional dictionary containing the schema to be used for the action.
        :param parameters: Optional dictionary containing necessary parameters for the requested action.
        :return: The response text as a string.
        """
        url = 'https://apim.workato.com/solconsult/assistant-tools-v1/workato-root-tool'
        headers = {
            'API-TOKEN': '0c95440824af817055b784c1e87bd31e36f21066df49f4d863e574cbf6e3b4d6',
            'Content-Type': 'application/json'
        }
        data = {
            'action_type': action_type,
            'parameters': parameters or {},
            'schema': schema or {}
        }
        response = requests.post(url, json=data, headers=headers)
        return response.text

    def get_definition(self) -> Dict[str, Any]:
        return {
            "type": "function",
            "function": {
                "name": "execute_workato_action",
                "description": "Routes requests to Workato for execution, enabling limitless automation, computations, and data retrieval.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "action_type": {
                            "type": "string",
                            "description": "The specific task to execute (e.g., 'query_db', 'send_email', 'process_file', 'trigger_rpa')."
                        },
                        "parameters": {
                            "type": "object",
                            "description": "A flexible payload containing necessary parameters for the requested action."
                        },
                        "schema": {
                            "type": "object",
                            "description": "The schema to be used for the action."
                        }
                    },
                    "required": ["action_type"] 
                }
            }
        }

FILE NAME /Users/rossdickinson/SolomonAssistants/app/tools/workato_action_tool/workato_action_tool.py

│   ├── models
│   │   ├── models_teams.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_teams.py

from pydantic import BaseModel
from typing import Optional, List

class TeamMemberCreate(BaseModel):
    callable_assistant_id: str
    callable_assistant_reason: Optional[str] = None

class TeamCallableAssistant(BaseModel):
    callable_assistant_id: str
    callable_assistant_reason: Optional[str] = None

class TeamCallableAssistantsResponse(BaseModel):
    callable_assistants: List[TeamCallableAssistant]

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_teams.py

│   │   ├── models_workato.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_workato.py

from pydantic import BaseModel

class WorkatoAssistantBuilderRequest(BaseModel):
    name: str
    description: str
    instructions: str
    
class WorkatoAssistantBuilderResponse(BaseModel):
    success: bool
    message: str

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_workato.py

│   │   ├── models_o1.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_o1.py

# models/models_o1.py
from pydantic import BaseModel

class O1Request(BaseModel):
    prompt: str

class O1Response(BaseModel):
    completion: str


FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_o1.py

│   │   ├── models_vector_stores.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_vector_stores.py

from typing import List, Optional, Dict
from pydantic import BaseModel

class CreateVectorStoreRequest(BaseModel):
    file_ids: Optional[List[str]] = None
    name: Optional[str] = None
    expires_after: Optional[Dict[str, int]] = None
    metadata: Optional[Dict[str, str]] = None

class FileCounts(BaseModel):
    in_progress: int
    completed: int
    failed: int
    cancelled: int
    total: int

class VectorStoreResponse(BaseModel):
    id: str
    object: str
    created_at: int
    name: Optional[str] = None
    usage_bytes: Optional[int] = None
    status: str
    expires_at: Optional[int] = None
    last_active_at: Optional[int] = None
    file_counts: FileCounts
    metadata: Optional[Dict[str, str]] = None

class ListVectorStoresResponse(BaseModel):
    object: str
    data: List[VectorStoreResponse]
    first_id: Optional[str] = None
    last_id: Optional[str] = None
    has_more: bool

class DeleteVectorStoreResponse(BaseModel):
    id: str
    object: str
    deleted: bool

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_vector_stores.py

│   │   ├── models_files.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_files.py

from pydantic import BaseModel
from typing import Optional, List

class UploadFileRequest(BaseModel):
    purpose: str = "assistants"  # Default value set to "assistants"

class FileResponse(BaseModel):
    id: str
    object: str
    bytes: int
    created_at: int
    filename: str
    purpose: str

class UploadFileResponse(BaseModel):
    id: str
    object: str
    bytes: int
    created_at: int
    filename: str
    purpose: str

class ListFilesResponse(BaseModel):
    data: List[UploadFileResponse]
    object: str

class FileContentUploadRequest(BaseModel):
    content: str
    file_name: str
    file_type: str
    purpose: str = "assistants"

class FileContentUploadResponse(BaseModel):
    id: str
    object: str
    bytes: int
    created_at: int
    filename: str
    purpose: str


FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_files.py

│   │   ├── models_auth.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_auth.py

# models/models_auth.py
from pydantic import BaseModel
from typing import Optional

class UserSignUp(BaseModel):
    email: str
    password: str
    name: str

class UserSignIn(BaseModel):
    email: str
    password: str

class TokenResponse(BaseModel):
    access_token: str
    id_token: str
    refresh_token: str

class UserResponse(BaseModel):
    id: str
    email: str
    name: str
    solomon_consumer_key: Optional[str] = None

class VerificationRequest(BaseModel):
    email: str
    code: str

class SolomonConsumerKeyUpdate(BaseModel):
    solomon_consumer_key: str

class WorkspacesResponse(BaseModel):
    workspace_names: list[str]

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_auth.py

│   │   ├── models_messages.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_messages.py

from typing import List, Optional, Dict, Any
from pydantic import BaseModel

class TextContent(BaseModel):
    value: str
    annotations: List[Any]

class Content(BaseModel):
    type: str
    text: TextContent

class IncompleteDetails(BaseModel):
    reason: str

class Message(BaseModel):
    id: str
    object: str
    created_at: int
    thread_id: str
    status: Optional[str] = None
    incomplete_details: Optional[IncompleteDetails] = None
    completed_at: Optional[int] = None
    incomplete_at: Optional[int] = None
    role: str
    content: List[Content]
    assistant_id: Optional[str] = None
    run_id: Optional[str] = None
    attachments: Optional[List[Any]] = None
    metadata: Dict[str, Any]

class ListMessagesResponse(BaseModel):
    object: str
    data: List[Message]
    first_id: Optional[str] = None
    last_id: Optional[str] = None
    has_more: bool

class CreateMessageRequest(BaseModel):
    role: str
    content: str
    attachments: Optional[List[Any]] = None
    metadata: Optional[Dict[str, Any]] = None

class CreateMessageResponse(BaseModel):
    id: str
    object: str
    created_at: int
    thread_id: str
    role: str
    content: List[Content]
    attachments: Optional[List[Any]] = None
    metadata: Dict[str, Any]

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_messages.py

│   │   ├── models_assistants.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_assistants.py

from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Union
from datetime import datetime

class Tool(BaseModel):
    type: str = Field(..., description="The type of the tool")

# Create assistants models
class CreateAssistantRequest(BaseModel):
    model: str
    name: Optional[str] = None
    description: Optional[str] = None
    instructions: Optional[str] = None
    tools: Optional[List[Tool]] = None
    metadata: Optional[dict] = None
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    response_format: Optional[Union[str, dict]] = None

class AssistantResponse(BaseModel):
    id: str
    object: str = Field(..., description="The object type, which is always 'assistant'")
    created_at: int
    name: Optional[str] = None
    description: Optional[str] = None
    model: str
    instructions: Optional[str] = None
    tools: List[Tool]
    metadata: dict = Field(default_factory=dict)
    top_p: Optional[float] = None
    temperature: Optional[float] = None
    response_format: Optional[Union[str, dict]] = None

# List assistants models
class Assistant(BaseModel):
    id: str
    object: str = Field("assistant", description="The object type, which is always 'assistant'")
    created_at: int
    name: Optional[str] = None
    description: Optional[str] = None
    model: str
    instructions: Optional[str] = None
    tools: List[Tool] = Field(default_factory=list)
    tool_resources: Dict[str, Any] = Field(default_factory=dict)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    top_p: Optional[float] = None
    temperature: Optional[float] = None
    response_format: Optional[Union[str, dict]] = None

class ListAssistantsRequest(BaseModel):
    limit: Optional[int] = Field(20, description="A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.")
    order: Optional[str] = Field("desc", description="Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.")
    # after: Optional[str] = Field(None, description="A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.")
    # before: Optional[str] = Field(None, description="A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.")

class ListAssistantsResponse(BaseModel):
    object: str = Field("list", description="The object type, which is always 'list'")
    data: List[Assistant]
    first_id: str
    last_id: str
    has_more: bool

# Modify assistant models
class FileSearchResource(BaseModel):
    vector_store_ids: List[str]

class CodeInterpreterResource(BaseModel):
    file_ids: Optional[List[str]] = None

class ToolResources(BaseModel):
    file_search: Optional[FileSearchResource] = None
    code_interpreter: Optional[CodeInterpreterResource] = None

class ModifyAssistantRequest(BaseModel):
    name: Optional[str] = None
    description: Optional[str] = None
    instructions: Optional[str] = None
    tools: Optional[List[Tool]] = None
    tool_resources: Optional[ToolResources] = None
    model: Optional[str] = None
    file_ids: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None
    temperature: Optional[float] = Field(None, ge=0, le=2)
    top_p: Optional[float] = Field(None, ge=0, le=1)
    response_format: Optional[Dict[str, str]] = None
    
class AssistantResponse(BaseModel):
    id: str = Field(..., description="The ID of the assistant")
    object: str = Field("assistant", description="The object type, which is always 'assistant'")
    created_at: int = Field(..., description="The Unix timestamp (in seconds) for when the assistant was created")
    name: Optional[str] = Field(None, description="The name of the assistant")
    description: Optional[str] = Field(None, description="The description of the assistant")
    model: str = Field(..., description="ID of the model used by the assistant")
    instructions: Optional[str] = Field(None, description="The system instructions that the assistant uses")
    tools: List[Tool] = Field(default_factory=list, description="A list of tools enabled on the assistant")
    tool_resources: Optional[ToolResources] = Field(None, description="A set of resources that are used by the assistant's tools")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Metadata associated with the assistant")
    top_p: Optional[float] = Field(None, description="The top_p value used for nucleus sampling")
    temperature: Optional[float] = Field(None, description="The temperature used for sampling")
    response_format: Optional[Union[str, Dict[str, Any]]] = Field(None, description="The format of the response")

# Delete assistant models
class DeleteAssistantResponse(BaseModel):
    id: str = Field(..., description="The ID of the deleted assistant")
    object: str = Field(..., description="The object type, which is 'assistant.deleted'")
    deleted: bool = Field(..., description="Indicates whether the assistant was successfully deleted")

class ToolDefinition(BaseModel):
    type: str
    function: Dict[str, Any]

class CreateAssistantWithToolsRequest(BaseModel):
    model: str = "gpt-4o"
    name: Optional[str] = Field(None, description="The name of the assistant")
    description: Optional[str] = Field(None, description="The description of the assistant")
    instructions: Optional[str] = Field(None, description="The system instructions that the assistant uses")
    tools: List[ToolDefinition] = Field(default_factory=list, description="A list of tools enabled on the assistant")
    file_ids: Optional[List[str]] = Field(default_factory=list, description="A list of file IDs attached to the assistant")
    metadata: Optional[Dict[str, str]] = Field(None, description="Set of key-value pairs that can be attached to an object")

class ListAssistantsResponse(BaseModel):
    object: str
    data: List[Assistant]
    first_id: str
    last_id: str
    has_more: bool

# Modify assistants models
class ModifyAssistantRequest(BaseModel):
    model: Optional[str] = None
    name: Optional[str] = None
    description: Optional[str] = None
    instructions: Optional[str] = None
    tools: Optional[List[Union[str, Dict[str, Any]]]] = None
    tool_resources: Optional[Dict[str, Any]] = None
    metadata: Optional[Dict[str, Union[str, int]]] = None
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    response_format: Optional[Union[str, Dict[str, str]]] = None
    
class DeleteAssistantResponse(BaseModel):
    id: str
    object: str
    deleted: bool
    
class UpdateAssistantRequest(BaseModel):
    assistant_id: str
    name: Optional[str] = None
    instructions: Optional[str] = None
    model: Optional[str] = None
    tools: Optional[List[str]] = None

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_assistants.py

│   │   ├── models_runs.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_runs.py

from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field

class Message(BaseModel):
    role: str = "user"
    content: str

class Thread(BaseModel):
    messages: List[Message]

class Tool(BaseModel):
    type: str

class TruncationStrategy(BaseModel):
    type: str
    last_messages: Optional[Any]

class Usage(BaseModel):
    prompt_tokens: Optional[int]
    completion_tokens: Optional[int]
    total_tokens: Optional[int]

class RunResponse(BaseModel):
    id: str
    object: str
    created_at: int
    assistant_id: str
    thread_id: str
    status: str
    required_action: Optional[Any]
    last_error: Optional[Any]
    expires_at: Optional[int]
    started_at: Optional[int]
    cancelled_at: Optional[int]
    failed_at: Optional[int]
    completed_at: Optional[int]
    incomplete_details: Optional[Any]
    model: str
    instructions: Optional[str]
    tools: List[Tool]
    metadata: Dict[str, Any]
    usage: Optional[Usage]
    temperature: Optional[float]
    top_p: Optional[float]
    max_prompt_tokens: Optional[int]
    max_completion_tokens: Optional[int]
    truncation_strategy: Optional[TruncationStrategy]
    response_format: Optional[str]
    tool_choice: Optional[Any]

class ToolDefinition(BaseModel):
    type: str
    function: Dict[str, Any] = Field(default_factory=dict)

    @classmethod
    def __get_validators__(cls):
        yield cls.validate

    @classmethod
    def validate(cls, v):
        if isinstance(v, dict):
            return cls(**v)
        return v

class CreateThreadRunRequest(BaseModel):
    assistant_id: str
    thread: Thread
    tools: Optional[List[dict]] = None

class RunThreadRequest(BaseModel):
    thread_id: str
    assistant_id: str
    tools: Optional[List[Dict[str, Any]]] = None

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_runs.py

│   │   ├── models_vector_store_files.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_vector_store_files.py

from typing import Optional
from pydantic import BaseModel
from typing import List
from enum import Enum

class CreateVectorStoreFileRequest(BaseModel):
    file_id: str

class VectorStoreFileResponse(BaseModel):
    id: str
    object: str
    created_at: int
    usage_bytes: int
    vector_store_id: str
    status: str
    last_error: Optional[str] = None

class ListVectorStoreFilesResponse(BaseModel):
    object: str
    data: List[VectorStoreFileResponse]
    first_id: str
    last_id: str
    has_more: bool
    
class DeleteVectorStoreFileResponse(BaseModel):
    id: str
    object: str
    deleted: bool

class FileType(str, Enum):
    TXT = "txt"
    CSV = "csv"
    JSON = "json"
    JSONL = "jsonl"
    PDF = "pdf"

class CreateVectorStoreFileWorkatoRequest(BaseModel):
    content: str
    file_name: str
    file_type: FileType

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_vector_store_files.py

│   │   ├── models_threads.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_threads.py

from pydantic import BaseModel
from typing import Optional, Dict, Any, List

class Thread(BaseModel):
    thread_id: str
    thread_name: Optional[str] = None

class ThreadsResponse(BaseModel):
    threads: list[Thread]

class CreateThreadRequest(BaseModel):
    messages: Optional[list] = None
    tool_resources: Optional[Dict[str, Any]] = None
    metadata: Optional[Dict[str, Any]] = None

class ThreadResponse(BaseModel):
    id: str
    object: str
    created_at: int
    metadata: Dict[str, Any]
    tool_resources: Dict[str, Any]

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_threads.py

│   │   ├── models_assistant_builder_threads.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_assistant_builder_threads.py

from pydantic import BaseModel
from typing import Optional

class AssistantBuilderThread(BaseModel):
    thread_id: str
    thread_name: str

class AssistantBuilderThreadCreate(BaseModel):
    solomon_consumer_key: str
    thread_id: str
    thread_name: str

class AssistantBuilderThreadsResponse(BaseModel):
    threads: list[AssistantBuilderThread]

class AssistantBuilderThreadsResponse(BaseModel):
    threads: list[AssistantBuilderThread]
    
class AssistantIdResponse(BaseModel):
    assistant_id: str

class AssistantBuilderIdResponse(BaseModel):
    assistant_builder_id: str

FILE NAME /Users/rossdickinson/SolomonAssistants/app/models/models_assistant_builder_threads.py

│   ├── api
│   │   ├── websocket_server.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/api/websocket_server.py

# Remove any imports like:
# from app.services.agent_services.direct_bridge import DirectAssistantBridge
# Remove any code that uses the DirectAssistantBridge class 

# Replace any code that might be choosing between bridges:
# bridge = DirectAssistantBridge(...) if use_direct_api else AssistantBridge(...)
# With:
bridge = AssistantBridge(...) 

import asyncio
import json
import logging
import uuid
from typing import Dict, List, Optional, Any

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# Import your existing services
from app.services.assistant_bridge import AssistantBridge
from app.services.workato_integration import WorkatoConfig

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Standard Workato configuration (you might want to load this from environment variables)
WORKATO_CONFIG = WorkatoConfig(
    api_token="ad19767e318455a1daa7635b3e5f3ce4055f11376155b45c506ceb4f4f739d1c",
    endpoint_url="https://apim.workato.com/solconsult/assistant-tools-v1/workato-root-tool"
)

# Create FastAPI app
app = FastAPI(title="OpenAI Agents WebSocket API")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # For production, specify actual origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Models for connection parameters
class ConnectionParams(BaseModel):
    api_key: str
    assistant_id: str
    vector_store_ids: Optional[List[str]] = None

# Store active connections
active_connections: Dict[str, AssistantBridge] = {}

# Authentication dependency
async def get_api_key(x_api_key: str = Header(None)):
    if not x_api_key:
        raise HTTPException(status_code=401, detail="API key is required")
    # In production, you would validate the API key against your database
    return x_api_key

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time chat with the assistant."""
    await websocket.accept()
    connection_id = str(uuid.uuid4())
    
    try:
        # Wait for connection parameters
        logger.info(f"New connection {connection_id} established, waiting for parameters")
        params_json = await websocket.receive_text()
        params = json.loads(params_json)
        
        # Validate required parameters
        if not params.get("api_key") or not params.get("assistant_id"):
            await websocket.send_json({
                "type": "error",
                "error": "Missing required parameters: api_key and assistant_id are required"
            })
            await websocket.close()
            return
        
        # Initialize the assistant bridge
        logger.info(f"Initializing AssistantBridge for connection {connection_id}")
        api_key = params.get("api_key")
        assistant_id = params.get("assistant_id")
        vector_store_ids = params.get("vector_store_ids")
        
        try:
            bridge = AssistantBridge(
                api_key=api_key,
                assistant_id=assistant_id,
                vector_store_ids=vector_store_ids
            )
            await bridge.initialize(workato_config=WORKATO_CONFIG)
            
            # Store the bridge instance
            active_connections[connection_id] = bridge
            
            # Notify client that the assistant is ready
            await websocket.send_json({
                "type": "ready",
                "message": "Assistant initialized successfully"
            })
            
            # Process messages
            while True:
                # Wait for a message from the client
                message_json = await websocket.receive_text()
                message_data = json.loads(message_json)
                
                # Process commands
                if message_data.get("type") == "command":
                    command = message_data.get("command")
                    
                    if command == "clear_history":
                        bridge.clear_history()
                        await websocket.send_json({
                            "type": "system",
                            "message": "Conversation history cleared"
                        })
                        continue
                    
                    elif command == "get_history":
                        history = bridge.get_conversation_history()
                        await websocket.send_json({
                            "type": "history",
                            "history": history
                        })
                        continue
                
                # Process chat messages
                if message_data.get("type") == "message":
                    user_input = message_data.get("content", "")
                    if not user_input.strip():
                        continue
                    
                    # Send acknowledgment
                    await websocket.send_json({
                        "type": "system",
                        "message": "Processing your message..."
                    })
                    
                    # Handle streaming response
                    if message_data.get("stream", True):
                        try:
                            # Send response in chunks
                            tool_used = False
                            full_response = ""
                            
                            async for chunk, event_type in bridge.chat_streaming(user_input):
                                if event_type == "raw_response" or event_type == "message":
                                    # Text content
                                    await websocket.send_json({
                                        "type": "stream",
                                        "content": chunk,
                                        "event_type": event_type
                                    })
                                    full_response += chunk
                                elif event_type == "tool_call":
                                    # Tool call event
                                    tool_used = True
                                    await websocket.send_json({
                                        "type": "tool",
                                        "tool": "call",
                                        "name": chunk
                                    })
                                elif event_type == "tool_output":
                                    # Tool output event
                                    await websocket.send_json({
                                        "type": "tool",
                                        "tool": "output",
                                        "content": chunk
                                    })
                            
                            # Send completion message
                            await websocket.send_json({
                                "type": "completion",
                                "content": full_response,
                                "tool_used": tool_used
                            })
                            
                        except Exception as e:
                            logger.error(f"Error during streaming: {str(e)}")
                            await websocket.send_json({
                                "type": "error",
                                "error": f"Error during response streaming: {str(e)}"
                            })
                    else:
                        # Handle non-streaming response
                        try:
                            response = await bridge.chat(user_input)
                            await websocket.send_json({
                                "type": "response",
                                "content": response
                            })
                        except Exception as e:
                            logger.error(f"Error during chat: {str(e)}")
                            await websocket.send_json({
                                "type": "error",
                                "error": f"Error during chat: {str(e)}"
                            })
                
        except Exception as e:
            logger.error(f"Error initializing bridge: {str(e)}")
            await websocket.send_json({
                "type": "error",
                "error": f"Error initializing assistant: {str(e)}"
            })
            await websocket.close()
            return
    
    except WebSocketDisconnect:
        logger.info(f"Client disconnected: {connection_id}")
        # Clean up resources
        if connection_id in active_connections:
            del active_connections[connection_id]
    
    except Exception as e:
        logger.error(f"Error in WebSocket connection: {str(e)}")
        try:
            await websocket.send_json({
                "type": "error",
                "error": f"Unexpected error: {str(e)}"
            })
        except:
            pass
        
        # Clean up resources
        if connection_id in active_connections:
            del active_connections[connection_id]

@app.on_event("shutdown")
async def shutdown_event():
    """Clean up resources on application shutdown."""
    logger.info("Application shutting down, cleaning up resources")
    active_connections.clear() 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/api/websocket_server.py

│   │   ├── websocket
│   │   │   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/api/websocket/__init__.py

"""
WebSocket server for real-time communication with OpenAI Agents.
""" 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/api/websocket/__init__.py

│   │   │   ├── websocket_server.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/api/websocket/websocket_server.py

import asyncio
import json
import logging
import uuid
from typing import Dict, List, Optional, Any

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# Import the AssistantBridge instead of DirectAssistantBridge
from app.services.assistant_bridge import AssistantBridge
from app.services.workato_integration import WorkatoConfig

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Standard Workato configuration (you might want to load this from environment variables)
WORKATO_CONFIG = WorkatoConfig(
    api_token="ad19767e318455a1daa7635b3e5f3ce4055f11376155b45c506ceb4f4f739d1c",
    endpoint_url="https://apim.workato.com/solconsult/assistant-tools-v1/workato-root-tool"
)

# Create FastAPI app
app = FastAPI(title="OpenAI Agents WebSocket API")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # For production, specify actual origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Store active connections
active_connections: Dict[str, AssistantBridge] = {}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time chat with the assistant."""
    await websocket.accept()
    connection_id = str(uuid.uuid4())
    
    try:
        # Wait for connection parameters
        logger.info(f"New connection {connection_id} established, waiting for parameters")
        params_json = await websocket.receive_text()
        params = json.loads(params_json)
        
        # Validate required parameters
        if not params.get("api_key") or not params.get("assistant_id"):
            await websocket.send_json({
                "type": "error",
                "error": "Missing required parameters: api_key and assistant_id are required"
            })
            await websocket.close()
            return
        
        # Initialize the assistant bridge
        logger.info(f"Initializing AssistantBridge for connection {connection_id}")
        api_key = params.get("api_key")
        assistant_id = params.get("assistant_id")
        vector_store_ids = params.get("vector_store_ids")
        
        try:
            bridge = AssistantBridge(
                api_key=api_key,
                assistant_id=assistant_id,
                vector_store_ids=vector_store_ids
            )
            await bridge.initialize(workato_config=WORKATO_CONFIG)
            
            # Store the bridge instance
            active_connections[connection_id] = bridge
            
            # Notify client that the assistant is ready
            await websocket.send_json({
                "type": "ready",
                "message": "Assistant initialized successfully"
            })
            
            # Process messages
            while True:
                # Wait for a message from the client
                message_json = await websocket.receive_text()
                message_data = json.loads(message_json)
                
                # Process commands
                if message_data.get("type") == "command":
                    command = message_data.get("command")
                    
                    if command == "clear_history":
                        bridge.clear_history()
                        await websocket.send_json({
                            "type": "system",
                            "message": "Conversation history cleared"
                        })
                        continue
                    
                    elif command == "get_history":
                        history = bridge.get_conversation_history()
                        await websocket.send_json({
                            "type": "history",
                            "history": history
                        })
                        continue
                
                # Process chat messages
                if message_data.get("type") == "message":
                    user_input = message_data.get("content", "")
                    if not user_input.strip():
                        continue
                    
                    # Send acknowledgment
                    await websocket.send_json({
                        "type": "system",
                        "message": "Processing your message..."
                    })
                    
                    # Handle streaming response
                    if message_data.get("stream", True):
                        try:
                            # Send response in chunks
                            tool_used = False
                            full_response = ""
                            
                            async for chunk, event_type in bridge.chat_streaming(user_input):
                                if event_type == "raw_response" or event_type == "message":
                                    # Text content
                                    await websocket.send_json({
                                        "type": "stream",
                                        "content": chunk,
                                        "event_type": event_type
                                    })
                                    full_response += chunk
                                elif event_type == "tool_call":
                                    # Tool call event
                                    tool_used = True
                                    await websocket.send_json({
                                        "type": "tool",
                                        "tool": "call",
                                        "name": chunk
                                    })
                                elif event_type == "tool_output":
                                    # Tool output event
                                    await websocket.send_json({
                                        "type": "tool",
                                        "tool": "output",
                                        "content": chunk
                                    })
                            
                            # Send completion message
                            await websocket.send_json({
                                "type": "completion",
                                "content": full_response,
                                "tool_used": tool_used
                            })
                            
                        except Exception as e:
                            logger.error(f"Error during streaming: {str(e)}")
                            await websocket.send_json({
                                "type": "error",
                                "error": f"Error during response streaming: {str(e)}"
                            })
                    else:
                        # Handle non-streaming response
                        try:
                            response = await bridge.chat(user_input)
                            await websocket.send_json({
                                "type": "response",
                                "content": response
                            })
                        except Exception as e:
                            logger.error(f"Error during chat: {str(e)}")
                            await websocket.send_json({
                                "type": "error",
                                "error": f"Error during chat: {str(e)}"
                            })
                
        except Exception as e:
            logger.error(f"Error initializing bridge: {str(e)}")
            await websocket.send_json({
                "type": "error",
                "error": f"Error initializing assistant: {str(e)}"
            })
            await websocket.close()
            return
    
    except WebSocketDisconnect:
        logger.info(f"Client disconnected: {connection_id}")
        # Clean up resources
        if connection_id in active_connections:
            del active_connections[connection_id]
    
    except Exception as e:
        logger.error(f"Error in WebSocket connection: {str(e)}")
        try:
            await websocket.send_json({
                "type": "error",
                "error": f"Unexpected error: {str(e)}"
            })
        except:
            pass
        
        # Clean up resources
        if connection_id in active_connections:
            del active_connections[connection_id]

@app.on_event("shutdown")
async def shutdown_event():
    """Clean up resources on application shutdown."""
    logger.info("Application shutting down, cleaning up resources")
    active_connections.clear() 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/api/websocket/websocket_server.py

│   ├── services
│   │   ├── service_auth.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_auth.py

# services/service_auth.py
import os
import boto3
import hmac
import base64
import hashlib
import jwt
import requests
from botocore.exceptions import ClientError
from models.models_auth import UserSignUp, UserSignIn, TokenResponse, UserResponse, VerificationRequest

class CognitoService:
    def __init__(self):
        self.client = boto3.client('cognito-idp', region_name=os.getenv('AWS_REGION'))
        self.user_pool_id = os.getenv('COGNITO_USER_POOL_ID')
        self.client_id = os.getenv('COGNITO_APP_CLIENT_ID')
        self.client_secret = os.getenv('COGNITO_APP_CLIENT_SECRET')

    def get_secret_hash(self, username):
        msg = username + self.client_id
        dig = hmac.new(str(self.client_secret).encode('utf-8'),
                       msg=str(msg).encode('utf-8'),
                       digestmod=hashlib.sha256).digest()
        return base64.b64encode(dig).decode()

    async def sign_up(self, user: UserSignUp) -> UserResponse:
        try:
            response = self.client.sign_up(
                ClientId=self.client_id,
                Username=user.email,
                Password=user.password,
                UserAttributes=[
                    {'Name': 'name', 'Value': user.name},
                    {'Name': 'email', 'Value': user.email},
                ],
                SecretHash=self.get_secret_hash(user.email)
            )
            return UserResponse(
                id=response['UserSub'],
                email=user.email,
                name=user.name,
            )
        except ClientError as e:
            raise Exception(f"Error signing up user: {str(e)}")

    async def sign_in(self, user: UserSignIn) -> TokenResponse:
        try:
            response = self.client.initiate_auth(
                ClientId=self.client_id,
                AuthFlow='USER_PASSWORD_AUTH',
                AuthParameters={
                    'USERNAME': user.email,
                    'PASSWORD': user.password,
                    'SECRET_HASH': self.get_secret_hash(user.email)
                }
            )
            auth_result = response['AuthenticationResult']
            return TokenResponse(
                access_token=auth_result['AccessToken'],
                id_token=auth_result['IdToken'],
                refresh_token=auth_result['RefreshToken']
            )
        except self.client.exceptions.NotAuthorizedException:
            raise Exception("Incorrect username or password")
        except self.client.exceptions.UserNotFoundException:
            raise Exception("User does not exist")
        except ClientError as e:
            raise Exception(f"Error signing in user: {str(e)}")

    async def get_user(self, access_token: str) -> UserResponse:
        try:
            response = self.client.get_user(AccessToken=access_token)
            user_attrs = {attr['Name']: attr['Value'] for attr in response['UserAttributes']}
            return UserResponse(
                id=response['Username'],
                email=user_attrs.get('email'),
                name=user_attrs.get('name'),
                solomon_consumer_key=user_attrs.get('custom:solomon_consumer_key')
            )
        except self.client.exceptions.NotAuthorizedException:
            raise Exception("Invalid or expired token")
        except ClientError as e:
            raise Exception(f"Error getting user details: {str(e)}")
        
    async def attach_solomon_consumer_key(self, username: str, solomon_consumer_key: str) -> bool:
        try:
            self.client.admin_update_user_attributes(
                UserPoolId=self.user_pool_id,
                Username=username,
                UserAttributes=[
                    {'Name': 'custom:solomon_consumer_key', 'Value': solomon_consumer_key},
                ]
            )
            return True
        except ClientError as e:
            raise Exception(f"Error attaching Solomon consumer key: {str(e)}")

    async def change_solomon_consumer_key(self, username: str, new_solomon_consumer_key: str) -> bool:
        return await self.attach_solomon_consumer_key(username, new_solomon_consumer_key)

    async def get_solomon_consumer_key(self, username: str) -> str:
        try:
            response = self.client.admin_get_user(
                UserPoolId=self.user_pool_id,
                Username=username
            )
            user_attrs = {attr['Name']: attr['Value'] for attr in response['UserAttributes']}
            return user_attrs.get('custom:solomon_consumer_key')
        except ClientError as e:
            raise Exception(f"Error getting Solomon consumer key: {str(e)}")
    
    async def confirm_sign_up(self, verification: VerificationRequest) -> bool:
        try:
            self.client.confirm_sign_up(
                ClientId=self.client_id,
                Username=verification.email,
                ConfirmationCode=verification.code,
                SecretHash=self.get_secret_hash(verification.email)
            )
            return True
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'CodeMismatchException':
                raise Exception("Invalid verification code")
            elif error_code == 'ExpiredCodeException':
                raise Exception("Verification code has expired")
            else:
                raise Exception(f"Error confirming sign up: {str(e)}")
    
    async def refresh_token(self, refresh_token: str, email: str) -> TokenResponse:
        try:
            response = self.client.initiate_auth(
                ClientId=self.client_id,
                AuthFlow='REFRESH_TOKEN_AUTH',
                AuthParameters={
                    'REFRESH_TOKEN': refresh_token,
                    'SECRET_HASH': self.get_secret_hash(email)
                }
            )
            auth_result = response['AuthenticationResult']
            return TokenResponse(
                access_token=auth_result['AccessToken'],
                id_token=auth_result['IdToken'],
                refresh_token=refresh_token  # Keep the original refresh token
            )
        except self.client.exceptions.NotAuthorizedException as e:
            print(f"NotAuthorizedException: {str(e)}")  # Add this for debugging
            raise Exception("Invalid or expired refresh token")
        except ClientError as e:
            print(f"ClientError: {str(e)}")  # Add this for debugging
            raise Exception(f"Error refreshing token: {str(e)}")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_auth.py

│   │   ├── service_healthcheck.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_healthcheck.py

# services/service_healthcheck.py

from sqlalchemy.exc import SQLAlchemyError
from rds_db_connection import DatabaseConnector

class HealthcheckService:
    @staticmethod
    async def check_database_connection():
        db_connector = DatabaseConnector()
        try:
            query = "SELECT 1"
            result = db_connector.execute_query(query)
            if result and result[0][0] == 1:
                return True, "Database connection successful"
            else:
                return False, "Database connection failed"
        except SQLAlchemyError as e:
            return False, f"Database connection error: {str(e)}"

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_healthcheck.py

│   │   ├── service_db.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_db.py

# services/service_db.py

from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError
from rds_db_connection import DatabaseConnector
import logging

class DBService:
    @staticmethod
    async def get_openai_api_key(solomon_consumer_key: str) -> str:
        db_connector = DatabaseConnector()
        try:
            query = """
                SELECT TOP 1 openai_api_key 
                FROM dbo.solConnectConsumers 
                WHERE solomon_consumer_key = :solomon_consumer_key
            """
            result = db_connector.execute_query(query, {"solomon_consumer_key": solomon_consumer_key})
            if result and result[0]:
                return result[0][0]
            else:
                logging.warning(f"No OpenAI API key found for Solomon Consumer Key: {solomon_consumer_key}")
                return None
        except SQLAlchemyError as e:
            logging.error(f"Database error in get_openai_api_key: {str(e)}")
            raise Exception(f"Database error: {str(e)}")

    @staticmethod
    async def get_consumer_info(solomon_consumer_key: str) -> dict:
        db_connector = DatabaseConnector()
        try:
            query = """
                SELECT TOP 1 
                    solomon_consumer_key,
                    customer_name,
                    aws_key,
                    create_date,
                    modified_on,
                    plan_level,
                    customer_email,
                    openai_api_key
                FROM dbo.solConnectConsumers 
                WHERE solomon_consumer_key = :solomon_consumer_key
            """
            result = db_connector.execute_query(query, {"solomon_consumer_key": solomon_consumer_key})
            print(result[0][7])
            if result and result[0]:
                return {
                    "solomon_consumer_key": result[0][0],
                    "customer_name": result[0][1],
                    "aws_key": result[0][2],
                    "create_date": result[0][3],
                    "modified_on": result[0][4],
                    "plan_level": result[0][5],
                    "customer_email": result[0][6],
                    "openai_api_key": result[0][7]
                }
            else:
                logging.warning(f"No consumer info found for Solomon Consumer Key: {solomon_consumer_key}")
                return None
        except SQLAlchemyError as e:
            logging.error(f"Database error in get_consumer_info: {str(e)}")
            raise Exception(f"Database error: {str(e)}")

    @staticmethod
    async def get_workspace_names_by_email(email: str) -> list[str]:
        db_connector = DatabaseConnector()
        try:
            query = """
                SELECT workspace_name
                FROM dbo.solConnectUsers 
                WHERE customer_email = :email
            """
            result = db_connector.execute_query(query, {"email": email})
            if result:
                return [row[0] for row in result]  # Just return the workspace names
            return []
        except SQLAlchemyError as e:
            logging.error(f"Database error in get_workspace_names_by_email: {str(e)}")
            raise Exception(f"Database error: {str(e)}")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_db.py

│   │   ├── service_threads.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_threads.py

from typing import List, Dict, Any
from models.models_threads import Thread
from rds_db_connection import DatabaseConnector
import requests
from utils import get_headers

class ThreadService:
    def __init__(self):
        self.db = DatabaseConnector()

    def get_threads(self, solomon_consumer_key: str) -> List[Thread]:
        threads = self.db.get_threads(solomon_consumer_key)
        return [Thread(**thread) for thread in threads]

    def create_thread_service(self, thread_data: Dict[str, Any], openai_api_key: str) -> dict:
        """
        Create a new thread using the OpenAI API.
        
        Args:
            thread_data (Dict[str, Any]): Optional thread data including messages, tool_resources, and metadata
            openai_api_key (str): OpenAI API key for authentication
            
        Returns:
            dict: The created thread object from OpenAI's response
        """
        url = "https://api.openai.com/v1/threads"
        headers = {
            **get_headers(openai_api_key),
            'OpenAI-Beta': 'assistants=v2'
        }
        
        try:
            response = requests.post(url, headers=headers, json=thread_data)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            logging.error(f"Error creating thread: {e}")
            if hasattr(e, 'response') and e.response is not None:
                error_detail = e.response.json().get('error', {}).get('message', str(e))
                raise HTTPException(status_code=e.response.status_code, detail=error_detail)
            raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_threads.py

│   │   ├── service_vector_store_files.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_vector_store_files.py

import requests
import logging
from models.models_vector_store_files import CreateVectorStoreFileRequest, VectorStoreFileResponse, ListVectorStoreFilesResponse, DeleteVectorStoreFileResponse, CreateVectorStoreFileWorkatoRequest
from typing import Optional
from utils import get_headers
import tempfile
import os

logger = logging.getLogger(__name__)

def create_vector_store_file(vector_store_id: str, create_vector_store_file_request: CreateVectorStoreFileRequest, openai_api_key: str) -> VectorStoreFileResponse:
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}/files"
    headers = get_headers(openai_api_key)

    payload = create_vector_store_file_request.dict()
    logging.debug(f"Payload: {payload}")

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        logging.debug(f"Response: {response.json()}")
        return VectorStoreFileResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTP Error: {errh.response.text}")
        raise
    except Exception as e:
        logging.error(f"Request Error: {e}")
        raise

def list_vector_store_files(
    vector_store_id: str, 
    limit: int = 20, 
    order: str = "desc", 
    after: Optional[str] = None, 
    before: Optional[str] = None, 
    filter: Optional[str] = None,
    openai_api_key: str = None
) -> ListVectorStoreFilesResponse:
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}/files"
    headers = get_headers(openai_api_key)
    params = {
        "limit": limit,
        "order": order,
        "after": after,
        "before": before,
        "filter": filter
    }
    params = {k: v for k, v in params.items() if v is not None}

    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        return ListVectorStoreFilesResponse(**response.json())
    except Exception as e:
        logging.error(f"Request Error: {e}")
        raise

def delete_vector_store_file(vector_store_id: str, file_id: str, openai_api_key: str) -> DeleteVectorStoreFileResponse:
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}"
    headers = get_headers(openai_api_key)

    try:
        response = requests.delete(url, headers=headers)
        response.raise_for_status()
        return DeleteVectorStoreFileResponse(**response.json())
    except Exception as e:
        logging.error(f"Request Error: {e}")
        raise

def retrieve_vector_store_file(vector_store_id: str, file_id: str, openai_api_key: str) -> VectorStoreFileResponse:
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}/files/{file_id}"
    headers = get_headers(openai_api_key)

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return VectorStoreFileResponse(**response.json())
    except Exception as e:
        logging.error(f"Request Error: {e}")
        raise

def create_vector_store_file_workato(
    vector_store_id: str,
    request: CreateVectorStoreFileWorkatoRequest,
    openai_api_key: str
) -> VectorStoreFileResponse:
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}/files"
    headers = get_headers(openai_api_key)

    with tempfile.NamedTemporaryFile(mode='w+', suffix=f'.{request.file_type}', delete=False) as temp_file:
        temp_file.write(request.content)
        temp_file.flush()
        
        file_path = temp_file.name
        files = {'file': (request.file_name, open(file_path, 'rb'))}
        
        try:
            response = requests.post(url, headers=headers, files=files)
            response.raise_for_status()
            os.remove(file_path)
            return VectorStoreFileResponse(**response.json())
        except requests.exceptions.RequestException as err:
            logging.error(f"Request Error: {err}")
            if os.path.exists(file_path):
                os.remove(file_path)
            raise

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_vector_store_files.py

│   │   ├── service_vector_stores.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_vector_stores.py

import requests
import logging
from models.models_vector_stores import CreateVectorStoreRequest, VectorStoreResponse, ListVectorStoresResponse, DeleteVectorStoreResponse
from typing import Optional
from utils import get_headers

logger = logging.getLogger(__name__)

def create_vector_store(create_vector_store_request: CreateVectorStoreRequest, openai_api_key: str) -> VectorStoreResponse:
    url = "https://api.openai.com/v1/vector_stores"
    headers = get_headers(openai_api_key)

    try:
        response = requests.post(url, headers=headers, json=create_vector_store_request.dict())
        response.raise_for_status()
        return VectorStoreResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logger.error(f"HTTP Error: {errh}")
        raise
    except Exception as e:
        logger.error(f"Request Error: {e}")
        raise

def list_vector_stores(limit: int = 20, order: str = "desc", after: Optional[str] = None, before: Optional[str] = None, openai_api_key: str = None) -> ListVectorStoresResponse:
    url = "https://api.openai.com/v1/vector_stores"
    headers = get_headers(openai_api_key)
    
    params = {
        "limit": limit,
        "order": order
    }
    if after:
        params["after"] = after
    if before:
        params["before"] = before

    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        return ListVectorStoresResponse(**response.json())
    except Exception as e:
        logger.error(f"Request Error: {e}")
        raise

def retrieve_vector_store(vector_store_id: str, openai_api_key: str) -> VectorStoreResponse:
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}"
    headers = get_headers(openai_api_key)

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return VectorStoreResponse(**response.json())
    except Exception as e:
        logger.error(f"Request Error: {e}")
        raise

def delete_vector_store(vector_store_id: str, openai_api_key: str) -> DeleteVectorStoreResponse:
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}"
    headers = get_headers(openai_api_key)

    try:
        response = requests.delete(url, headers=headers)
        response.raise_for_status()
        return DeleteVectorStoreResponse(**response.json())
    except Exception as e:
        logger.error(f"Request Error: {e}")
        raise

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_vector_stores.py

│   │   ├── service_assistants.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_assistants.py

from openai import OpenAI
import asyncio
import logging
from fastapi import UploadFile
from models.models_assistants import CreateAssistantRequest, CreateAssistantWithToolsRequest, Assistant
from typing import Dict, Any, List, Union, Optional
import os
import httpx
from fastapi import HTTPException
import logging
import requests
from utils import get_headers
from tools import tool_registry

# TODO
# from config import get_settings
# settings = get_settings()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

def create_assistant_service(assistant: CreateAssistantRequest, openai_api_key: str):
    url = "https://api.openai.com/v1/assistants"
    headers = get_headers(openai_api_key)
    
    logger.info(f"Creating assistant with model: {assistant.model}")
    
    # Convert Pydantic model to dict and remove None values
    assistant_data = {k: v for k, v in assistant.dict().items() if v is not None}
    
    try:
        response = requests.post(url, headers=headers, json=assistant_data)
        response.raise_for_status()
        logger.info(f"Assistant created successfully: {response.json()}")
        return response.json()
    except requests.exceptions.HTTPException as e:
        logger.error(f"Failed to create assistant: {e.response.text}")
        raise HTTPException(status_code=e.response.status_code, detail=e.response.text)
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

def create_assistant_with_tools(assistant_data: CreateAssistantWithToolsRequest, openai_api_key: str) -> Assistant:
    url = "https://api.openai.com/v1/assistants"
    headers = get_headers(openai_api_key)
    
    assistant_dict = assistant_data.dict(exclude_unset=True)
    
    try:
        response = requests.post(url, headers=headers, json=assistant_dict)
        response.raise_for_status()
        return Assistant(**response.json())
    except requests.exceptions.RequestException as e:
        logger.error(f"Error creating assistant: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error creating assistant: {str(e)}")
    
def list_openai_assistants(limit: int = 20, order: str = "desc", openai_api_key: Optional[str] = None):
    url = "https://api.openai.com/v1/assistants"
    headers = get_headers(openai_api_key)
    
    params = {
        "limit": limit,
        "order": order
    }
    
    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        logging.error(f"Error in list_openai_assistants: {e}")
        raise HTTPException(status_code=500, detail="Error fetching assistants from OpenAI")

import requests
import logging
from fastapi import HTTPException
from typing import Dict, Any

logger = logging.getLogger(__name__)

def modify_openai_assistant(assistant_id: str, data: Dict[str, Any], openai_api_key: str) -> Dict[str, Any]:
    """
    Modify an existing OpenAI assistant.
    """
    url = f"https://api.openai.com/v1/assistants/{assistant_id}"
    
    # Headers exactly as shown in the working curl command
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "OpenAI-Beta": "assistants=v2",
        "Content-Type": "application/json"
    }

    # Ensure we're maintaining the exact structure OpenAI expects
    payload = {
        key: value for key, value in data.items()
        if value is not None and key in {
            "name", "description", "instructions", "tools",
            "tool_resources", "metadata", "model", "file_ids",
            "temperature", "top_p", "response_format"
        }
    }

    try:
        # Use POST method as shown in the working curl command
        response = requests.post(
            url,
            headers=headers,
            json=payload
        )
        
        # Log the request and response for debugging
        logger.debug(f"Request URL: {url}")
        logger.debug(f"Request headers: {headers}")
        logger.debug(f"Request payload: {payload}")
        logger.debug(f"Response status: {response.status_code}")
        logger.debug(f"Response body: {response.text}")

        response.raise_for_status()
        return response.json()

    except requests.exceptions.HTTPError as err:
        logger.error(f"HTTP Error: {err}")
        if err.response is not None:
            error_detail = err.response.json().get('error', {}).get('message', str(err))
            raise HTTPException(
                status_code=err.response.status_code,
                detail=error_detail
            )
        raise HTTPException(status_code=500, detail=str(err))
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def delete_openai_assistant(assistant_id: str, openai_api_key: str) -> dict:
    url = f"https://api.openai.com/v1/assistants/{assistant_id}"
    headers = get_headers(openai_api_key)

    try:
        response = requests.delete(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as err:
        logger.error(f"Request Error in delete_openai_assistant: {err}")
        if err.response:
            error_detail = err.response.json().get('error', {}).get('message', str(err))
            raise HTTPException(status_code=err.response.status_code, detail=error_detail)
        raise HTTPException(status_code=500, detail="Internal Server Error")

def _get_tool_definitions(tools: List[Union[str, Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
    if not tools:
        return []
    
    tool_definitions = []
    for tool in tools:
        if isinstance(tool, str):
            if tool in tool_registry:
                tool_definitions.append({
                    "type": "function",
                    "function": tool_registry[tool]().get_definition()['function']
                })
            else:
                logger.warning(f"Unknown tool: {tool}")
        elif isinstance(tool, dict):
            if 'type' in tool:
                tool_definitions.append(tool)
            else:
                logger.warning(f"Invalid tool definition: {tool}")
        else:
            logger.warning(f"Invalid tool type: {type(tool)}")
    
    return tool_definitions

# New function to update an assistant's tools
def update_assistant_tools(assistant_id: str, tools: List[str], openai_api_key: str = None) -> dict:
    tool_definitions = _get_tool_definitions(tools)
    return modify_openai_assistant(assistant_id, {"tools": tool_definitions}, openai_api_key)

def get_openai_assistant(assistant_id: str, openai_api_key: str) -> dict:
    """
    Retrieve a specific assistant from OpenAI.
    
    Args:
        assistant_id (str): The ID of the assistant to retrieve
        openai_api_key (str): OpenAI API key for authentication
        
    Returns:
        dict: The assistant object from OpenAI's response
    """
    
    url = f"https://api.openai.com/v1/assistants/{assistant_id}"
    headers = get_headers(openai_api_key)
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        logging.error(f"Error retrieving OpenAI assistant: {e}")
        raise e

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_assistants.py

│   │   ├── assistant_bridge.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/assistant_bridge.py

from typing import Dict, Any, List, Optional, AsyncGenerator, Union, Tuple
import logging
import json
import asyncio
from openai import AsyncOpenAI
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class StreamEvent:
    """Custom event class for streaming events."""
    type: str
    data: Dict[str, Any]

class AssistantBridgeError(Exception):
    """Base exception for assistant bridge errors."""
    pass

class AssistantBridge:
    def __init__(self, api_key: str, assistant_id: str, vector_store_ids: Optional[List[str]] = None):
        """
        Bridge between Assistant API and front-end.
        
        Args:
            api_key: OpenAI API key
            assistant_id: Existing Assistant ID to get configuration from
            vector_store_ids: Optional list of vector store IDs for file search
        """
        self.api_key = api_key
        self.assistant_id = assistant_id
        self.vector_store_ids = vector_store_ids
        self.conversation_history = []
        self.openai_client = AsyncOpenAI(api_key=api_key)
        self._thread_id = None
        self.initialized = False
        
    async def initialize(self, workato_config=None):
        """Initialize the bridge."""
        try:
            # Fetch assistant data to verify it exists
            assistant = await self.openai_client.beta.assistants.retrieve(self.assistant_id)
            logger.info(f"Successfully connected to assistant: {assistant.name}")
            
            # Create a new thread
            thread = await self.openai_client.beta.threads.create()
            self._thread_id = thread.id
            logger.info(f"Created thread: {thread.id}")
            
            self.initialized = True
            return True
        except Exception as e:
            logger.error(f"Failed to initialize assistant bridge: {str(e)}")
            raise AssistantBridgeError(f"Initialization failed: {str(e)}")
            
    async def chat(self, message: str) -> str:
        """
        Process a chat message using the assistant.
        
        Args:
            message: The user's message
        
        Returns:
            The assistant's response
        """
        if not self._thread_id:
            await self.initialize()
            
        try:
            # Add the message to history
            self.conversation_history.append({"role": "user", "content": message})
            
            # Add message to thread
            await self.openai_client.beta.threads.messages.create(
                thread_id=self._thread_id,
                role="user",
                content=message
            )
            
            # Run the thread
            run = await self.openai_client.beta.threads.runs.create(
                thread_id=self._thread_id,
                assistant_id=self.assistant_id
            )
            
            # Wait for completion
            while True:
                run_status = await self.openai_client.beta.threads.runs.retrieve(
                    thread_id=self._thread_id,
                    run_id=run.id
                )
                
                if run_status.status == "completed":
                    break
                elif run_status.status in ["failed", "cancelled", "expired"]:
                    raise AssistantBridgeError(f"Run failed with status: {run_status.status}")
                
                await asyncio.sleep(0.5)
            
            # Get messages (newest first)
            messages = await self.openai_client.beta.threads.messages.list(
                thread_id=self._thread_id
            )
            
            # Get the assistant's response (first message, which is the latest)
            response = ""
            for msg in messages.data:
                if msg.role == "assistant":
                    for content_item in msg.content:
                        if content_item.type == "text":
                            response = content_item.text.value
                            break
                    break
            
            # Add to history
            if response:
                self.conversation_history.append({"role": "assistant", "content": response})
                
            return response
        
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            raise AssistantBridgeError(f"Chat failed: {str(e)}")
    
    async def chat_streaming(self, message: str):
        """Simulate streaming responses from the API."""
        # Add the message to history
        self.conversation_history.append({"role": "user", "content": message})
        
        try:
            # Get the complete response
            full_response = await self.chat(message)
            
            # Simulate streaming by breaking up the response
            sentences = full_response.split(". ")
            
            for i, sentence in enumerate(sentences):
                # Add the period back except for the last sentence
                if i < len(sentences) - 1:
                    sentence += "."
                
                # Add a space after the sentence
                sentence += " "
                
                # Yield each sentence
                yield sentence, "message"
                
                # Brief pause to simulate streaming
                await asyncio.sleep(0.1)
        
        except Exception as e:
            logger.error(f"Error in streaming chat: {str(e)}")
            raise
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """Get the conversation history"""
        return self.conversation_history
        
    def clear_history(self) -> None:
        """Clear the conversation history and create a new thread"""
        self.conversation_history = []
        # Create a new thread asynchronously in the background
        asyncio.create_task(self._create_new_thread())
    
    async def _create_new_thread(self):
        """Create a new thread for the conversation."""
        try:
            thread = await self.openai_client.beta.threads.create()
            self._thread_id = thread.id
            logger.info(f"Created new thread: {thread.id}")
        except Exception as e:
            logger.error(f"Failed to create new thread: {str(e)}") 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/assistant_bridge.py

│   │   ├── service_messages.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_messages.py

import aiohttp
import logging
from models.models_messages import ListMessagesResponse, CreateMessageRequest, CreateMessageResponse
import os
from typing import Optional
from utils import get_headers

logger = logging.getLogger(__name__)

async def list_thread_messages(thread_id: str, limit: int = 20, order: str = "desc", openai_api_key: Optional[str] = None) -> ListMessagesResponse:
    url = f"https://api.openai.com/v1/threads/{thread_id}/messages"
    headers = get_headers(openai_api_key)
    params = {
        "limit": limit,
        "order": order
    }

    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url, headers=headers, params=params) as response:
                response.raise_for_status()
                response_json = await response.json()
                return ListMessagesResponse(**response_json)
        except aiohttp.ClientResponseError as e:
            logger.error(f"HTTP Error: {e}, Response Content: {await response.text()}")
            raise
        except aiohttp.ClientError as e:
            logger.error(f"Request Error: {e}")
            raise

async def create_message(thread_id: str, create_message_request: CreateMessageRequest, openai_api_key: Optional[str] = None) -> CreateMessageResponse:
    url = f"https://api.openai.com/v1/threads/{thread_id}/messages"
    headers = get_headers(openai_api_key)
    payload = create_message_request.dict(exclude_unset=True)  # This excludes None values and unset fields
    
    logger.info(f"Sending request to {url}")
    logger.info(f"Headers: {headers}")
    logger.info(f"Payload: {payload}")

    async with aiohttp.ClientSession() as session:
        try:
            async with session.post(url, headers=headers, json=payload) as response:
                response.raise_for_status()
                response_json = await response.json()
                return CreateMessageResponse(**response_json)
        except aiohttp.ClientResponseError as e:
            logger.error(f"HTTP Error: {e}, Response Content: {await response.text()}")
            raise
        except aiohttp.ClientError as e:
            logger.error(f"Request Error: {e}")
            raise

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_messages.py

│   │   ├── service_files.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_files.py

import requests
import logging
from models.models_files import UploadFileResponse, ListFilesResponse, FileContentUploadResponse, FileResponse
from typing import Optional

def upload_file(file_path: str, openai_api_key: str, purpose: str = "assistants") -> UploadFileResponse:
    url = "https://api.openai.com/v1/files"
    
    # Use the API key to set the Authorization header
    headers = {
        "Authorization": f"Bearer {openai_api_key}"
    }
    
    files = {
        'file': open(file_path, 'rb'),
        'purpose': (None, purpose)
    }

    try:
        response = requests.post(url, headers=headers, files=files)
        response.raise_for_status()
        return UploadFileResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTP Error: {errh}, Response Content: {response.content}")
        raise
    except requests.exceptions.ConnectionError as errc:
        logging.error(f"Error Connecting: {errc}")
        raise
    except requests.exceptions.Timeout as errt:
        logging.error(f"Timeout Error: {errt}")
        raise
    except requests.exceptions.RequestException as err:
        logging.error(f"Request Error: {err}")
        raise

def list_files(purpose: Optional[str] = None, openai_api_key: str = None) -> ListFilesResponse:
    url = "https://api.openai.com/v1/files"
    
    # Define headers for v1 API
    headers = {
        "Authorization": f"Bearer {openai_api_key}"
    }
    
    params = {}
    if purpose:
        params['purpose'] = purpose

    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        return ListFilesResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTP Error: {errh}, Response Content: {response.content}")
        raise
    except requests.exceptions.ConnectionError as errc:
        logging.error(f"Error Connecting: {errc}")
        raise
    except requests.exceptions.Timeout as errt:
        logging.error(f"Timeout Error: {errt}")
        raise
    except requests.exceptions.RequestException as err:
        logging.error(f"Request Error: {err}")
        raise

def upload_file_content(file_path: str, file_name: str, openai_api_key: str, purpose: str = "assistants") -> FileContentUploadResponse:
    url = "https://api.openai.com/v1/files"
    
    headers = {
        "Authorization": f"Bearer {openai_api_key}"
    }
    
    with open(file_path, 'rb') as f:
        files = {
            'file': (file_name, f, 'application/octet-stream'),
            'purpose': (None, purpose)
        }
        
        try:
            response = requests.post(url, headers=headers, files=files)
            response.raise_for_status()
            return FileContentUploadResponse(**response.json())
        except requests.exceptions.RequestException as err:
            logging.error(f"Request Error: {err}")
            raise
    
def get_file(file_id: str, openai_api_key: str) -> FileResponse:
    """
    Retrieve information about a specific file from OpenAI.
    
    Args:
        file_id (str): The ID of the file to retrieve
        openai_api_key (str): OpenAI API key for authentication
        
    Returns:
        FileResponse: The file object from OpenAI's response
    """
    # Use the API key to set the Authorization header
    headers = {
        "Authorization": f"Bearer {openai_api_key}"
    }
    
    url = f"https://api.openai.com/v1/files/{file_id}"
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return FileResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTP Error: {errh}, Response Content: {response.content}")
        raise
    except requests.exceptions.ConnectionError as errc:
        logging.error(f"Error Connecting: {errc}")
        raise
    except requests.exceptions.Timeout as errt:
        logging.error(f"Timeout Error: {errt}")
        raise
    except requests.exceptions.RequestException as err:
        logging.error(f"Request Error: {err}")
        raise

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_files.py

│   │   ├── service_assistant_builder_threads.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_assistant_builder_threads.py

from typing import List, Optional
from models.models_assistant_builder_threads import AssistantBuilderThread, AssistantBuilderThreadCreate
from rds_db_connection import DatabaseConnector

class AssistantBuilderThreadService:
    def __init__(self):
        self.db = DatabaseConnector()

    def get_threads(self, solomon_consumer_key: str) -> List[AssistantBuilderThread]:
        threads = self.db.get_assistant_builder_threads(solomon_consumer_key)
        return [AssistantBuilderThread(**thread) for thread in threads]

    def create_thread(self, thread_data: AssistantBuilderThreadCreate) -> bool:
        return self.db.create_assistant_builder_thread(
            thread_data.solomon_consumer_key,
            thread_data.thread_id,
            thread_data.thread_name
        )

    def delete_thread(self, thread_id: str) -> bool:
        return self.db.delete_assistant_builder_thread(thread_id)
    
    def get_assistant_id(self, thread_id: str, solomon_consumer_key: str) -> Optional[str]:
        return self.db.get_assistant_id_by_thread(thread_id, solomon_consumer_key)

    def get_assistant_builder_id(self, solomon_consumer_key: str, workspace_name: str) -> Optional[str]:
        return self.db.get_assistant_builder_id(solomon_consumer_key, workspace_name)

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_assistant_builder_threads.py

│   │   ├── agent_management.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_management.py

from typing import Optional, Dict, Any
import asyncio
from log import logger
from openai_agents.runner import Runner
from openai_agents.message_output_item import MessageOutputItem
from openai_agents.stream_event import StreamEvent

class AgentManagement:
    def __init__(self, agent):
        self.agent = agent

    async def run_existing_agent_streaming(
        self,
        input_text: str,
        context: Optional[Dict[str, Any]] = None
    ):
        """Run the agent with streaming enabled - simulating streaming since Runner.stream doesn't exist."""
        if not self.agent:
            raise ValueError("Agent not initialized. Call initialize() first.")
        
        try:
            # First yield a starting event
            yield StreamEvent(type="start", data={"message": "Starting agent processing"})
            
            # Run the agent - get the complete response without streaming
            result = await Runner.run(
                starting_agent=self.agent,
                input=input_text,
                context=context or {}
            )
            
            # Extract the output from the result
            output = ""
            if result.new_items:
                for item in result.new_items:
                    # Look for MessageOutputItem to get the response text
                    if isinstance(item, MessageOutputItem):
                        if hasattr(item, 'message') and hasattr(item.message, 'content'):
                            output = item.message.content
                            break
                        # Fallback to raw_item if available
                        elif hasattr(item, 'raw_item'):
                            if hasattr(item.raw_item, 'content') and isinstance(item.raw_item.content, list):
                                # Combine all text from content items
                                content_texts = []
                                for content_item in item.raw_item.content:
                                    if hasattr(content_item, 'text'):
                                        content_texts.append(content_item.text)
                                
                                if content_texts:
                                    output = "\n".join(content_texts)
                                    break
            
            # If we have an output, simulate streaming by breaking it into chunks
            if output:
                # Track tool usage to simulate tool events
                tool_mentioned = False
                
                # Break the output into sentences
                sentences = output.split(". ")
                
                for i, sentence in enumerate(sentences):
                    # Add the period back except for the last sentence
                    if i < len(sentences) - 1:
                        sentence += "."
                    
                    # If the sentence mentions tools and we haven't simulated a tool event yet
                    if ("tool" in sentence.lower() or "search" in sentence.lower()) and not tool_mentioned:
                        yield StreamEvent(type="tool_event", data={"message": "Using a tool"})
                        tool_mentioned = True
                    
                    # Yield the sentence as a content chunk
                    yield StreamEvent(type="content_chunk", data={"content": sentence + " "})
                    
                    # Add a small delay to simulate real streaming
                    await asyncio.sleep(0.05)
            
            # Yield a completion event
            yield StreamEvent(type="completion", data={"message": "Processing complete"})
            
        except Exception as e:
            logger.error(f"Error in streaming agent run: {str(e)}")
            raise 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_management.py

│   │   ├── service_runs.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_runs.py

from fastapi import HTTPException
import requests
import logging
from models.models_runs import CreateThreadRunRequest, RunResponse
from models.models_messages import ListMessagesResponse
from services.service_messages import list_thread_messages
import os
import time
from utils import get_headers
from tools import tool_registry
import json
from typing import List, Dict, Any, Union, Optional
from tenacity import retry, stop_after_attempt, wait_exponential

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

logger = logging.getLogger(__name__)

def create_and_run_thread(create_thread_run_request: CreateThreadRunRequest, openai_api_key: str = None) -> RunResponse:
    url = "https://api.openai.com/v1/threads/runs"
    headers = get_headers(openai_api_key)

    thread_payload = {
        "assistant_id": create_thread_run_request.assistant_id,
        "thread": create_thread_run_request.thread.dict()
    }

    try:
        response = requests.post(url, headers=headers, json=thread_payload)
        response.raise_for_status()
        return RunResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTP Error: {errh}")
        raise
    except requests.exceptions.ConnectionError as errc:
        logging.error(f"Error Connecting: {errc}")
        raise
    except requests.exceptions.Timeout as errt:
        logging.error(f"Timeout Error: {errt}")
        raise
    except requests.exceptions.RequestException as err:
        logging.error(f"Request Error: {err}")
        raise

def run_thread(thread_id: str, assistant_id: str, openai_api_key: str = None) -> RunResponse:
    url = f"https://api.openai.com/v1/threads/{thread_id}/runs"
    headers = get_headers(openai_api_key)
    payload = {
        "assistant_id": assistant_id
    }

    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        return RunResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTP Error: {errh}")
        raise
    except requests.exceptions.ConnectionError as errc:
        logging.error(f"Error Connecting: {errc}")
        raise
    except requests.exceptions.Timeout as errt:
        logging.error(f"Timeout Error: {errt}")
        raise
    except requests.exceptions.RequestException as err:
        logging.error(f"Request Error: {err}")
        raise

def get_run_status(thread_id: str, run_id: str, openai_api_key: str = None) -> RunResponse:
    url = f"https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}"
    headers = get_headers(openai_api_key)

    logging.debug(f"Headers: {headers}")

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return RunResponse(**response.json())
    except requests.exceptions.HTTPError as errh:
        logging.error(f"HTTP Error: {errh}")
        raise
    except requests.exceptions.ConnectionError as errc:
        logging.error(f"Error Connecting: {errc}")
        raise
    except requests.exceptions.Timeout as errt:
        logging.error(f"Timeout Error: {errt}")
        raise
    except requests.exceptions.RequestException as err:
        logging.error(f"Request Error: {err}")
        raise

def poll_run_status(thread_id: str, run_id: str, openai_api_key: str = None, interval: int = 5, timeout: int = 300) -> RunResponse:
    start_time = time.time()
    while True:
        run_response = get_run_status(thread_id, run_id, openai_api_key)
        if run_response.status == "completed":
            return run_response
        elif time.time() - start_time > timeout:
            raise TimeoutError(f"Run {run_id} did not complete within {timeout} seconds")
        time.sleep(interval)

def get_thread_messages(thread_id: str, limit: int = 20, order: str = "desc", openai_api_key: str = None) -> ListMessagesResponse:
    return list_thread_messages(thread_id, limit, order, openai_api_key)

# def create_run_and_list_messages(create_thread_run_request: CreateThreadRunRequest, openai_api_key: str = None, interval: int = 5, timeout: int = 300) -> ListMessagesResponse:
#     # Create and run the thread
#     initial_response = create_and_run_thread(create_thread_run_request, openai_api_key)
    
#     # Poll the run status until it is completed
#     final_response = poll_run_status(initial_response.thread_id, initial_response.id, openai_api_key, interval, timeout)
    
#     # List the messages in the completed thread
#     return get_thread_messages(final_response.thread_id, openai_api_key=openai_api_key)

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
def make_request(url, method='get', **kwargs):
    response = requests.request(method, url, **kwargs)
    response.raise_for_status()
    return response

def run_thread_and_list_messages(
    thread_id: str, 
    assistant_id: str, 
    tools: Optional[List[Dict[str, Any]]] = None,
    openai_api_key: str = None, 
    interval: int = 5, 
    timeout: int = 300
) -> Union[List[Dict[str, Any]], Dict[str, Any]]:
    headers = get_headers(openai_api_key)
    
    logger.info(f"Running thread {thread_id} with assistant {assistant_id}")
    run_url = f"https://api.openai.com/v1/threads/{thread_id}/runs"
    run_payload = {"assistant_id": assistant_id}
    
    if tools:
        run_payload['tools'] = tools
        logger.info(f"Added {len(tools)} tools to run payload")
    
    try:
        run_response = make_request(run_url, method='post', headers=headers, json=run_payload)
        run = run_response.json()
        logger.info(f"Run created with ID: {run['id']}")
    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to create run: {str(e)}")
        raise HTTPException(status_code=500, detail="Failed to create run")
    
    start_time = time.time()
    
    logger.info("Waiting for run to complete")
    while run['status'] not in ['completed', 'failed', 'cancelled']:
        if time.time() - start_time > timeout:
            logger.error(f"Run timed out after {timeout} seconds")
            raise HTTPException(status_code=504, detail="Run timed out")
        
        time.sleep(interval)
        run_status_url = f"https://api.openai.com/v1/threads/{thread_id}/runs/{run['id']}"
        try:
            run_status_response = make_request(run_status_url, headers=headers)
            run = run_status_response.json()
            logger.info(f"Current run status: {run['status']}")
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to get run status: {str(e)}")
            continue
        
        if run['status'] == 'requires_action':
            logger.info("Run requires action, handling tools")
            run = handle_run_with_tools(run, thread_id, openai_api_key)
    
    logger.info(f"Run completed with status: {run['status']}")

    logger.info("Listing messages")
    messages_url = f"https://api.openai.com/v1/threads/{thread_id}/messages"
    try:
        messages_response = make_request(messages_url, headers=headers)
        messages = messages_response.json()
        logger.info(f"Retrieved messages")
    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to retrieve messages: {str(e)}")
        raise HTTPException(status_code=500, detail="Failed to retrieve messages")
    
    if 'data' in messages and isinstance(messages['data'], list):
        return messages['data']
    elif isinstance(messages, dict):
        return messages
    else:
        logger.error(f"Unexpected message format: {messages}")
        raise HTTPException(status_code=500, detail="Unexpected message format from OpenAI API")
    
def execute_tool(tool_call: Dict[str, Any]) -> Dict[str, Any]:
    tool_name = tool_call['function']['name']
    arguments = json.loads(tool_call['function']['arguments'])
    
    logger.info(f"Executing tool: {tool_name}")
    logger.debug(f"Tool arguments: {arguments}")

    tool_class = tool_registry.get(tool_name)
    if not tool_class:
        logger.error(f"Unknown tool: {tool_name}")
        raise ValueError(f"Unknown tool: {tool_name}")
    
    tool = tool_class()
    result = tool.execute(**arguments)
    
    logger.info(f"Tool {tool_name} execution completed")
    
    # If result is already a string, use it directly
    if isinstance(result, str):
        output = result
    else:
        # If it's not a string, try to serialize it to JSON
        try:
            output = json.dumps(result)
        except TypeError:
            # If serialization fails, convert to string
            output = str(result)

    logger.debug(f"Tool result: {output}")

    return {
        "tool_call_id": tool_call['id'],
        "output": output
    }

def handle_run_with_tools(run: Dict[str, Any], thread_id: str, openai_api_key: str) -> Dict[str, Any]:
    headers = get_headers(openai_api_key)
    while run['status'] == 'requires_action':
        logger.info(f"Run {run['id']} requires action")
        tool_calls = run['required_action']['submit_tool_outputs']['tool_calls']
        logger.debug(f"Tool calls: {tool_calls}")

        tool_outputs = [execute_tool(tool_call) for tool_call in tool_calls]
        logger.info(f"Executed {len(tool_outputs)} tools")
        
        url = f"https://api.openai.com/v1/threads/{thread_id}/runs/{run['id']}/submit_tool_outputs"
        response = requests.post(url, headers=headers, json={"tool_outputs": tool_outputs})
        response.raise_for_status()
        run = response.json()
        logger.info(f"Submitted tool outputs, new run status: {run['status']}")
    
    return run

def create_run_and_list_messages(create_thread_run_request: Dict[str, Any], openai_api_key: str = None) -> Union[List[Dict[str, Any]], Dict[str, Any]]:
    # Log the API key (partially masked)
    if openai_api_key:
        logger.info(f"Using OpenAI API key: {openai_api_key}")
    else:
        logger.warning("No OpenAI API key provided")

    headers = get_headers(openai_api_key)
    
    logger.info("Creating thread")
    thread_url = "https://api.openai.com/v1/threads"
    thread_payload = {"messages": create_thread_run_request['thread']['messages']}
    thread_response = requests.post(thread_url, headers=headers, json=thread_payload)
    try:
        thread_response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        logger.error(f"HTTP error when creating thread: {e}")
        logger.error(f"Response content: {thread_response.text}")
        raise

    thread_id = thread_response.json()['id']
    logger.info(f"Thread created with ID: {thread_id}")

    logger.info("Creating run")
    run_url = f"https://api.openai.com/v1/threads/{thread_id}/runs"
    run_payload = {
        "assistant_id": create_thread_run_request['assistant_id'],
        "instructions": create_thread_run_request.get('instructions')
    }
    
    if 'tools' in create_thread_run_request:
        run_payload['tools'] = create_thread_run_request['tools']
        logger.info(f"Added {len(create_thread_run_request['tools'])} tools to run payload")
    
    logger.debug(f"Run payload: {run_payload}")
    run_response = requests.post(run_url, headers=headers, json=run_payload)
    try:
        run_response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        logger.error(f"HTTP error when creating run: {e}")
        logger.error(f"Response content: {run_response.text}")
        raise

    run = run_response.json()
    logger.info(f"Run created with ID: {run['id']}")
    
    start_time = time.time()
    timeout = 600  # 10 minutes timeout
    
    logger.info("Waiting for run to complete")
    while run['status'] not in ['completed', 'failed', 'cancelled']:
        if time.time() - start_time > timeout:
            logger.error(f"Run timed out after {timeout} seconds")
            raise HTTPException(status_code=504, detail="Run timed out")
        
        time.sleep(5)
        run_status_url = f"https://api.openai.com/v1/threads/{thread_id}/runs/{run['id']}"
        run_status_response = requests.get(run_status_url, headers=headers)
        try:
            run_status_response.raise_for_status()
        except requests.exceptions.HTTPError as e:
            logger.error(f"HTTP error when checking run status: {e}")
            logger.error(f"Response content: {run_status_response.text}")
            raise

        run = run_status_response.json()
        logger.info(f"Current run status: {run['status']}")
        
        if run['status'] == 'requires_action':
            logger.info("Run requires action, handling tools")
            run = handle_run_with_tools(run, thread_id, openai_api_key)
    
    logger.info(f"Run completed with status: {run['status']}")

    logger.info("Listing messages")
    messages_url = f"https://api.openai.com/v1/threads/{thread_id}/messages"
    messages_response = requests.get(messages_url, headers=headers)
    try:
        messages_response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        logger.error(f"HTTP error when listing messages: {e}")
        logger.error(f"Response content: {messages_response.text}")
        raise

    messages = messages_response.json()
    logger.info(f"Retrieved messages")
    
    # Check if 'data' key exists in the response
    if 'data' in messages and isinstance(messages['data'], list):
        return messages['data']
    elif isinstance(messages, dict):
        return messages
    else:
        logger.error(f"Unexpected message format: {messages}")
        raise HTTPException(status_code=500, detail="Unexpected message format from OpenAI API")

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_runs.py

│   │   ├── service_teams.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_teams.py

from typing import List, Optional
from fastapi import HTTPException
from models.models_teams import TeamCallableAssistant
from rds_db_connection import DatabaseConnector

class TeamService:
    def __init__(self):
        self.db = DatabaseConnector()

    def add_team_member(self, solomon_consumer_key: str, origin_assistant_id: str,
                      callable_assistant_id: str, callable_assistant_reason: Optional[str] = None) -> tuple[bool, str]:
        return self.db.add_team_member(
            solomon_consumer_key=solomon_consumer_key,
            origin_assistant_id=origin_assistant_id,
            callable_assistant_id=callable_assistant_id,
            callable_assistant_reason=callable_assistant_reason
        )

    def get_team_callable_assistants(self, solomon_consumer_key: str, 
                                   origin_assistant_id: str) -> List[TeamCallableAssistant]:
        assistants = self.db.get_team_callable_assistants(
            solomon_consumer_key=solomon_consumer_key,
            origin_assistant_id=origin_assistant_id
        )
        return [TeamCallableAssistant(**assistant) for assistant in assistants]

    def delete_team_callable_assistant(self, solomon_consumer_key: str, origin_assistant_id: str,
                                     callable_assistant_id: str) -> bool:
        return self.db.delete_team_callable_assistant(
            solomon_consumer_key=solomon_consumer_key,
            origin_assistant_id=origin_assistant_id,
            callable_assistant_id=callable_assistant_id
        )

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_teams.py

│   │   ├── service_o1.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_o1.py

# services/service_o1.py
from openai import OpenAI
from models.models_o1 import O1Request, O1Response
import os

# Initialize the OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def get_o1_completion(request: O1Request) -> O1Response:
    response = client.chat.completions.create(
        model="o1-preview",
        messages=[{"role": "user", "content": request.prompt}]
    )
    completion_text = response.choices[0].message.content.strip()
    return O1Response(completion=completion_text)


FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/service_o1.py

│   │   ├── workato_integration.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/workato_integration.py

from typing import Dict, List, Any, Optional, Callable
import logging
import json
import aiohttp
from dataclasses import dataclass

try:
    from agents import Tool, function_tool
    AGENTS_SDK_AVAILABLE = True
except ImportError:
    AGENTS_SDK_AVAILABLE = False
    # Create dummy classes/functions for typing
    class Tool: pass
    def function_tool(*args, **kwargs): return lambda x: x

logger = logging.getLogger(__name__)

@dataclass
class WorkatoConfig:
    """Configuration for Workato API."""
    api_token: str
    endpoint_url: str

class WorkatoIntegration:
    """Integration with Workato for system actions and tools."""
    
    def __init__(self, config: WorkatoConfig):
        """Initialize the Workato integration."""
        self.config = config
    
    def get_tools(self) -> List[Tool]:
        """Get the list of Workato tools."""
        if not AGENTS_SDK_AVAILABLE:
            logger.warning("Agents SDK not available, returning empty tools list")
            return []
            
        tools = []
        
        @function_tool(
            name_override="execute_workato_action",
            description_override="""Execute any action through Workato. Available actions include searching or creating contacts in Salesforce.
            The action_type specifies what operation to perform (e.g., 'search_contact', 'create_contact').
            The system parameter indicates which system to interact with (e.g., 'salesforce', 'hubspot').
            The payload_json should be a JSON string containing the data for the action."""
        )
        async def execute_workato_action(action_type: str, system: str, payload_json: str) -> Dict[str, Any]:
            """Execute an action via Workato.
            
            Args:
                action_type: The type of action to execute (e.g., 'search_contact', 'create_contact')
                system: The system to interact with (e.g., 'salesforce', 'hubspot')
                payload_json: JSON string containing the data payload for the action
            
            Returns:
                Dict containing success status, data/error message, and optional result data
            """
            try:
                # For search_contact actions, ensure we use contact_name
                if action_type == "search_contact":
                    try:
                        # Parse existing payload
                        payload_dict = json.loads(payload_json)
                        # If name is provided, convert it to contact_name
                        if "name" in payload_dict:
                            payload_dict["contact_name"] = payload_dict.pop("name")
                        # If neither exists, create contact_name
                        if "contact_name" not in payload_dict:
                            return {
                                "success": False,
                                "error": "Missing contact_name in payload"
                            }
                        # Convert back to JSON string
                        payload_json = json.dumps(payload_dict)
                    except json.JSONDecodeError as e:
                        return {
                            "success": False,
                            "error": f"Invalid payload JSON: {str(e)}"
                        }

                async with aiohttp.ClientSession() as session:
                    headers = {
                        "API-TOKEN": self.config.api_token,
                        "Content-Type": "application/json"
                    }
                    
                    # Format the payload according to Workato's expected structure
                    request_payload = {
                        "action_type": action_type,
                        "system": system,
                        "payload": payload_json,  # JSON string with correct field names
                        "schema": "{}"  # Empty schema as a JSON string
                    }
                    
                    # Log the complete request details
                    logger.info("=== Workato API Request Details ===")
                    logger.info(f"Endpoint URL: {self.config.endpoint_url}")
                    logger.info(f"Headers: {json.dumps(headers, indent=2)}")
                    logger.info(f"Request Payload: {json.dumps(request_payload, indent=2)}")
                    logger.info("================================")
                    
                    async with session.post(
                        self.config.endpoint_url,
                        headers=headers,
                        json=request_payload
                    ) as response:
                        response_text = await response.text()
                        logger.info("=== Workato API Response ===")
                        logger.info(f"Status Code: {response.status}")
                        logger.info(f"Response Body: {response_text}")
                        logger.info("===========================")
                        
                        if response.status == 200:
                            result = json.loads(response_text)
                            return {
                                "success": True,
                                "data": result,
                                "message": f"Action '{action_type}' on system '{system}' completed successfully"
                            }
                        else:
                            logger.error(f"Error executing action: {response_text}")
                            return {
                                "success": False,
                                "error": f"Failed to execute action: {response_text}"
                            }
                            
            except Exception as e:
                logger.error(f"Error in execute_workato_action: {str(e)}")
                return {
                    "success": False,
                    "error": f"Error executing action: {str(e)}"
                }
        
        tools.append(execute_workato_action)
        return tools 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/workato_integration.py

│   │   ├── agent_services
│   │   │   ├── tool_management.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/tool_management.py

from typing import List, Dict, Any, Optional, Callable
import logging
import inspect
from agents import Tool, function_tool

logger = logging.getLogger(__name__)

class ToolManagementError(Exception):
    """Base exception for tool management errors."""
    pass

class InvalidToolConfigError(ToolManagementError):
    """Exception raised when the tool configuration is invalid."""
    pass

class ToolNotFoundError(ToolManagementError):
    """Exception raised when a requested tool cannot be found."""
    pass

class ToolManagementService:
    """Service for managing tools that can be used by OpenAI agents."""
    
    def __init__(self):
        """Initialize the tool management service."""
        self.registered_functions = {}
        self.tools = {}
    
    def register_function(
        self,
        func_id: str,
        func: Callable,
        description: str
    ) -> Dict[str, Any]:
        """
        Register a Python function for use with tools.
        
        Args:
            func_id: A unique identifier for the function
            func: The Python function to register
            description: A description of what the function does
            
        Returns:
            A dictionary with the function's details
            
        Raises:
            InvalidToolConfigError: If the function is invalid
        """
        if not callable(func):
            raise InvalidToolConfigError("Function must be callable")
            
        if func_id in self.registered_functions:
            logger.warning(f"Function with ID {func_id} already registered, overwriting")
            
        self.registered_functions[func_id] = {
            "id": func_id,
            "func": func,
            "description": description
        }
        
        return {
            "id": func_id,
            "description": description
        }
    
    def list_registered_functions(self) -> List[Dict[str, Any]]:
        """
        List all registered functions.
        
        Returns:
            A list of function information dictionaries
        """
        return [
            {"id": func_id, "description": func_info["description"]}
            for func_id, func_info in self.registered_functions.items()
        ]
    
    def get_registered_function(self, func_id: str) -> Dict[str, Any]:
        """
        Get a registered function by ID.
        
        Args:
            func_id: The ID of the function to get
            
        Returns:
            A dictionary with the function's details
            
        Raises:
            ToolNotFoundError: If the function is not found
        """
        if func_id not in self.registered_functions:
            raise ToolNotFoundError(f"Function with ID {func_id} not found")
            
        func_info = self.registered_functions[func_id]
        return {
            "id": func_id,
            "description": func_info["description"]
        }
    
    def create_tool(
        self,
        name: str,
        description: str,
        function_id: str
    ) -> Dict[str, Any]:
        """
        Create a tool from a registered function.
        
        Args:
            name: The name of the tool
            description: A description of what the tool does
            function_id: The ID of the registered function to use
            
        Returns:
            A dictionary with the tool's details
            
        Raises:
            ToolNotFoundError: If the function is not found
            InvalidToolConfigError: If the tool configuration is invalid
        """
        if function_id not in self.registered_functions:
            raise ToolNotFoundError(f"Function with ID {function_id} not found")
            
        func_info = self.registered_functions[function_id]
        func = func_info["func"]
        
        try:
            # Create the tool using function_tool decorator
            tool = function_tool(
                name_override=name,
                description_override=description
            )(func)
            
            # Generate a unique ID for the tool
            tool_id = f"tool_{len(self.tools) + 1}"
            
            # Store the tool
            self.tools[tool_id] = {
                "id": tool_id,
                "name": name,
                "description": description,
                "function_id": function_id,
                "tool": tool
            }
            
            return {
                "id": tool_id,
                "name": name,
                "description": description,
                "function_id": function_id
            }
            
        except Exception as e:
            logger.error(f"Error creating tool: {str(e)}")
            raise InvalidToolConfigError(f"Error creating tool: {str(e)}")
    
    def get_tool(self, tool_id: str) -> Dict[str, Any]:
        """
        Get a tool by ID.
        
        Args:
            tool_id: The ID of the tool to get
            
        Returns:
            A dictionary with the tool's details
            
        Raises:
            ToolNotFoundError: If the tool is not found
        """
        if tool_id not in self.tools:
            raise ToolNotFoundError(f"Tool with ID {tool_id} not found")
            
        tool_info = self.tools[tool_id]
        return {
            "id": tool_info["id"],
            "name": tool_info["name"],
            "description": tool_info["description"],
            "function_id": tool_info["function_id"]
        }
    
    def list_tools(self) -> List[Dict[str, Any]]:
        """
        List all tools.
        
        Returns:
            A list of tool information dictionaries
        """
        return [self.get_tool(tool_id) for tool_id in self.tools]
    
    def get_tools_for_agent(self, tool_ids: List[str]) -> List[Tool]:
        """
        Get a list of Tool instances for use with an agent.
        
        Args:
            tool_ids: A list of tool IDs to get
            
        Returns:
            A list of Tool instances
            
        Raises:
            ToolNotFoundError: If any tool is not found
        """
        tools = []
        for tool_id in tool_ids:
            if tool_id not in self.tools:
                raise ToolNotFoundError(f"Tool with ID {tool_id} not found")
                
            tool_info = self.tools[tool_id]
            tools.append(tool_info["tool"])
            
        return tools
    
    def delete_tool(self, tool_id: str) -> bool:
        """
        Delete a tool by ID.
        
        Args:
            tool_id: The ID of the tool to delete
            
        Returns:
            True if the tool was deleted, False if not found
            
        Raises:
            ToolNotFoundError: If the tool is not found
        """
        if tool_id not in self.tools:
            raise ToolNotFoundError(f"Tool with ID {tool_id} not found")
            
        try:
            del self.tools[tool_id]
            return True
        except Exception as e:
            logger.error(f"Error deleting tool: {str(e)}")
            return False
    
    def register_tool(
        self,
        name: str,
        description: str,
        func: Callable,
        **kwargs
    ) -> Tool:
        """
        Create a tool from a Python function.
        
        Args:
            name: The name of the tool
            description: A description of what the tool does
            func: The Python function to use
            **kwargs: Additional arguments for the tool
            
        Returns:
            A Tool instance
            
        Raises:
            InvalidToolConfigError: If the tool configuration is invalid
        """
        if not callable(func):
            raise InvalidToolConfigError("Function must be callable")
            
        try:
            # Create the tool using the function_tool decorator
            tool = function_tool(
                name_override=name,
                description_override=description,
                **kwargs
            )(func)
            
            return tool
            
        except Exception as e:
            logger.error(f"Error creating tool: {str(e)}")
            raise InvalidToolConfigError(f"Error creating tool: {str(e)}") 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/tool_management.py

│   │   │   ├── __init__.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/__init__.py

"""
Services for the OpenAI Agents SDK integration.

This package provides services for working with the OpenAI Agents SDK, 
including agent management, tool management, and model management.
"""

# Import the services for easy access
from .agent_management import (
    AgentService,
    StreamEvent,
    AgentManagementError,
    AgentNotFoundError,
    InvalidAPIKeyError,
    InvalidAgentConfigError
)
from .tool_management import (
    ToolManagementService,
    ToolManagementError,
    ToolNotFoundError,
    InvalidToolConfigError
)
from .model_management import (
    ModelManagementService,
    ModelManagementError,
    UnsupportedModelError,
    InvalidAPIKeyError
)
from .assistant_bridge import (
    AssistantBridge,
    AssistantBridgeError
)
from .workato_integration import (
    WorkatoIntegration,
    WorkatoConfig
)

# Version info
__version__ = "0.1.0"

# For backward compatibility
AgentManagementService = AgentService 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/__init__.py

│   │   │   ├── assistant_bridge.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/assistant_bridge.py

from typing import Dict, Any, List, Optional, AsyncGenerator, Union, Tuple
import logging
import json
from openai import AsyncOpenAI
from agents import (
    Agent, OpenAIChatCompletionsModel, OpenAIResponsesModel,
    Tool, WebSearchTool, FileSearchTool
)
from agents.model_settings import ModelSettings
from agents.run import RunResult
from agents.items import RunItem, MessageOutputItem
from agents.exceptions import AgentsException
from .tool_management import ToolManagementService
from .agent_management import AgentManagementService, StreamEvent, AgentService
from .model_management import ModelManagementService
from .workato_integration import WorkatoConfig, WorkatoIntegration

logger = logging.getLogger(__name__)

class AssistantBridgeError(Exception):
    """Base exception for assistant bridge errors."""
    pass

class AssistantBridge:
    def __init__(self, api_key: str, assistant_id: str, vector_store_ids: Optional[List[str]] = None):
        """
        Bridge between Assistant and Agent SDK.
        
        Args:
            api_key: OpenAI API key
            assistant_id: Existing Assistant ID to get configuration from
            vector_store_ids: Optional list of vector store IDs for file search
        """
        self.api_key = api_key
        self.assistant_id = assistant_id
        self.vector_store_ids = vector_store_ids
        self.conversation_history = []
        self.agent_service = None
        self.workato_integration = None
        self.openai_client = AsyncOpenAI(api_key=api_key)
        self._agent_id: str | None = None
        self._agent_config: Dict[str, Any] | None = None
        self.initialized = False
        
    async def _create_tool_from_function(self, func_config: Dict[str, Any]) -> Tool:
        """Create a tool from a function configuration"""
        name = func_config["name"]
        description = func_config.get("description", "")
        parameters = func_config.get("parameters", {})
        
        # Create a proper tool implementation based on the function schema
        async def tool_func(context: Any, **kwargs: Any) -> Any:
            # In a real implementation, this would actually execute the function
            # For now, we just return a placeholder response
            return f"Called {name} with args: {kwargs}"
        
        return self.tool_service.register_tool(
            name=name,
            description=description,
            func=tool_func,
            parameters=parameters
        )

    async def _fetch_assistant_config(self) -> Dict[str, Any]:
        """Fetch the assistant configuration once and cache it"""
        if not self._agent_config:
            try:
                assistant = await self.openai_client.beta.assistants.retrieve(self.assistant_id)
                self._agent_config = {
                    "name": assistant.name,
                    "instructions": assistant.instructions,
                    "model": assistant.model,
                    "tools": assistant.tools
                }
            except Exception as e:
                logger.error(f"Error fetching assistant config: {str(e)}")
                raise AssistantBridgeError(f"Failed to fetch assistant config: {str(e)}")
        
        return self._agent_config

    async def initialize(self, workato_config: Optional[WorkatoConfig] = None):
        """Initialize the bridge with optional Workato configuration."""
        self.agent_service = AgentService(self.api_key)
        
        if workato_config:
            self.workato_integration = WorkatoIntegration(workato_config)
            await self.agent_service.initialize(
                assistant_id=self.assistant_id,
                vector_store_ids=self.vector_store_ids,
                workato_integration=self.workato_integration
            )
        else:
            await self.agent_service.initialize(
                assistant_id=self.assistant_id,
                vector_store_ids=self.vector_store_ids
            )
        
        self.initialized = True

    async def chat(self, message: str) -> str:
        """
        Process a chat message using the agent.
        
        Args:
            message: The user's message
            
        Returns:
            The agent's response
        """
        try:
            # Initialize if needed
            if not self.agent_service:
                await self.initialize()
                
            # Add message to history
            self.conversation_history.append({"role": "user", "content": message})
            
            # Format conversation history for agent context
            context = {
                "conversation_history": self.conversation_history,
                "assistant_id": self.assistant_id
            }
            
            # Run the agent with the new message
            response = await self.agent_service.run_existing_agent(
                input_text=message,
                context=context
            )
            
            # Add response to history
            self.conversation_history.append({"role": "assistant", "content": response})

            return response
            
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            raise AssistantBridgeError(f"Chat failed: {str(e)}")
    
    async def chat_streaming(self, message: str):
        """Chat with the assistant using streaming mode."""
        try:
            # Initialize if not already done
            if not self.agent_service:
                await self.initialize()
            
            # Append user message to conversation history
            self.conversation_history.append({"role": "user", "content": message})
            
            # Format conversation history for agent context
            context = {
                "conversation_history": self.conversation_history,
                "assistant_id": self.assistant_id
            }
            
            # Track the full response for conversation history
            full_response = ""
            
            # Stream events from agent service
            async for event in self.agent_service.run_existing_agent_streaming(
                input_text=message,
                context=context
            ):
                if event.type == "content_chunk":
                    content = event.data["content"]
                    full_response += content
                    yield content, "message"
                elif event.type == "tool_event":
                    yield "Using tool...", "tool_call"
                elif event.type == "start":
                    logger.debug("Agent processing started")
                elif event.type == "completion":
                    logger.debug("Agent processing completed")
                else:
                    # Log other event types without yielding them to the UI
                    logger.debug(f"Received event type {event.type}: {event.data}")
            
            # Add assistant's response to conversation history
            if full_response:
                self.conversation_history.append({"role": "assistant", "content": full_response})
                
        except Exception as e:
            logger.error(f"Error in streaming chat: {str(e)}")
            raise
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """Get the conversation history"""
        return self.conversation_history
        
    def clear_history(self) -> None:
        """Clear the conversation history"""
        self.conversation_history = [] 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/assistant_bridge.py

│   │   │   ├── agent_management.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/agent_management.py

from typing import List, Dict, Any, Optional, Union, Tuple, AsyncGenerator
import logging
import json
import uuid
import asyncio
from dataclasses import dataclass

# Use try/except to handle imports gracefully
try:
    from agents import (
        Agent, 
        Tool,
        OpenAIChatCompletionsModel,
        OpenAIResponsesModel,
        WebSearchTool,
        FileSearchTool,
        Runner
    )
    from agents.model_settings import ModelSettings
    from agents.items import MessageOutputItem
    AGENTS_SDK_AVAILABLE = True
except (ImportError, AttributeError):
    # Create dummy classes for typing
    class Agent: pass
    class Tool: pass
    class ModelSettings: pass
    class MessageOutputItem: pass
    class Runner:
        @staticmethod
        async def run(*args, **kwargs): 
            return type('obj', (object,), {'new_items': []})
    AGENTS_SDK_AVAILABLE = False
    print("WARNING: agents-sdk import failed. Using dummy implementation.")

from openai import AsyncOpenAI

logger = logging.getLogger(__name__)

@dataclass
class StreamEvent:
    """Custom event class for simulating streaming events."""
    type: str
    data: Dict[str, Any]

class AgentService:
    """Service for managing OpenAI agents."""
    
    def __init__(self, api_key: str):
        """Initialize with an API key."""
        self.api_key = api_key
        self.agent = None
        self.openai_client = AsyncOpenAI(api_key=api_key)
    
    async def initialize(self, assistant_id: str, vector_store_ids: Optional[List[str]] = None, workato_integration=None):
        """Initialize the agent from an assistant ID."""
        if not AGENTS_SDK_AVAILABLE:
            logger.warning("Agents SDK not available, using fallback implementation")
            return False
            
        try:
            # 1. Get assistant details
            assistant = await self.openai_client.beta.assistants.retrieve(assistant_id)
            
            # 2. Configure tools
            tools = []
            
            # 3. Add web search tool if needed
            web_search_tool = WebSearchTool()
            tools.append(web_search_tool)
            
            # 4. Add file search if vector store IDs provided
            if vector_store_ids:
                for vs_id in vector_store_ids:
                    file_search = FileSearchTool(vector_store_id=vs_id)
                    tools.append(file_search)
            
            # 5. Add Workato tools if provided
            if workato_integration:
                workato_tools = workato_integration.get_tools()
                tools.extend(workato_tools)
            
            # 6. Create the model
            model = OpenAIResponsesModel(
                openai_client=self.openai_client,
                model=assistant.model
            )
            
            # 7. Create the agent
            self.agent = Agent(
                name=assistant.name or "Assistant",
                instructions=assistant.instructions,
                tools=tools,
                model=model
            )
            
            logger.info(f"Agent initialized from assistant {assistant_id}")
            return True
            
        except Exception as e:
            logger.error(f"Error initializing agent: {str(e)}")
            return False
    
    async def run_existing_agent(self, input_text: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Run the agent with the given input."""
        if not self.agent:
            raise ValueError("No agent found. Call initialize() first.")
            
        if not AGENTS_SDK_AVAILABLE:
            return "Agents SDK not available. This is a simulated response."
        
        try:
            # Use the Runner to run the agent
            result = await Runner.run(
                starting_agent=self.agent,
                input=input_text,
                context=context or {}
            )
            
            # Extract text output
            output = ""
            if result.new_items:
                for item in reversed(result.new_items):
                    if hasattr(item, 'message') and hasattr(item.message, 'content'):
                        output = item.message.content
                        break
                    elif hasattr(item, 'text'):
                        output = item.text
                        break
            
            return output or "No response generated."
            
        except Exception as e:
            logger.error(f"Error running agent: {str(e)}")
            raise
    
    async def run_existing_agent_streaming(self, input_text: str, context: Optional[Dict[str, Any]] = None):
        """Run the agent with streaming enabled."""
        if not self.agent:
            raise ValueError("No agent found. Call initialize() first.")
            
        if not AGENTS_SDK_AVAILABLE:
            # Fallback for when agents SDK isn't available
            yield StreamEvent(type="start", data={"message": "Starting processing"})
            await asyncio.sleep(0.5)
            yield StreamEvent(type="content_chunk", data={"content": "I'm sorry, the Agents SDK is not available. "})
            await asyncio.sleep(0.1)
            yield StreamEvent(type="content_chunk", data={"content": "This is a simulated response. "})
            await asyncio.sleep(0.1)
            yield StreamEvent(type="completion", data={"message": "Processing complete"})
            return
        
        try:
            # First yield a starting event
            yield StreamEvent(type="start", data={"message": "Starting agent processing"})
            
            # Run the agent normally (without stream=True) - get complete response
            agent = self.agent
            result = await Runner.run(
                starting_agent=agent,
                input=input_text,
                context=context or {}
            )
            
            # Extract the final output message
            output = ""
            if result.new_items:
                for item in reversed(result.new_items):
                    # Find a MessageOutputItem to get the final response
                    if hasattr(item, 'message') and hasattr(item.message, 'content'):
                        output = item.message.content
                        break
                    # Fallback to text attribute
                    elif hasattr(item, 'text'):
                        output = item.text
                        break
                    # Fallback to raw_item if available
                    elif hasattr(item, 'raw_item'):
                        if hasattr(item.raw_item, 'content') and isinstance(item.raw_item.content, list):
                            # Combine all text from content items
                            content_texts = []
                            for content_item in item.raw_item.content:
                                if hasattr(content_item, 'text'):
                                    content_texts.append(content_item.text)
                            
                            if content_texts:
                                output = "\n".join(content_texts)
                                break
            
            # If we have an output, simulate streaming by breaking it into chunks
            if output:
                # Track tool usage to simulate tool events
                tool_mentioned = False
                
                # Break the output into sentences
                sentences = output.split(". ")
                
                for i, sentence in enumerate(sentences):
                    # Add the period back except for the last sentence
                    if i < len(sentences) - 1:
                        sentence += "."
                    
                    # If the sentence mentions tools and we haven't simulated a tool event yet
                    if ("tool" in sentence.lower() or "search" in sentence.lower()) and not tool_mentioned:
                        yield StreamEvent(type="tool_event", data={"message": "Using a tool"})
                        tool_mentioned = True
                    
                    # Yield the sentence as a content chunk
                    yield StreamEvent(type="content_chunk", data={"content": sentence + " "})
                    
                    # Add a small delay to simulate real streaming
                    await asyncio.sleep(0.05)
            
            # Yield a completion event
            yield StreamEvent(type="completion", data={"message": "Processing complete"})
                
        except Exception as e:
            logger.error(f"Error in streaming agent run: {str(e)}")
            raise 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/agent_management.py

│   │   │   ├── workato_integration.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/workato_integration.py

from dataclasses import dataclass
from typing import List, Dict, Any
import aiohttp
import json
import logging
from agents import Tool, function_tool

logger = logging.getLogger(__name__)

@dataclass
class WorkatoConfig:
    """Configuration for Workato integration."""
    api_token: str
    endpoint_url: str

class WorkatoIntegration:
    """Integration with Workato API."""
    
    def __init__(self, config: WorkatoConfig):
        self.config = config
        
    def get_tools(self) -> List[Tool]:
        """Get the list of Workato tools."""
        tools = []
        
        @function_tool(
            name_override="execute_workato_action",
            description_override="""Execute any action through Workato. Available actions include searching or creating contacts in Salesforce.
            The action_type specifies what operation to perform (e.g., 'search_contact', 'create_contact').
            The system parameter indicates which system to interact with (e.g., 'salesforce', 'hubspot').
            The payload_json should be a JSON string containing the data for the action."""
        )
        async def execute_workato_action(action_type: str, system: str, payload_json: str) -> Dict[str, Any]:
            """Execute an action via Workato.
            
            Args:
                action_type: The type of action to execute (e.g., 'search_contact', 'create_contact')
                system: The system to interact with (e.g., 'salesforce', 'hubspot')
                payload_json: JSON string containing the data payload for the action
            
            Returns:
                Dict containing success status, data/error message, and optional result data
            """
            try:
                # For search_contact actions, ensure we use contact_name
                if action_type == "search_contact":
                    try:
                        # Parse existing payload
                        payload_dict = json.loads(payload_json)
                        # If name is provided, convert it to contact_name
                        if "name" in payload_dict:
                            payload_dict["contact_name"] = payload_dict.pop("name")
                        # If neither exists, create contact_name
                        if "contact_name" not in payload_dict:
                            return {
                                "success": False,
                                "error": "Missing contact_name in payload"
                            }
                        # Convert back to JSON string
                        payload_json = json.dumps(payload_dict)
                    except json.JSONDecodeError as e:
                        return {
                            "success": False,
                            "error": f"Invalid payload JSON: {str(e)}"
                        }

                async with aiohttp.ClientSession() as session:
                    headers = {
                        "API-TOKEN": self.config.api_token,
                        "Content-Type": "application/json"
                    }
                    
                    # Format the payload according to Workato's expected structure
                    request_payload = {
                        "action_type": action_type,
                        "system": system,
                        "payload": payload_json,  # JSON string with correct field names
                        "schema": "{}"  # Empty schema as a JSON string
                    }
                    
                    # Log the complete request details
                    logger.info("=== Workato API Request Details ===")
                    logger.info(f"Endpoint URL: {self.config.endpoint_url}")
                    logger.info(f"Headers: {json.dumps(headers, indent=2)}")
                    logger.info(f"Request Payload: {json.dumps(request_payload, indent=2)}")
                    logger.info("================================")
                    
                    async with session.post(
                        self.config.endpoint_url,
                        headers=headers,
                        json=request_payload
                    ) as response:
                        response_text = await response.text()
                        logger.info("=== Workato API Response ===")
                        logger.info(f"Status Code: {response.status}")
                        logger.info(f"Response Body: {response_text}")
                        logger.info("===========================")
                        
                        if response.status == 200:
                            result = json.loads(response_text)
                            return {
                                "success": True,
                                "data": result,
                                "message": f"Action '{action_type}' on system '{system}' completed successfully"
                            }
                        else:
                            logger.error(f"Error executing action: {response_text}")
                            return {
                                "success": False,
                                "error": f"Failed to execute action: {response_text}"
                            }
                            
            except Exception as e:
                logger.error(f"Error in execute_workato_action: {str(e)}")
                return {
                    "success": False,
                    "error": f"Error executing action: {str(e)}"
                }
        
        tools.append(execute_workato_action)
        return tools 

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/workato_integration.py

│   │   │   ├── model_management.py

FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/model_management.py

from typing import Dict, Any, Optional, List, Union
import logging
from agents import OpenAIChatCompletionsModel, OpenAIResponsesModel, ModelSettings
import openai

logger = logging.getLogger(__name__)

class ModelManagementError(Exception):
    """Base exception for model management errors."""
    pass

class InvalidAPIKeyError(ModelManagementError):
    """Exception raised when the API key is invalid."""
    pass

class UnsupportedModelError(ModelManagementError):
    """Exception raised when the requested model is not supported."""
    pass

class ModelManagementService:
    """Service for managing OpenAI models for use with agents."""
    
    # List of supported models
    SUPPORTED_MODELS = [
        "gpt-4", 
        "gpt-4-turbo", 
        "gpt-3.5-turbo",
        "gpt-4o"
    ]
    
    def __init__(self):
        """Initialize the model management service."""
        self.model_configs = {}
    
    def _validate_api_key(self, api_key: str) -> bool:
        """
        Validate that the API key is properly formatted.
        This is a basic check - real validation happens when using the key with OpenAI.
        """
        if not isinstance(api_key, str):
            return False
        
        # OpenAI API keys typically start with "sk-" and have a specific length
        if not api_key.startswith("sk-") or len(api_key) < 20:
            return False
            
        return True
    
    def create_model_settings(
        self,
        temperature: float = 0.7,
        top_p: float = 1.0,
        max_tokens: Optional[int] = None,
        presence_penalty: float = 0.0,
        frequency_penalty: float = 0.0,
        stop: Optional[List[str]] = None,
        **kwargs
    ) -> ModelSettings:
        """
        Create model settings with the specified parameters.
        
        Args:
            temperature: Controls randomness. Higher values make output more random.
            top_p: Controls diversity via nucleus sampling.
            max_tokens: Maximum number of tokens to generate.
            presence_penalty: Penalizes new tokens based on presence in text so far.
            frequency_penalty: Penalizes new tokens based on frequency in text so far.
            stop: A list of strings that will stop generation.
            **kwargs: Additional model settings parameters.
            
        Returns:
            A ModelSettings instance
        """
        settings_dict = {
            "temperature": temperature,
            "top_p": top_p,
            "presence_penalty": presence_penalty,
            "frequency_penalty": frequency_penalty,
            **kwargs
        }
        
        if max_tokens is not None:
            settings_dict["max_tokens"] = max_tokens
            
        if stop is not None:
            settings_dict["stop"] = stop
            
        return ModelSettings(**settings_dict)
    
    def create_model(
        self,
        api_key: str,
        model_name: str = "gpt-4o",
        settings: Optional[ModelSettings] = None,
        use_chat_completions: bool = False
    ) -> Union[OpenAIResponsesModel, OpenAIChatCompletionsModel]:
        """
        Create an OpenAI model instance.
        
        Args:
            api_key: The OpenAI API key to use
            model_name: The name of the model to use
            settings: Optional model settings
            use_chat_completions: If True, use OpenAIChatCompletionsModel instead of OpenAIResponsesModel
            
        Returns:
            An OpenAI model instance (OpenAIResponsesModel by default)
            
        Raises:
            InvalidAPIKeyError: If the API key is invalid
            UnsupportedModelError: If the model is not supported
        """
        if not self._validate_api_key(api_key):
            raise InvalidAPIKeyError("Invalid API key format")
            
        if model_name not in self.SUPPORTED_MODELS:
            raise UnsupportedModelError(f"Model {model_name} is not supported. Supported models: {', '.join(self.SUPPORTED_MODELS)}")
        
        try:
            # Create OpenAI client
            client = openai.AsyncOpenAI(api_key=api_key)
            
            # Create model with client - use OpenAIResponsesModel by default
            if use_chat_completions:
                logger.info(f"Creating OpenAIChatCompletionsModel with model {model_name}")
                model = OpenAIChatCompletionsModel(
                    model=model_name,
                    openai_client=client
                )
            else:
                logger.info(f"Creating OpenAIResponsesModel with model {model_name}")
                model = OpenAIResponsesModel(
                    model=model_name,
                    openai_client=client
                )
            
            # Apply settings if provided
            if settings:
                model.model_settings = settings
                
            return model
            
        except Exception as e:
            logger.error(f"Error creating model: {str(e)}")
            raise ModelManagementError(f"Error creating model: {str(e)}")
    
    def save_model_config(
        self,
        config_id: str,
        model_name: str,
        settings: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Save a model configuration for later use.
        
        Args:
            config_id: A unique identifier for the configuration
            model_name: The name of the model
            settings: A dictionary of model settings
            
        Returns:
            A dictionary with the configuration details
        """
        if config_id in self.model_configs:
            logger.warning(f"Model configuration with ID {config_id} already exists, overwriting")
            
        config = {
            "id": config_id,
            "model_name": model_name,
            "settings": settings
        }
        
        self.model_configs[config_id] = config
        return config
    
    def get_model_config(self, config_id: str) -> Dict[str, Any]:
        """
        Get a model configuration by ID.
        
        Args:
            config_id: The ID of the configuration to get
            
        Returns:
            A dictionary with the configuration details
            
        Raises:
            ModelManagementError: If the configuration is not found
        """
        if config_id not in self.model_configs:
            raise ModelManagementError(f"Model configuration with ID {config_id} not found")
            
        return self.model_configs[config_id]
    
    def list_model_configs(self) -> List[Dict[str, Any]]:
        """
        List all model configurations.
        
        Returns:
            A list of configuration dictionaries
        """
        return list(self.model_configs.values())
    
    def delete_model_config(self, config_id: str) -> bool:
        """
        Delete a model configuration by ID.
        
        Args:
            config_id: The ID of the configuration to delete
            
        Returns:
            True if the configuration was deleted, False if not found
            
        Raises:
            ModelManagementError: If the configuration is not found
        """
        if config_id not in self.model_configs:
            raise ModelManagementError(f"Model configuration with ID {config_id} not found")
            
        try:
            del self.model_configs[config_id]
            return True
        except Exception as e:
            logger.error(f"Error deleting model configuration: {str(e)}")
            return False
    
    def get_model_from_config(
        self,
        api_key: str,
        config_id: str,
        use_chat_completions: bool = False
    ) -> Union[OpenAIResponsesModel, OpenAIChatCompletionsModel]:
        """
        Create a model instance from a saved configuration.
        
        Args:
            api_key: The OpenAI API key to use
            config_id: The ID of the configuration to use
            use_chat_completions: If True, use OpenAIChatCompletionsModel instead of OpenAIResponsesModel
            
        Returns:
            An OpenAI model instance
            
        Raises:
            ModelManagementError: If the configuration is not found
            InvalidAPIKeyError: If the API key is invalid
            UnsupportedModelError: If the model is not supported
        """
        config = self.get_model_config(config_id)
        
        # Convert settings dict to ModelSettings
        settings = self.create_model_settings(**config["settings"])
        
        # Create the model
        return self.create_model(
            api_key=api_key,
            model_name=config["model_name"],
            settings=settings,
            use_chat_completions=use_chat_completions
        )


FILE NAME /Users/rossdickinson/SolomonAssistants/app/services/agent_services/model_management.py

├── tests
│   ├── test_agent_interface.py

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_agent_interface.py

#!/usr/bin/env python
import asyncio
import argparse
import logging
from typing import List, Optional
import os
import sys
import re
import time

# Add the parent directory to Python path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.agent_services.assistant_bridge import AssistantBridge
from app.services.agent_services.workato_integration import WorkatoConfig

# Configure logging - set to WARNING to suppress INFO logs
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

# Also suppress httpx logging
logging.getLogger("httpx").setLevel(logging.WARNING)

# Standard Workato configuration for testing
WORKATO_CONFIG = WorkatoConfig(
    api_token="ad19767e318455a1daa7635b3e5f3ce4055f11376155b45c506ceb4f4f739d1c",
    endpoint_url="https://apim.workato.com/solconsult/assistant-tools-v1/workato-root-tool"
)

def format_response_with_citations(response: str) -> str:
    """Format the response to highlight web search citations."""
    # Check if the response contains markdown-style links
    if "[" in response and "](" in response:
        # Add a separator before the citations section if it exists
        if "##" in response:
            parts = response.split("##")
            main_content = parts[0]
            citations = "##" + "##".join(parts[1:])
            
            # Format the main content
            formatted_main = format_markdown_links(main_content)
            
            # Format the citations section
            formatted_citations = format_markdown_links(citations)
            
            return formatted_main + "\n" + formatted_citations
        else:
            return format_markdown_links(response)
    else:
        return response

def format_markdown_links(text):
    """Format markdown links to make them more visible."""
    # Find all markdown links [text](url)
    pattern = r'\[([^\]]+)\]\(([^)]+)\)'
    
    # Replace with a formatted version
    formatted = re.sub(pattern, r'[\1](\2)', text)
    
    return formatted

async def interactive_chat(api_key, assistant_id, vector_store_ids=None):
    """Run an interactive chat session with the assistant."""
    print("\n=== Assistant Bridge Test Interface ===")
    print("Type 'exit', 'quit', or 'bye' to end the conversation.")
    print("Type 'history' to see the conversation history.")
    print("Type 'clear' to clear the conversation history.")
    print("Type 'stream' to toggle streaming mode.")
    print("=========================================\n")
    
    # Initialize the bridge
    print("Initializing bridge...")
    bridge = AssistantBridge(api_key, assistant_id, vector_store_ids)
    await bridge.initialize(workato_config=WORKATO_CONFIG)
    print("Bridge initialized successfully!\n")
    print("NOTE: This interface uses the OpenAI Agents SDK for all interactions.")
    print("      Web search capability is enabled and will be used when appropriate.")
    print("      Workato integration is enabled for system interactions.")
    
    # Print file search status
    if vector_store_ids:
        print(f"      File search capability is enabled with vector stores: {vector_store_ids}")
    else:
        print("      File search capability is disabled (no vector stores provided).")
    print()
    
    # Stream mode flag
    streaming_enabled = True
    print(f"Streaming mode is {'enabled'} by default.")

    # Main conversation loop
    while True:
        # Get user input
        user_input = input("You: ")
        
        # Check for exit commands
        if user_input.lower() in ["exit", "quit", "bye"]:
            print("\nThank you for chatting! Goodbye.")
            break
            
        # Check for history command
        elif user_input.lower() == "history":
            history = bridge.get_conversation_history()
            print("\n=== Conversation History ===")
            for entry in history:
                role = entry["role"].upper()
                content = entry["content"]
                print(f"{role}: {content}\n")
            continue
            
        # Check for clear command
        elif user_input.lower() == "clear":
            bridge.clear_history()
            print("\nConversation history cleared.\n")
            continue
        
        # Toggle streaming mode
        elif user_input.lower() == "stream":
            streaming_enabled = not streaming_enabled
            print(f"\nStreaming mode is now {'enabled' if streaming_enabled else 'disabled'}.\n")
            continue
        
        # Process the user message
        print("\nAssistant is thinking...")
        try:
            # Use streaming or non-streaming mode based on user preference
            if streaming_enabled:
                # Use streaming mode - display tokens as they come
                full_response = ""
                tool_used = False
                print("\nAssistant: ", end="", flush=True)
                
                async for chunk, event_type in bridge.chat_streaming(user_input):
                    if event_type == "raw_response" or event_type == "message":
                        print(chunk, end="", flush=True)
                        full_response += chunk
                    elif event_type == "tool_call":
                        # Print tool usage without adding to full response
                        time.sleep(0.1)  # Brief pause for readability
                        print(f"\n[Using tool: {chunk}]", end="", flush=True)
                        tool_used = True
                    elif event_type == "tool_output":
                        # Print tool result without adding to full response
                        time.sleep(0.1)  # Brief pause for readability
                        print(f"\n[Tool result: {chunk}]", end="", flush=True)
                
                # Format the complete response at the end
                formatted_response = format_response_with_citations(full_response)
                print("\n")  # Add an extra line break after streaming
                
                # Check if the response likely contains web search results
                if "[" in full_response and "](" in full_response:
                    print("(Web search was used to generate this response)\n")
                elif tool_used:
                    print("(Tools were used to generate this response)\n")
            else:
                # Use non-streaming mode - display complete response at once
                response = await bridge.chat(user_input)
                
                # Format the response to highlight citations
                formatted_response = format_response_with_citations(response)
                print(f"\nAssistant: {formatted_response}\n")
                
                # Check if the response likely contains web search results
                if "[" in response and "](" in response:
                    print("(Web search was used to generate this response)\n")

        except Exception as e:
            print(f"\nError: {str(e)}\n")

def main():
    parser = argparse.ArgumentParser(description="Test interface for Assistant Bridge")
    parser.add_argument("api_key", help="OpenAI API key")
    parser.add_argument("assistant_id", help="OpenAI Assistant ID")
    parser.add_argument("--vector-stores", nargs="+", help="Vector store IDs for file search")
    
    args = parser.parse_args()
    
    # Run the interactive chat
    asyncio.run(interactive_chat(args.api_key, args.assistant_id, args.vector_stores))

if __name__ == "__main__":
    main() 

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_agent_interface.py

│   ├── test_basic.py

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_basic.py

import asyncio
import argparse
import logging
import sys
import os

# Configure basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import AsyncOpenAI

async def direct_assistant_test(api_key, assistant_id):
    """Test the assistant directly using OpenAI API."""
    print("Starting direct assistant test...")
    
    # Initialize the OpenAI client
    client = AsyncOpenAI(api_key=api_key)
    
    # Create a thread
    thread = await client.beta.threads.create()
    print(f"Created thread: {thread.id}")
    
    # Add a message to the thread
    message = await client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content="Hello! How are you today?"
    )
    print(f"Added message to thread")
    
    # Run the assistant
    run = await client.beta.threads.runs.create(
        thread_id=thread.id,
        assistant_id=assistant_id
    )
    print(f"Started run: {run.id}")
    
    # Wait for the run to complete
    while True:
        run_status = await client.beta.threads.runs.retrieve(
            thread_id=thread.id,
            run_id=run.id
        )
        print(f"Run status: {run_status.status}")
        
        if run_status.status == "completed":
            break
        elif run_status.status in ["failed", "cancelled", "expired"]:
            print(f"Run failed with status: {run_status.status}")
            return
        
        # Wait before checking again
        await asyncio.sleep(1)
    
    # Get the messages
    messages = await client.beta.threads.messages.list(
        thread_id=thread.id
    )
    
    # Print the assistant's response
    print("\nAssistant's response:")
    for msg in messages.data:
        if msg.role == "assistant":
            for content_item in msg.content:
                if content_item.type == "text":
                    print(content_item.text.value)
    
    print("\nTest completed successfully!")

def main():
    parser = argparse.ArgumentParser(description="Basic test for OpenAI Assistant")
    parser.add_argument("api_key", help="OpenAI API key")
    parser.add_argument("assistant_id", help="OpenAI Assistant ID")
    
    args = parser.parse_args()
    
    # Run the test
    asyncio.run(direct_assistant_test(args.api_key, args.assistant_id))

if __name__ == "__main__":
    main() 

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_basic.py

│   ├── test_interface_debug.py

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_interface_debug.py

import asyncio
import argparse
import logging
import traceback
from typing import List, Optional
import os
import sys
import re
import time

# Configure verbose logging
logging.basicConfig(level=logging.DEBUG, 
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Add the parent directory to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    print("Importing WorkatoConfig...")
    from app.services.workato_integration import WorkatoConfig
    print("Importing AssistantBridge...")
    from app.services.assistant_bridge import AssistantBridge
    print("Imports completed successfully")
except Exception as e:
    print(f"Error during imports: {str(e)}")
    traceback.print_exc()
    sys.exit(1)

# Hard-coded Workato configuration for testing
WORKATO_CONFIG = WorkatoConfig(
    api_token="ad19767e318455a1daa7635b3e5f3ce4055f11376155b45c506ceb4f4f739d1c",
    endpoint_url="https://apim.workato.com/solconsult/assistant-tools-v1/workato-root-tool"
)

async def test_chat(api_key, assistant_id, vector_store_ids=None):
    """Test that chat functionality works."""
    try:
        print("\n=== Testing AssistantBridge ===")
        print("1. Creating bridge instance...")
        bridge = AssistantBridge(api_key, assistant_id, vector_store_ids)
        
        print("2. Initializing bridge...")
        await bridge.initialize(workato_config=WORKATO_CONFIG)
        print("Bridge initialized successfully!")
        
        print("3. Testing chat...")
        response = await bridge.chat("Hello! What can you help me with today?")
        print(f"\nChat response:\n{response}\n")
        
        print("4. Testing streaming chat...")
        print("\nStreaming: ", end="", flush=True)
        async for chunk, event_type in bridge.chat_streaming("Tell me about yourself in 3 sentences."):
            print(chunk, end="", flush=True)
        print("\n\nStreaming completed")
        
        print("5. Getting conversation history...")
        history = bridge.get_conversation_history()
        print(f"Conversation history: {len(history)} messages")
        
        print("Test completed successfully!")
        return True
    except Exception as e:
        print(f"Error during test: {str(e)}")
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description="Test interface for Assistant Bridge")
    parser.add_argument("api_key", help="OpenAI API key")
    parser.add_argument("assistant_id", help="OpenAI Assistant ID")
    parser.add_argument("--vector-stores", nargs="+", help="Vector store IDs for file search")
    
    args = parser.parse_args()
    
    # Run the test
    success = asyncio.run(test_chat(args.api_key, args.assistant_id, args.vector_stores))
    
    if success:
        print("\nAll tests passed!")
        sys.exit(0)
    else:
        print("\nTests failed!")
        sys.exit(1)

if __name__ == "__main__":
    main() 

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_interface_debug.py

│   ├── test_interface.py

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_interface.py

import asyncio
import argparse
import logging
from typing import List, Optional
import os
import sys
import re
import time

# Add the parent directory to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.assistant_bridge import AssistantBridge
from app.services.workato_integration import WorkatoConfig

# Configure logging - set to WARNING to suppress INFO logs
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

# Also suppress httpx logging
logging.getLogger("httpx").setLevel(logging.WARNING)

# Hard-coded Workato configuration for testing
WORKATO_CONFIG = WorkatoConfig(
    api_token="ad19767e318455a1daa7635b3e5f3ce4055f11376155b45c506ceb4f4f739d1c",
    endpoint_url="https://apim.workato.com/solconsult/assistant-tools-v1/workato-root-tool"
)

def format_response_with_citations(response: str) -> str:
    """Format the response to highlight web search citations."""
    # Check if the response contains markdown-style links
    if "[" in response and "](" in response:
        # Add a separator before the citations section if it exists
        if "##" in response:
            parts = response.split("##")
            main_content = parts[0]
            citations = "##" + "##".join(parts[1:])
            
            # Format the main content
            formatted_main = format_markdown_links(main_content)
            
            # Format the citations section
            formatted_citations = format_markdown_links(citations)
            
            return formatted_main + "\n" + formatted_citations
        else:
            return format_markdown_links(response)
    else:
        return response

def format_markdown_links(text):
    """Format markdown links to make them more visible."""
    # Find all markdown links [text](url)
    pattern = r'\[([^\]]+)\]\(([^)]+)\)'
    
    # Replace with a formatted version
    formatted = re.sub(pattern, r'[\1](\2)', text)
    
    return formatted

async def interactive_chat(api_key, assistant_id, vector_store_ids=None):
    """Run an interactive chat session with the assistant."""
    print("\n=== Assistant Bridge Test Interface ===")
    print("Type 'exit', 'quit', or 'bye' to end the conversation.")
    print("Type 'history' to see the conversation history.")
    print("Type 'clear' to clear the conversation history.")
    print("Type 'stream' to toggle streaming mode.")
    print("=========================================\n")
    
    # Initialize the bridge
    print("Initializing bridge...")
    bridge = AssistantBridge(api_key, assistant_id, vector_store_ids)
    await bridge.initialize(workato_config=WORKATO_CONFIG)
    print("Bridge initialized successfully!\n")
    print("NOTE: This interface now uses OpenAIResponsesModel by default for all interactions.")
    print("      Web search capability is enabled and will be used when appropriate.")
    print("      Workato integration is enabled for system interactions.")
    
    # Print file search status
    if vector_store_ids:
        print(f"      File search capability is enabled with vector stores: {vector_store_ids}")
    else:
        print("      File search capability is disabled (no vector stores provided).")
    print()
    
    # Stream mode flag
    streaming_enabled = True
    print(f"Streaming mode is {'enabled'} by default.")

    # Main conversation loop
    while True:
        # Get user input
        user_input = input("You: ")
        
        # Check for exit commands
        if user_input.lower() in ["exit", "quit", "bye"]:
            print("\nThank you for chatting! Goodbye.")
            break
            
        # Check for history command
        elif user_input.lower() == "history":
            history = bridge.get_conversation_history()
            print("\n=== Conversation History ===")
            for entry in history:
                role = entry["role"].upper()
                content = entry["content"]
                print(f"{role}: {content}\n")
            continue
            
        # Check for clear command
        elif user_input.lower() == "clear":
            bridge.clear_history()
            print("\nConversation history cleared.\n")
            continue
        
        # Toggle streaming mode
        elif user_input.lower() == "stream":
            streaming_enabled = not streaming_enabled
            print(f"\nStreaming mode is now {'enabled' if streaming_enabled else 'disabled'}.\n")
            continue
        
        # Process the user message
        print("\nAssistant is thinking...")
        try:
            # Use streaming or non-streaming mode based on user preference
            if streaming_enabled:
                # Use streaming mode - display tokens as they come
                full_response = ""
                tool_used = False
                print("\nAssistant: ", end="", flush=True)
                
                async for chunk, event_type in bridge.chat_streaming(user_input):
                    if event_type == "raw_response" or event_type == "message":
                        print(chunk, end="", flush=True)
                        full_response += chunk
                    elif event_type == "tool_call":
                        # Print tool usage without adding to full response
                        time.sleep(0.1)  # Brief pause for readability
                        print(f"\n[{chunk}]", end="", flush=True)
                        tool_used = True
                    elif event_type == "tool_output":
                        # Print tool result without adding to full response
                        time.sleep(0.1)  # Brief pause for readability
                        print(f"\n[{chunk}]", end="", flush=True)
                
                # Format the complete response at the end
                formatted_response = format_response_with_citations(full_response)
                print("\n")  # Add an extra line break after streaming
                
                # Check if the response likely contains web search results
                if "[" in full_response and "](" in full_response:
                    print("(Web search was used to generate this response)\n")
                elif tool_used:
                    print("(Tools were used to generate this response)\n")
            else:
                # Use non-streaming mode - display complete response at once
                response = await bridge.chat(user_input)
                
                # Format the response to highlight citations
                formatted_response = format_response_with_citations(response)
                print(f"\nAssistant: {formatted_response}\n")
                
                # Check if the response likely contains web search results
                if "[" in response and "](" in response:
                    print("(Web search was used to generate this response)\n")

        except Exception as e:
            print(f"\nError: {str(e)}\n")

def main():
    parser = argparse.ArgumentParser(description="Test interface for Assistant Bridge")
    parser.add_argument("api_key", help="OpenAI API key")
    parser.add_argument("assistant_id", help="OpenAI Assistant ID")
    parser.add_argument("--vector-stores", nargs="+", help="Vector store IDs for file search")
    
    args = parser.parse_args()
    
    # Run the interactive chat
    asyncio.run(interactive_chat(args.api_key, args.assistant_id, args.vector_stores))

if __name__ == "__main__":
    main() 

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_interface.py

│   ├── test_websocket_client.py

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_websocket_client.py

#!/usr/bin/env python
import asyncio
import websockets
import json
import sys
import argparse
import logging
import os

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_websocket_client(api_key, assistant_id, vector_store_ids=None):
    """Test the WebSocket API with streaming responses."""
    uri = "ws://localhost:8000/ws"
    print(f"Connecting to {uri}...")
    
    async with websockets.connect(uri) as websocket:
        # Send connection parameters
        await websocket.send(json.dumps({
            "api_key": api_key,
            "assistant_id": assistant_id,
            "vector_store_ids": vector_store_ids
        }))
        
        # Wait for ready message
        response = await websocket.recv()
        response_data = json.loads(response)
        print(f"Server: {response}")
        
        if response_data.get("type") == "error":
            print(f"Error: {response_data.get('error')}")
            return
        
        # Start interactive mode
        print("\n=== Interactive WebSocket Test ===")
        print("Type your messages, or 'exit' to quit")
        
        while True:
            # Get user input
            user_input = input("You: ")
            
            if user_input.lower() == "exit":
                break
            
            # Send message to server
            await websocket.send(json.dumps({
                "type": "message",
                "content": user_input,
                "stream": True  # Enable streaming
            }))
            
            # Process server responses
            assistant_response = ""
            print("Assistant: ", end="", flush=True)
            
            while True:
                try:
                    response = await websocket.recv()
                    response_data = json.loads(response)
                    
                    if response_data.get("type") == "stream":
                        # Print streaming content
                        print(response_data.get("content", ""), end="", flush=True)
                        assistant_response += response_data.get("content", "")
                    elif response_data.get("type") == "tool":
                        # Print tool usage
                        if response_data.get("tool") == "call":
                            print(f"\n[Using tool: {response_data.get('name', 'unknown')}]", end="", flush=True)
                        elif response_data.get("tool") == "output":
                            print(f"\n[Tool output: {response_data.get('content', '')}]", end="", flush=True)
                    elif response_data.get("type") == "completion":
                        # Stream complete
                        print()  # Add newline
                        break
                    elif response_data.get("type") == "error":
                        # Error occurred
                        print(f"\nError: {response_data.get('error')}")
                        break
                    elif response_data.get("type") == "system":
                        # System message
                        if "Processing" not in response_data.get("message", ""):
                            print(f"\nSystem: {response_data.get('message')}")
                    elif response_data.get("type") == "response":
                        # Non-streaming response
                        print(response_data.get("content", ""))
                        break
                except Exception as e:
                    logger.error(f"Error in WebSocket communication: {str(e)}")
                    print(f"\nConnection error: {str(e)}")
                    return

def main():
    parser = argparse.ArgumentParser(description="Test the WebSocket API")
    parser.add_argument("api_key", help="OpenAI API key")
    parser.add_argument("assistant_id", help="OpenAI Assistant ID")
    parser.add_argument("--vector-stores", nargs="+", help="Vector store IDs for file search")
    
    args = parser.parse_args()
    
    try:
        asyncio.run(test_websocket_client(args.api_key, args.assistant_id, args.vector_stores))
    except KeyboardInterrupt:
        print("\nTest terminated by user")
    except Exception as e:
        print(f"Error: {str(e)}")

if __name__ == "__main__":
    main() 

FILE NAME /Users/rossdickinson/SolomonAssistants/tests/test_websocket_client.py

"""
